\documentclass[12pt,a4paper]{article}
\usepackage{pgf}
% \usepackage[condensed,math]{kurier}
% \usepackage[T1]{fontenc}
\usepackage{svg}
\usepackage{tikz}
\usepackage{stanli}
\usepackage{afterpage}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{pgfpages}
\usepackage{svg}
\usepackage{rotating}
\usepackage{multicol}
%\usepackage[color=True, allcoloring=blue]{hyperref}

%\usepackage{times}


\pgfpagesdeclarelayout{boxed}
{
	\edef\pgfpageoptionborder{0pt}
}
{
	\pgfpagesphysicalpageoptions
	{%
		logical pages=1,%
	}
	\pgfpageslogicalpageoptions{1}
	{
		border code=\pgfsetlinewidth{2pt}\pgfstroke,%
		border shrink=\pgfpageoptionborder,%
		resized width=.9\pgfphysicalwidth,%
		resized height=.9\pgfphysicalheight,%
		center=\pgfpoint{.5\pgfphysicalwidth}{.5\pgfphysicalheight}%
	}%
}

\pagestyle{empty}

\pgfpagesuselayout{boxed}


% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[a4paper,top=2cm,bottom=1.5cm,left=1.5cm,right=1.5cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=black]{hyperref}

\title{}
\author{}
\date{}

%Sets the margins

\textwidth = 7.5 in
\textheight = 9.5 in
\oddsidemargin = -0.7 in
\evensidemargin = -0.3 in
\topmargin = -0.3 in
\headheight = 0.0 in
\headsep = 0.0 in
\parskip = 0.1in
\parindent = 0.0in

\begin{document}

\pgfpagesphysicalpageoptions
{
	logical pages=1,%
}
\pgfpageslogicalpageoptions{1}
{
	border code=\pgfsetlinewidth{2pt}\pgfstroke,%
	border shrink=\pgfpageoptionborder,%
	resized width=.9\pgfphysicalwidth,%
	resized height=.9\pgfphysicalheight,%
	center=\pgfpoint{.5\pgfphysicalwidth}{.5\pgfphysicalheight}%
}%

\pagestyle{empty}

\begin{multicols}{3}

    \footnotesize
    \textbf{ REPUBLIQUE DU CAMEROUN}
    
    \textbf{ Paix-Travail-Patrie}
    
    \textbf{ UNIVERSITE DE YAOUNDE 1}
    
    \textbf{ DEPARTEMENT  }
    
    \textbf{ D'INFORMATIQUE }
    
    \textbf{ BP/P.O.Box 812 }
    
    \textbf{ Yaounde-Cameroun}
    

    \includegraphics[width=6cm,height=6cm]{logo-.png}
    
    
    \hfill \textbf{REPUBLIC OF CAMEROON}
    
    \hfill \textbf{Peace-Work-Fatherland}
    
    \hfill \textbf{UNIVERSITY OF YAOUNDE 1}
    
    \hfill \textbf{COMPUTER SCIENCES }
    
    \hfill \textbf{ DEPARTMENT}
    
    \hfill \textbf{ BP/P.O.Box 812 }
    
    \hfill \textbf{ Yaounde-Cameroun}

\end{multicols}

\begin{center}
			\vspace*{3cm}
			
			\Huge
			\textbf{Methode explicable basee sur les auto-encodeurs pour la detection des anomalies dans les flux de donnees
}
			
			\vspace{0.3cm}
			
			\Huge
            \vspace{3cm}
			
		\end{center}
  \Large
		\begin{tabbing}
			\hspace*{1em}\= \hspace*{10em} \= \kill % set the tabbings
			\> \textbf{Noms et prénoms}\> : NAKAM YOPDUP MANUELLA KRISTEVA \\
			\> \textbf{Matricule}\>  : 19M2233 \\
			\> \textbf{Niveau}\>  : Master 2  \\
			\> \textbf{Spécialité}  \> : Sciences de Données(DS) \\
            \> \textbf{Encadreur}  \> : Pr Norbert TSOPZE
		\end{tabbing}
  \vspace{1.5cm}

        \hfill \textbf{Superviseur:} Pr Roger ETOUNDI ATSA 

        \vspace{1.5cm}
       
	
	\pagebreak
 

	\large 


\tableofcontents

\pagebreak

\section{Domaine de recherche}

Un domaine de recherche est un champ d'étude spécifique qui est traité par les chercheurs. Il est généralement défini par un ensemble de questions ou de problèmes qui sont étudiés, ainsi que par les méthodes et les techniques utilisées pour les étudier. il existe plusieurs domaines de recherche mais dans la suite de notre devoir nous nous interesserons au domaine des sciences de donnees. 

Les sciences des données constituent un domaine interdisciplinaire qui combine des éléments des sciences naturelles, des sciences sociales, de l'ingénierie et des mathématiques. Les sciences des données se concentrent sur l'étude, l'analyse et l'interprétation des données.

\subsection{Bases scientifiques des sciences de donnees }

Afin d'exceller dans le domaine des sciences de donnees, des connaissances fondamentales  sont nécessaires pour comprendre et pratiquer ce domaine. Entre autre on peut citer:

\begin{itemize}
\item \textbf{La théorie des probabilités} est utilisée pour modéliser l'incertitude et la variabilité des données.
\item \textbf{La statistique} est utilisée pour analyser les données et en tirer des conclusions. Les statistiques jouent un rôle fondamental dans les sciences des données. Elles fournissent les méthodes et les outils nécessaires pour collecter, analyser et interpréter les données. Les concepts statistiques tels que la probabilité, l'échantillonnage, l'estimation et les tests d'hypothèses sont utilisés pour prendre des décisions basées sur les données.
\item \textbf{L'apprentissage automatique} est utilisé pour développer des modèles qui peuvent apprendre à partir des données. L'apprentissage automatique est une branche des sciences des données qui implique la construction de modèles et d'algorithmes qui permettent aux ordinateurs d'apprendre à partir des données. Les bases statistiques et mathématiques sont utilisées pour développer des modèles d'apprentissage automatique, tandis que l'informatique fournit les outils et les infrastructures nécessaires pour entraîner et déployer ces modèles.
\item \textbf{Informatique} : Les sciences des données reposent fortement sur les compétences en informatique. La programmation est essentielle pour manipuler et analyser les données à grande échelle. Des langages de programmation tels que Python, R et SQL sont couramment utilisés. Les bases de données, les systèmes de gestion de bases de données et les compétences en ingénierie logicielle sont également nécessaires pour gérer efficacement les flux de données et développer des systèmes d'analyse robustes.
\item \textbf{Domaine d'application spécifique} : Les sciences des données reposent souvent sur des connaissances spécialisées dans un domaine d'application spécifique. Par exemple, la bioinformatique, la finance, la médecine, le marketing ou l'ingénierie peuvent nécessiter des connaissances spécialisées pour comprendre les données et développer des modèles appropriés.
\end{itemize}

\subsection{Types de recherche en sciences de donnees }

La recherche en sciences des données est un domaine en pleine croissance, avec de nombreuses opportunités de recherche dans une grande variété de domaines.La recherche en sciences des données peut être classée de différentes manières, en fonction \textbf{de l'approche, de l'objectif ou du domaine d'application}.

En fonction de \textbf{l'approche}, la recherche en sciences des données peut être divisée en deux catégories principales :

\begin{itemize}
\item \textbf{La recherche fondamentale} vise à développer de nouvelles connaissances sur les données et les méthodes d'analyse des données. Elle est généralement menée par des universitaires dans des laboratoires de recherche.
\item \textbf{La recherche appliquée} vise à résoudre des problèmes concrets à l'aide des données. Elle est généralement menée par des entreprises, des organisations publiques ou des organismes de recherche appliquée.
\end{itemize}


En fonction de \textbf{l'objectif}, la recherche en sciences des données peut être divisée en deux catégories principales :

\begin{itemize}
\item \textbf{La recherche exploratoire} vise à comprendre les données et à identifier des tendances ou des schémas. Elle est généralement utilisée pour orienter la recherche future.
\item \textbf{La recherche confirmatoire} vise à tester des hypothèses ou à valider des modèles. Elle est généralement utilisée pour prendre des décisions ou pour développer des applications.
\end{itemize}


En fonction du \textbf{domaine d'application}, la recherche en sciences des données peut être divisée en de nombreuses sous-catégories, telles que :

\begin{itemize}
\item \textbf{La recherche en santé} utilise les données pour améliorer la prévention, le diagnostic et le traitement des maladies.
\item \textbf{La recherche en finance} utilise les données pour prendre des décisions d'investissement et de gestion des risques.
\item \textbf{La recherche en marketing} utilise les données pour comprendre les comportements des consommateurs et pour développer des stratégies marketing efficaces.
\item \textbf{La recherche en sécurité} utilise les données pour détecter les menaces et les incidents de sécurité.
\end{itemize}



\subsection{Methodologie de recherche en sciences de donnees }

La méthodologie de recherche en sciences des données implique une approche systématique pour mener des études et des projets de recherche basés sur les données. Bien que la méthodologie puisse varier en fonction du contexte spécifique et des objectifs de recherche. De maniere generale la méthodologie de recherche en sciences des données comprend généralement les étapes suivantes :

\begin{itemize}
\item \textbf{Définition du problème de recherche:}
La première étape consiste à définir le problème de recherche. Cela implique de clarifier la question de recherche, de préciser les objectifs de la recherche et d'identifier les données et les méthodes d'analyse nécessaires.

\item \textbf{Collecte des données:}
La deuxième étape consiste à collecter les données. Les données peuvent être collectées à partir de diverses sources, telles que des bases de données, des enquêtes, des observations ou des expériences.

\item \textbf{Nettoyage des données :}
Une fois que les données ont été collectées, elles doivent être nettoyées. Cela implique de corriger les erreurs, de supprimer les données aberrantes et de formater les données de manière à ce qu'elles soient prêtes pour l'analyse.

\item \textbf{Sélection des méthodes et des modèles} : Sélectionnez les méthodes et les modèles d'analyse appropriés en fonction de la nature de votre problème de recherche. Cela peut inclure des techniques de statistiques, d'apprentissage automatique, de fouille de données, de modélisation prédictive ou d'autres approches analytiques.

\item \textbf{Analyse des données :}
La quatrième étape consiste à analyser les données. L'analyse des données peut être réalisée à l'aide de diverses méthodes, telles que l'analyse statistique, l'apprentissage automatique ou l'intelligence artificielle.

\item \textbf{Interprétation des résultats :}
La cinquième étape consiste à interpréter les résultats de l'analyse des données. Cela implique de tirer des conclusions sur les données et de les mettre en relation avec le problème de recherche.

\item \textbf{Communication des résultats :}
La sixième étape consiste à communiquer les résultats de la recherche. Cela peut être fait à travers des publications scientifiques, des conférences ou des rapports.
\end{itemize}
La méthodologie de recherche en sciences des données est un processus flexible qui peut être adapté aux besoins spécifiques de chaque projet de recherche. 

\subsection{Les grands noms du domaine}

Le domaine des sciences des données est vaste et en constante évolution, et de nombreux experts ont contribué de manière significative à son développement. Voici quelques-uns des pionniers du domaine des sciences des données :

\begin{itemize}
\item \textbf{Geoffrey Hinton} : Geoffrey Hinton est considéré comme l'un des pionniers de l'apprentissage profond (deep learning). Ses travaux sur les réseaux de neurones artificiels ont grandement contribué à l'avancement de l'intelligence artificielle et de l'apprentissage automatique.

\item \textbf{Yann LeCun} : Yann LeCun est un chercheur en intelligence artificielle et directeur de l'AI Research chez Facebook. Il est connu pour ses contributions dans le domaine de la vision par ordinateur et de l'apprentissage profond, notamment pour avoir développé le concept des réseaux de neurones convolutifs (CNN).

\item \textbf{Andrew Ng} : Andrew Ng est un chercheur et entrepreneur spécialisé dans le domaine de l'apprentissage automatique. Il a cofondé Google Brain et a été l'un des cofondateurs de Coursera. Ses travaux ont contribué à populariser l'apprentissage automatique et à rendre les connaissances en sciences des données plus accessibles grâce à des cours en ligne.

\item \textbf{Judea Pearl} : Judea Pearl est un informaticien et philosophe reconnu pour ses travaux fondamentaux sur le raisonnement causal et les réseaux bayésiens. Ses contributions ont permis d'élargir les capacités de la modélisation causale dans les sciences des données.

\item \textbf{DJ Patil} : DJ Patil est un data scientist et entrepreneur qui a joué un rôle clé dans la popularisation du terme "scientifique des données". Il a occupé le poste de Chief Data Scientist des États-Unis sous l'administration Obama et a contribué à promouvoir l'utilisation des données pour la prise de décisions dans divers domaines.

\item \textbf{Fei-Fei Li }: Fei-Fei Li est une chercheuse en intelligence artificielle et vision par ordinateur. Elle a joué un rôle important dans le développement de méthodes d'apprentissage profond pour la reconnaissance d'images et a contribué à la création de la base de données d'images ImageNet, qui a été largement utilisée dans le domaine de la vision par ordinateur.

\item \textbf{Hadley Wickham} : Hadley Wickham est un statisticien et programmeur renommé, connu pour ses contributions majeures dans le domaine de l'analyse de données et de la visualisation. Il a développé des packages populaires tels que ggplot2 et dplyr en langage de programmation R, qui sont largement utilisés par les scientifiques des données.

\end{itemize}

Nous avons aussi des grands noms plus recents tels que:

\begin{itemize}
\item \textbf{Andrew Ng} est un informaticien américain qui est considéré comme l'un des pionniers de l'apprentissage profond. Il a cofondé Coursera, une plateforme d'apprentissage en ligne, et a été nommé directeur de l'intelligence artificielle chez Baidu.
\item \textbf{Ilya Sutskever} est un informaticien russe qui est également un pionnier de l'apprentissage profond. Il a cofondé OpenAI, une organisation à but non lucratif dédiée à la recherche et au développement de l'intelligence artificielle, et a été directeur de l'intelligence artificielle chez Tesla.
\item \textbf{Yann LeCun} est un informaticien français qui est également un pionnier de l'apprentissage profond. Il est professeur d'informatique à l'Université de New York et directeur du laboratoire de vision et de reconnaissance de formes.
Quoc Le est un informaticien américain qui est un expert en apprentissage automatique et en traitement du langage naturel. Il est directeur de l'ingénierie chez Google AI.
\item \textbf{Timnit Gebru} est une informaticienne éthiopienne-américaine qui est une experte en apprentissage automatique et en justice sociale. Elle est cofondatrice de Black in AI, une organisation qui vise à promouvoir la diversité et l'inclusion dans le domaine de l'intelligence artificielle.
\item \textbf{Kaggle Community} : Bien que ce ne soit pas une personne spécifique, la communauté Kaggle a joué un rôle majeur dans le domaine des sciences des données depuis 2010. Kaggle est une plateforme en ligne populaire qui héberge des compétitions de science des données et permet aux chercheurs de partager des ensembles de données, de collaborer et de repousser les limites de l'apprentissage automatique.
\end{itemize}

\subsection{Conferences et journaux dans le domaine de la data sciences}

Il existe plusieurs conférences et journaux renommés dans le domaine des sciences des données. Voici quelques exemples parmi les plus influents :

\textbf{Conférences :}

\begin{itemize}

\item \textbf{Conference on Neural Information Processing Systems (NeurIPS)} : NeurIPS est l'une des principales conférences en apprentissage automatique et en intelligence artificielle. Elle rassemble des chercheurs, des praticiens et des experts du monde entier pour présenter et discuter des dernières avancées dans le domaine.

\item \textbf{International Conference on Machine Learning (ICML)} : L'ICML est une conférence de premier plan en apprentissage automatique qui se concentre sur la présentation de travaux de recherche novateurs et sur l'échange d'idées entre les scientifiques des données.

\item \textbf{International Conference on Data Mining (ICDM)} : L'ICDM est une conférence de premier plan en fouille de données et en extraction de connaissances à partir de grandes bases de données. Elle rassemble des chercheurs et des praticiens pour partager leurs travaux sur les techniques, les méthodologies et les applications de l'exploration de données.

\item \textbf{International Conference on Very Large Data Bases (VLDB)} : VLDB est une conférence majeure dans le domaine des bases de données et de la gestion de données à grande échelle. Elle offre une plateforme pour présenter des recherches sur les systèmes de gestion de bases de données, l'analyse de données et les applications liées aux mégadonnées.

\item \textbf{ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)} : KDD est une conférence de premier plan en science des données et en fouille de données. Elle explore les dernières avancées dans les domaines de la découverte de connaissances, de l'apprentissage automatique et de l'exploration de données.

\item \textbf{ACM SIGAI Conference on Artificial Intelligence (AAAI)} : La conférence AAAI sur l'intelligence artificielle (AAAI) est une conférence internationale de premier plan consacrée à l'avancement de la recherche sur l'intelligence artificielle (IA). Organisée chaque année par l'Association for the Advancement of Artificial Intelligence (AAAI), elle est considérée comme l'une des conférences les plus prestigieuses dans le domaine de l'IA. Elle aborde les sujets suivants : Apprentissage automatique (Machine Learning),
Apprentissage profond (Deep Learning),
Vision par ordinateur (Computer Vision),
Traitement automatique du langage naturel (Natural Language Processing),
Raisonnement et planification (Reasoning and Planning),
Robotique et agents autonomes (Robotics and Autonomous Agents),
Apprentissage par renforcement (Reinforcement Learning) et 
Éthique de l'IA (AI Ethics).

\end{itemize}

\textbf{Journaux :}

\begin{itemize}
\item \textbf{Journal of Machine Learning Research (JMLR)} : JMLR est un journal en accès libre qui publie des articles de recherche originaux dans le domaine de l'apprentissage automatique et de l'intelligence artificielle. Il est considéré comme l'un des journaux les plus prestigieux dans le domaine de l'apprentissage automatique.

\item \textbf{IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)} : TPAMI est un journal de l'IEEE qui se concentre sur la publication d'articles de recherche sur la vision par ordinateur, la reconnaissance de formes et l'analyse d'images.

\item \textbf{Data Mining and Knowledge Discovery (DMKD)} : DMKD est un journal qui couvre les aspects théoriques et pratiques de la fouille de données, de l'extraction de connaissances et de l'exploration de données.

\item \textbf{Journal of Big Data} : Ce journal se concentre sur la publication d'articles de recherche sur les défis et les opportunités liés aux données massives (big data), y compris les méthodologies, les outils et les applications.

\item \textbf{ACM Transactions on Knowledge Discovery from Data (TKDD)} : TKDD est un journal qui couvre les aspects de la découverte de connaissances à partir des données, y compris les algorithmes, les modèles, les méthodologies et les applications.

\item \textbf{Knowledge and Information Systems (KAIS)} :est une revue scientifique internationale à comité de lecture publiée par Springer Nature. Elle est consacrée à la recherche sur les systèmes de connaissance et d'information.

\item \textbf{L'ACM Transactions on Intelligent Systems and Technology (TIST) } : est une revue scientifique internationale à comité de lecture publiée par l'Association for Computing Machinery (ACM). Elle est consacrée à la recherche et à la pratique des systèmes intelligents et de la technologie.

\item \textbf{IEEE Transactions on Knowledge and Data Engineering (TKDE)} : est une revue scientifique internationale à comité de lecture publiée par l'Institute of Electrical and Electronics Engineers (IEEE). Elle est considérée comme l'une des principales revues dans le domaine des sciences des données et de l'ingénierie des connaissances.

\end{itemize}

\section{Les axes de recherche}

\subsection{Les differents axes de recherche}

En data science, il existe plusieurs axes de recherche qui englobent un large éventail de domaines et de sujets. Voici quelques-uns des principaux axes de recherche :
\begin{itemize}
\item     \textbf{Apprentissage automatique et apprentissage profond} : Cette branche explore les algorithmes et les modèles pour permettre aux ordinateurs d'apprendre à partir de données et de prendre des décisions sans être explicitement programmés.

\item     \textbf{Analyse de données massives (Big Data)} : Ce domaine se concentre sur les méthodes, les outils et les infrastructures pour gérer, traiter et analyser des ensembles de données massives et complexes.

\item     \textbf{Recherche sur les réseaux neuronaux} : Étude approfondie des architectures, des méthodes d'entraînement et des applications des réseaux neuronaux, y compris les réseaux convolutifs, récurrents et d'autres architectures avancées.

 \item    \textbf{Visualisation de données} : Cette discipline cherche à développer des méthodes pour représenter visuellement des données complexes de manière à en extraire des informations significatives et à faciliter la prise de décision.

\item     \textbf{Exploration de données (Data Mining) }: L'exploration de données vise à découvrir des schémas, des tendances ou des relations significatives au sein de grands ensembles de données pour en tirer des informations utiles.

\item     \textbf{Analyse prédictive} : Utilisation de techniques statistiques et d'apprentissage automatique pour prévoir des événements futurs ou des tendances en se basant sur des données historiques.

\item     \textbf{Sécurité et confidentialité des données} : Cette recherche se concentre sur la protection des données sensibles contre les accès non autorisés, les atteintes à la vie privée et les cybermenaces.

\item     \textbf{Traitement du langage naturel (NLP)} : Cette branche se focalise sur le développement de modèles et d'algorithmes pour permettre aux ordinateurs de comprendre, interpréter et générer un langage humain.

\item     \textbf{Optimisation et apprentissage par renforcement} : Cette recherche porte sur le développement d'algorithmes permettant de prendre des décisions séquentielles dans des environnements complexes pour atteindre des objectifs spécifiques.

\item     \textbf{Data Science éthique et responsable} : Un domaine émergeant qui se concentre sur l'éthique de la collecte, de l'utilisation et de la diffusion des données, ainsi que sur les implications sociales de l'analyse des 
données.

\item \textbf{Vision par ordinateur (Computer Vision)} : Il s'agit d'un domaine de recherche qui se concentre sur l'analyse, l'interprétation et la compréhension des images et des vidéos par les machines. Cela comprend la reconnaissance d'objets, la détection de motifs, la segmentation d'images, etc.

\end{itemize}

Ces axes de recherche en data science ne sont pas exhaustifs et peuvent souvent se chevaucher. De plus, de nouvelles branches émergent constamment à mesure que la discipline évolue et que de nouveaux défis se présentent.



\subsection{Axe de recherche choisi}


Apres avoir fait les cours fouille de donnees en Master 1 je me suis interessee aux flux de donnees et en particulier a la detection d'anomalies dans les flux de donnees . J'ai donc lu de nombreux articles sur le sujet tel que:  

\begin{itemize}
\item \textbf{Review of Anomaly Detection Algorithms for Data Streams, Tianyuan Lu, Lei Wang * and Xiaoyong Zhao}\cite{1}: explore les principaux défis liés à la détection d'anomalies dans les flux de données, tels que la nature dynamique des données, la limitation des ressources et la nécessité de détecter rapidement les anomalies.
\item \textbf{DeepStream: Autoencoder-Based Stream Temporal Clustering and Anomaly Detection, Shimon Harush, Yair Meidan, Asaf Shabtai}\cite{2} : présente une méthode novatrice appelée DeepStream, qui utilise des autoencodeurs pour la détection d'anomalies et le regroupement temporel dans les flux de données.
\item  \textbf{Méthodes parallèles pour le traitement des flux de données continus, Mme Ge Song}\cite{3}  : travaille sur les méthodes parallèles pour le traitement des flux de données continus. 
\item \textbf{Détection d’anomalies dans les flux de données par structure d’indexation et approximation : Application à l’analyse en continu des flux de messages du système d’information de la SNCF, Lucas Foulon}\cite{4}  : semble proposer une approche qui combine la structure d'indexation et l'approximation pour détecter les anomalies dans les flux de messages du système d'information de la SNCF.
\item \textbf{Anomaly Detection of Time Series with Smoothness-Inducing Sequential Variational Auto-Encoder}\cite{5}  : présente une approche novatrice pour la détection d'anomalies dans les séries temporelles. Les auteurs proposent l'utilisation d'un auto-encodeur variationnel séquentiel (Sequential Variational Auto-Encoder, SVAE) qui intègre une régularisation favorisant la régularité et la continuité des séries temporelles.
\end{itemize}

C'est donc sur l'article \textbf{Anomaly Detection of Time Series with Smoothness-Inducing Sequential Variational Auto-Encoder,Longyuan Li, Junchi Yan, Member, IEEE,, Haiyang Wang, and Yaohui Jin Member, IEEE,} que j'ai decide de m'appuyer avec les conseils de Dr Jiechieu Florentin. Cet artvcle traitant sur les auto-encodeurs; l'axe de recherche choisis est donc : \textbf{l'apprentissage automatique}

\section{Justification du theme}

Le theme qui m'a ete propose est: \textbf{Methode explicable basee sur les auto-encodeurs pour la detection des anomalies dans les flux de donnees}

\subsection{Definitions de concepts}

\begin{itemize}
\item \textbf{Auto-encodeurs}: sont une forme de réseau de neurones utilisés pour apprendre des représentations efficaces des données en tentant de reconstruire les entrées à la sortie. Ils sont composés de deux parties principales : un encodeur et un décodeur. Ils sont souvent utilisés pour \textbf{la compression de données, la détection d'anomalies, la réduction de dimension, la génération de données, etc.}
\item \textbf{Flux de donnees}: est une séquence continue de données qui est générée et traitée de manière continue et progressive. Les flux de données peuvent provenir de diverses sources, telles que \textbf{des capteurs, des transactions, des événements ou des médias sociaux}.
\item \textbf{Anomalies}: se réfèrent à des observations, des comportements ou des événements qui diffèrent significativement du modèle ou du schéma habituel des données. Elles peuvent être \textbf{le résultat d'erreurs, de défauts, de manipulations malveillantes ou simplement de variations inhabituelles dans les données}.
\end{itemize}

\subsection{Objectifs du theme}

il sera donc question tout au long de mon travail de :
\begin{itemize}
\item Trouver un jeu de donnees representant un flux de donnees tels que Apache SPARK :
\item En fonction du contexte du jeu de donnees choisis identifier ce qui est considere comme anomalie
\item On va appliquer l'algorithme de l'article choisi sur notre jeu de donnees
\item On va observer les limites et essayer d'apporter un exemple d'amelioration tout en portant l'interet sur l'explicabilite du modele 
\item On va appliquer la methode proposee sur notre modele et faire des tests
\item Puis on va comparer les resultats
\end{itemize}

\subsection{Les apports du theme}

Tout theme de recherche se veut d'un apport soit pour le domaine de la recherche soit pour la vie courante:
\begin{itemize}
\item  Concernant la recherche, les auto-encodeurs sont generalement des boites noires donc obtenvr une methode explicable est un veritable atout pour faire valider les resultats par un expert et justifier son utilisation.
\item D'autres parts les applications de la detection des anomalies dans les flux de donnees peuvent jouer un role important dans de nombreux domaines( sante, securite, ....)

\end{itemize}

\section{Conclusion}

Le choix d'un theme de recherche demande de suivre un ensemble d'etapes qui sont autant importantes les unes comme les autres. Le but de cette approche est de se rassurer que le projet respecte les normes de la recherche tels que l'axe de recherche. De plus l'importance et l'utilite du theme doivent etre un indispensable dans le choix de celui-ci.

\bibliographystyle{alpha}
\bibliography{sample}


	
	\end{document}

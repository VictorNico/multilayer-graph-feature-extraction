{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcaab6e5-6498-4250-a0f2-afde5b3243a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T22:44:07.489383Z",
     "start_time": "2025-05-12T22:43:58.206293Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries importation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import joblib\n",
    "#import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3503995b-488f-426f-9342-52acf1844507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_classes(df, target_column, min_count=10):\n",
    "    class_counts = df[target_column].value_counts()\n",
    "    rare_classes = class_counts[class_counts < min_count].index\n",
    "    print(f\"[INFO] Classes supprimées (trop rares) : {list(rare_classes)}\")\n",
    "\n",
    "    return df[~df[target_column].isin(rare_classes)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a0090-ddc7-4f2c-9b0d-aa7dcaec3b40",
   "metadata": {},
   "source": [
    "# Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9978d27b38849c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "adult_train_path = \"./datasets/private/multiclass datasets/adult/adult.data\"\n",
    "adult_test_path = \"./datasets/private/multiclass datasets/adult/adult.test\"\n",
    "\n",
    "adult_all_path_out = \"./datasets/private/multiclass datasets/adult/all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da76c287-ba30-4983-bf1d-c9dfcf41ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected delimiter (,)\n"
     ]
    }
   ],
   "source": [
    "# Read a portion of the file to analyze the separator\n",
    "num_lines_to_read = 10\n",
    "\n",
    "# Detect the delimiter\n",
    "with open(adult_train_path, 'r') as file:\n",
    "    sample = file.read(num_lines_to_read)\n",
    "    dialect = csv.Sniffer().sniff(sample)\n",
    "    delimiter = dialect.delimiter\n",
    "    \n",
    "# Print the detected delimiter\n",
    "print(f\"Detected delimiter ({delimiter})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7695399-6093-483b-a4a6-a57303431391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the list of header names\n",
    "adult_names = [\n",
    "    \"age\", \n",
    "    \"workclass\", \n",
    "    \"fnlwgt\", \n",
    "    \"education\", \n",
    "    \"education-num\", \n",
    "    \"marital-status\", \n",
    "    \"occupation\", \n",
    "    \"relationship\", \n",
    "    \"race\", \n",
    "    \"sex\", \n",
    "    \"capital-gain\", \n",
    "    \"capital-loss\", \n",
    "    \"hours-per-week\", \n",
    "    \"native-country\",\n",
    "    \"class\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9854d778-61dc-482e-ad3a-273fb3127f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .dat file using pandas and set the header names\n",
    "df_adult_train = pd.read_csv(adult_train_path, delimiter=delimiter, names=adult_names, index_col=False)\n",
    "df_adult_test = pd.read_csv(adult_test_path, delimiter=delimiter, names=adult_names, index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a013fd56-abf7-4d50-a5a9-af772a439514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K' nan]\n",
      "[' <=50K' ' >50K']\n",
      "[nan ' <=50K.' ' >50K.']\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the two datasets\n",
    "merged_df = pd.concat([df_adult_train, df_adult_test], ignore_index=True)\n",
    "# Remove trailing '.' and trim whitespace\n",
    "merged_df['class'] = merged_df['class'].str.strip().str.rstrip('.')\n",
    "\n",
    "# Show unique values\n",
    "print(merged_df['class'].unique())\n",
    "print(df_adult_train['class'].unique())\n",
    "print(df_adult_test['class'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d2f4d0-5193-4770-aac5-c97fa5e605ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fnlwgt  education-num  capital-gain  capital-loss  hours-per-week\n",
       "count  4.884200e+04   48842.000000  48842.000000  48842.000000    48842.000000\n",
       "mean   1.896641e+05      10.078089   1079.067626     87.502314       40.422382\n",
       "std    1.056040e+05       2.570973   7452.019058    403.004552       12.391444\n",
       "min    1.228500e+04       1.000000      0.000000      0.000000        1.000000\n",
       "25%    1.175505e+05       9.000000      0.000000      0.000000       40.000000\n",
       "50%    1.781445e+05      10.000000      0.000000      0.000000       40.000000\n",
       "75%    2.376420e+05      12.000000      0.000000      0.000000       45.000000\n",
       "max    1.490400e+06      16.000000  99999.000000   4356.000000       99.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8510b620-9e30-4048-a38d-b385f11753cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48842</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48843 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass    fnlwgt   education  education-num  \\\n",
       "0      39          State-gov   77516.0   Bachelors           13.0   \n",
       "1      50   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
       "2      38            Private  215646.0     HS-grad            9.0   \n",
       "3      53            Private  234721.0        11th            7.0   \n",
       "4      28            Private  338409.0   Bachelors           13.0   \n",
       "...    ..                ...       ...         ...            ...   \n",
       "48838  39            Private  215419.0   Bachelors           13.0   \n",
       "48839  64                  ?  321403.0     HS-grad            9.0   \n",
       "48840  38            Private  374983.0   Bachelors           13.0   \n",
       "48841  44            Private   83891.0   Bachelors           13.0   \n",
       "48842  35       Self-emp-inc  182148.0   Bachelors           13.0   \n",
       "\n",
       "            marital-status          occupation     relationship  \\\n",
       "0            Never-married        Adm-clerical    Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial          Husband   \n",
       "2                 Divorced   Handlers-cleaners    Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners          Husband   \n",
       "4       Married-civ-spouse      Prof-specialty             Wife   \n",
       "...                    ...                 ...              ...   \n",
       "48838             Divorced      Prof-specialty    Not-in-family   \n",
       "48839              Widowed                   ?   Other-relative   \n",
       "48840   Married-civ-spouse      Prof-specialty          Husband   \n",
       "48841             Divorced        Adm-clerical        Own-child   \n",
       "48842   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital-gain  capital-loss  \\\n",
       "0                    White     Male        2174.0           0.0   \n",
       "1                    White     Male           0.0           0.0   \n",
       "2                    White     Male           0.0           0.0   \n",
       "3                    Black     Male           0.0           0.0   \n",
       "4                    Black   Female           0.0           0.0   \n",
       "...                    ...      ...           ...           ...   \n",
       "48838                White   Female           0.0           0.0   \n",
       "48839                Black     Male           0.0           0.0   \n",
       "48840                White     Male           0.0           0.0   \n",
       "48841   Asian-Pac-Islander     Male        5455.0           0.0   \n",
       "48842                White     Male           0.0           0.0   \n",
       "\n",
       "       hours-per-week  native-country  class  \n",
       "0                40.0   United-States  <=50K  \n",
       "1                13.0   United-States  <=50K  \n",
       "2                40.0   United-States  <=50K  \n",
       "3                40.0   United-States  <=50K  \n",
       "4                40.0            Cuba  <=50K  \n",
       "...               ...             ...    ...  \n",
       "48838            36.0   United-States  <=50K  \n",
       "48839            40.0   United-States  <=50K  \n",
       "48840            50.0   United-States  <=50K  \n",
       "48841            40.0   United-States  <=50K  \n",
       "48842            60.0   United-States   >50K  \n",
       "\n",
       "[48843 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41d0ea3691305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Class\"\n",
    "stat = merged_df[\"class\"].value_counts()\n",
    "print(stat)\n",
    "merged_df = remove_rare_classes(merged_df, \"class\", min_count=5)\n",
    "stat = df_nursery_train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665e7ae723fb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the class column\n",
    "merged_df['class'] = le.fit_transform(merged_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a18234cd75b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9793399cb718ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61287ce279710fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825cd4f72c8fe7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1382c6b6bef634",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(adult_all_path_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472da3c92816fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"class-encoding\": label_mapping\n",
    "}, adult_all_path_out[:-4]+\".conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8105285a9a995a6",
   "metadata": {},
   "source": [
    "# audiology+standardized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd858d74181283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "audiology_train_path = \"./datasets/private/multiclass datasets/audiology+standardized/audiology.standardized.data\"\n",
    "audiology_test_path = \"./datasets/private/multiclass datasets/audiology+standardized/audiology.standardized.test\"\n",
    "\n",
    "audiology_all_path_out = \"./datasets/private/multiclass datasets/audiology+standardized/all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a96f3f32a48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a portion of the file to analyze the separator\n",
    "num_lines_to_read = 10\n",
    "\n",
    "# Detect the delimiter\n",
    "with open(audiology_train_path, 'r') as file:\n",
    "    sample = file.read(num_lines_to_read)\n",
    "    dialect = csv.Sniffer().sniff(sample)\n",
    "    delimiter = dialect.delimiter\n",
    "    \n",
    "# Print the detected delimiter\n",
    "print(f\"Detected delimiter ({delimiter})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d42f627063c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the list of header names\n",
    "audiology_names = [\n",
    "    \"age_gt_60\",\n",
    "    \"air()\",\n",
    "    \"airBoneGap\",\n",
    "    \"ar_c()\",\n",
    "    \"ar_u()\",\n",
    "    \"bone()\",\n",
    "    \"boneAbnormal\",\n",
    "    \"bser()\",\n",
    "    \"history_buzzing\",\n",
    "    \"history_dizziness\",\n",
    "    \"history_fluctuating\",\n",
    "    \"history_fullness\",\n",
    "    \"history_heredity\",\n",
    "    \"history_nausea\",\n",
    "    \"history_noise\",\n",
    "    \"history_recruitment\",\n",
    "    \"history_ringing\",\n",
    "    \"history_roaring\",\n",
    "    \"history_vomiting\",\n",
    "    \"late_wave_poor\",\n",
    "    \"m_at_2k\",\n",
    "    \"m_cond_lt_1k\",\n",
    "    \"m_gt_1k\",\n",
    "    \"m_m_gt_2k\",\n",
    "    \"m_m_sn\",\n",
    "    \"m_m_sn_gt_1k\",\n",
    "    \"m_m_sn_gt_2k\",\n",
    "    \"m_m_sn_gt_500\",\n",
    "    \"m_p_sn_gt_2k\",\n",
    "    \"m_s_gt_500\",\n",
    "    \"m_s_sn\",\n",
    "    \"m_s_sn_gt_1k\",\n",
    "    \"m_s_sn_gt_2k\",\n",
    "    \"m_s_sn_gt_3k\",\n",
    "    \"m_s_sn_gt_4k\",\n",
    "    \"m_sn_2_3k\",\n",
    "    \"m_sn_gt_1k\",\n",
    "    \"m_sn_gt_2k\",\n",
    "    \"m_sn_gt_3k\",\n",
    "    \"m_sn_gt_4k\",\n",
    "    \"m_sn_gt_500\",\n",
    "    \"m_sn_gt_6k\",\n",
    "    \"m_sn_lt_1k\",\n",
    "    \"m_sn_lt_2k\",\n",
    "    \"m_sn_lt_3k\",\n",
    "    \"middle_wave_poor\",\n",
    "    \"mod_gt_4k\",\n",
    "    \"mod_mixed\",\n",
    "    \"mod_s_mixed\",\n",
    "    \"mod_s_sn_gt_500\",\n",
    "    \"mod_sn\",\n",
    "    \"mod_sn_gt_1k\",\n",
    "    \"mod_sn_gt_2k\",\n",
    "    \"mod_sn_gt_3k\",\n",
    "    \"mod_sn_gt_4k\",\n",
    "    \"mod_sn_gt_500\",\n",
    "    \"notch_4k\",\n",
    "    \"notch_at_4k\",\n",
    "    \"o_ar_c()\",\n",
    "    \"o_ar_u()\",\n",
    "    \"s_sn_gt_1k\",\n",
    "    \"s_sn_gt_2k\",\n",
    "    \"s_sn_gt_4k\",\n",
    "    \"speech()\",\n",
    "    \"static_normal\",\n",
    "    \"tymp()\",\n",
    "    \"viith_nerve_signs\",\n",
    "    \"wave_V_delayed\",\n",
    "    \"waveform_ItoV_prolonged\"\n",
    "] + [\"identifier\", \"class\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e236495631ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .dat file using pandas and set the header names\n",
    "df_audiology_train = pd.read_csv(audiology_train_path, delimiter=delimiter, names=audiology_names, index_col=False, na_values='?')\n",
    "df_audiology_test = pd.read_csv(audiology_test_path, delimiter=delimiter, names=audiology_names, index_col=False, na_values='?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a51e180ecb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two datasets\n",
    "merged_df = pd.concat([df_audiology_train, df_audiology_test], ignore_index=True)\n",
    "# Remove trailing '.' and trim whitespace\n",
    "merged_df['class'] = merged_df['class'].str.strip().str.rstrip('.')\n",
    "\n",
    "# Show unique values\n",
    "print(merged_df['class'].unique())\n",
    "print(df_audiology_train['class'].unique())\n",
    "print(df_audiology_test['class'].unique())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "129048b0afc150f5",
   "metadata": {},
   "source": [
    "# Affichage des dimensions initiales et du nombre de valeurs manquantes\n",
    "print(\"Taille initiale :\", merged_df.shape)\n",
    "print(\"Valeurs manquantes par colonne :\")\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Détection automatique du type de colonnes\n",
    "for col in merged_df.columns:\n",
    "    if merged_df[col].dtype == 'object':\n",
    "        # Imputation par le mode pour les colonnes catégorielles\n",
    "        mode = merged_df[col].mode(dropna=True)\n",
    "        if not mode.empty:\n",
    "            merged_df[col].fillna(mode[0], inplace=True)\n",
    "    else:\n",
    "        # Imputation par la moyenne pour les colonnes numériques\n",
    "        merged_df[col].fillna(merged_df [col].mean(), inplace=True)\n",
    "\n",
    "# Vérification finale\n",
    "print(\"\\nValeurs manquantes restantes :\")\n",
    "print(merged_df.isnull().sum().sum())  # Doit être 0\n",
    "\n",
    "# Sauvegarder si besoin\n",
    "# df.to_csv(\"audiology_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb6ba7995028cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c68e6de7601e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185fccdabc04ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67639be49394e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d8ed41e4d806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933734d51d58355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Class\"\n",
    "stat = merged_df[\"class\"].value_counts()\n",
    "print(stat)\n",
    "merged_df = remove_rare_classes(merged_df, \"class\", min_count=5)\n",
    "stat = df_nursery_train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a3de0a2cc1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the class column\n",
    "merged_df['class'] = le.fit_transform(merged_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5d7a4cf4fbc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba71f8d555ce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402117c1b6fb4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a076f2320b6a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(audiology_all_path_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633184953d7b47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"class-encoding\": label_mapping\n",
    "}, audiology_all_path_out[:-4]+\".conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8257fc5eb74ca",
   "metadata": {},
   "source": [
    "# car+evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6686107dc9e6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "car_train_path = \"./datasets/private/multiclass datasets/car+evaluation/car.data\"\n",
    "\n",
    "car_all_path_out = \"./datasets/private/multiclass datasets/car+evaluation/all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb8349220cc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a portion of the file to analyze the separator\n",
    "num_lines_to_read = 10\n",
    "\n",
    "# Detect the delimiter\n",
    "with open(car_train_path, 'r') as file:\n",
    "    sample = file.read(num_lines_to_read)\n",
    "    dialect = csv.Sniffer().sniff(sample)\n",
    "    delimiter = dialect.delimiter\n",
    "    \n",
    "# Print the detected delimiter\n",
    "print(f\"Detected delimiter ({delimiter})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c49efe677cac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_names = [\n",
    "    \"buying\",\n",
    "    \"maint\",\n",
    "    \"doors\",\n",
    "    \"persons\",\n",
    "    \"lug_boot\",\n",
    "    \"safety\"\n",
    "] + [ \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a62370363ec6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .dat file using pandas and set the header names\n",
    "df_car_train = pd.read_csv(car_train_path, delimiter=delimiter, names=car_names, index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0448a665fe14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ead6996520248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a674a409b6805b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a64b027c7b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Class\"\n",
    "stat = df_car_train[\"class\"].value_counts()\n",
    "print(stat)\n",
    "df_car_train = remove_rare_classes(df_car_train, \"class\", min_count=5)\n",
    "print(df_car_train[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11479a8a52d867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the class column\n",
    "df_car_train['class'] = le.fit_transform(df_car_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be0e0ad1335f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b3283ffea2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2741829e4c93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car_train.to_csv(car_all_path_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc370b3ffbeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"class-encoding\": label_mapping\n",
    "}, car_all_path_out[:-4]+\".conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b9a90fadf2487",
   "metadata": {},
   "source": [
    "# diabetes+130-us+hospitals+for+years+1999-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f9a2101582a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "diab130_train_path = \"./datasets/private/multiclass datasets/diabetes+130-us+hospitals+for+years+1999-2008/diabetic_data.csv\"\n",
    "diab130IDS_train_path = \"./datasets/private/multiclass datasets/diabetes+130-us+hospitals+for+years+1999-2008/diabetic_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0ea3cfeceab7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1w/cp3gd6d5749_6bq40_6_35vh0000gn/T/ipykernel_19588/511890330.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_diab130_train = pd.read_csv(diab130_train_path, delimiter=',', index_col=False, na_values='?')\n"
     ]
    }
   ],
   "source": [
    "# Read the .dat file using pandas and set the header names\n",
    "df_diab130_train = pd.read_csv(diab130_train_path, delimiter=',', index_col=False, na_values='?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8fb6d-6178-4452-9a91-b17e0e5093d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12db1d1-9b8d-4c20-8e53-51e45ffb0ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b643316aa6bd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101761</th>\n",
       "      <td>443847548</td>\n",
       "      <td>100162476</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101762</th>\n",
       "      <td>443847782</td>\n",
       "      <td>74694222</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101763</th>\n",
       "      <td>443854148</td>\n",
       "      <td>41088789</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101764</th>\n",
       "      <td>443857166</td>\n",
       "      <td>31693671</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101765</th>\n",
       "      <td>443867222</td>\n",
       "      <td>175429310</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101766 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0            2278392      8222157        Caucasian  Female   [0-10)    NaN   \n",
       "1             149190     55629189        Caucasian  Female  [10-20)    NaN   \n",
       "2              64410     86047875  AfricanAmerican  Female  [20-30)    NaN   \n",
       "3             500364     82442376        Caucasian    Male  [30-40)    NaN   \n",
       "4              16680     42519267        Caucasian    Male  [40-50)    NaN   \n",
       "...              ...          ...              ...     ...      ...    ...   \n",
       "101761     443847548    100162476  AfricanAmerican    Male  [70-80)    NaN   \n",
       "101762     443847782     74694222  AfricanAmerican  Female  [80-90)    NaN   \n",
       "101763     443854148     41088789        Caucasian    Male  [70-80)    NaN   \n",
       "101764     443857166     31693671        Caucasian  Female  [80-90)    NaN   \n",
       "101765     443867222    175429310        Caucasian    Male  [70-80)    NaN   \n",
       "\n",
       "        admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                       6                        25                    1   \n",
       "1                       1                         1                    7   \n",
       "2                       1                         1                    7   \n",
       "3                       1                         1                    7   \n",
       "4                       1                         1                    7   \n",
       "...                   ...                       ...                  ...   \n",
       "101761                  1                         3                    7   \n",
       "101762                  1                         4                    5   \n",
       "101763                  1                         1                    7   \n",
       "101764                  2                         3                    7   \n",
       "101765                  1                         1                    7   \n",
       "\n",
       "        time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                      1  ...          No      No                   No   \n",
       "1                      3  ...          No      Up                   No   \n",
       "2                      2  ...          No      No                   No   \n",
       "3                      2  ...          No      Up                   No   \n",
       "4                      1  ...          No  Steady                   No   \n",
       "...                  ...  ...         ...     ...                  ...   \n",
       "101761                 3  ...          No    Down                   No   \n",
       "101762                 5  ...          No  Steady                   No   \n",
       "101763                 1  ...          No    Down                   No   \n",
       "101764                10  ...          No      Up                   No   \n",
       "101765                 6  ...          No      No                   No   \n",
       "\n",
       "        glipizide-metformin  glimepiride-pioglitazone  \\\n",
       "0                        No                        No   \n",
       "1                        No                        No   \n",
       "2                        No                        No   \n",
       "3                        No                        No   \n",
       "4                        No                        No   \n",
       "...                     ...                       ...   \n",
       "101761                   No                        No   \n",
       "101762                   No                        No   \n",
       "101763                   No                        No   \n",
       "101764                   No                        No   \n",
       "101765                   No                        No   \n",
       "\n",
       "        metformin-rosiglitazone  metformin-pioglitazone  change diabetesMed  \\\n",
       "0                            No                      No      No          No   \n",
       "1                            No                      No      Ch         Yes   \n",
       "2                            No                      No      No         Yes   \n",
       "3                            No                      No      Ch         Yes   \n",
       "4                            No                      No      Ch         Yes   \n",
       "...                         ...                     ...     ...         ...   \n",
       "101761                       No                      No      Ch         Yes   \n",
       "101762                       No                      No      No         Yes   \n",
       "101763                       No                      No      Ch         Yes   \n",
       "101764                       No                      No      Ch         Yes   \n",
       "101765                       No                      No      No          No   \n",
       "\n",
       "       readmitted  \n",
       "0              NO  \n",
       "1             >30  \n",
       "2              NO  \n",
       "3              NO  \n",
       "4              NO  \n",
       "...           ...  \n",
       "101761        >30  \n",
       "101762         NO  \n",
       "101763         NO  \n",
       "101764         NO  \n",
       "101765         NO  \n",
       "\n",
       "[101766 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diab130_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e69a7-2f04-4edc-a87b-9f33cee49714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b413b-aa55-4676-95d1-66c3e80e4453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c52b70-e461-4a99-811f-a73cd18d0b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight',\n",
       "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'time_in_hospital', 'payer_code', 'medical_specialty',\n",
       "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
       "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
       "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
       "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
       "       'glyburide-metformin', 'glipizide-metformin',\n",
       "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
       "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diab130_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914cb8e-082f-425c-84d4-ee32989b7fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf34913111819c77",
   "metadata": {},
   "source": [
    "# mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a20d0edf608fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "mushroom_train_path = \"./datasets/private/multiclass datasets/mushroom/agaricus-lepiota.data\"\n",
    "\n",
    "\n",
    "mushroom_train_path_out = \"./datasets/private/multiclass datasets/mushroom/all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6031ed70e33326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a portion of the file to analyze the separator\n",
    "num_lines_to_read = 10\n",
    "\n",
    "# Detect the delimiter\n",
    "with open(mushroom_train_path, 'r') as file:\n",
    "    sample = file.read(num_lines_to_read)\n",
    "    dialect = csv.Sniffer().sniff(sample)\n",
    "    delimiter = dialect.delimiter\n",
    "    \n",
    "# Print the detected delimiter\n",
    "print(f\"Detected delimiter ({delimiter})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3369cb5aebee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_names = [\"class\"] + [\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"population\",\n",
    "    \"habitat\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51789b6db1c50397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .data file using pandas and set the header names\n",
    "df_mushroom_train = pd.read_csv(mushroom_train_path, delimiter=delimiter, names=mushroom_names, index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7ad1d5a620423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mushroom_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b258321bb3caf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mushroom_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467a04d2915b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mushroom_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755854b9972ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Class\"\n",
    "stat = df_mushroom_train[\"class\"].value_counts()\n",
    "print(stat)\n",
    "df_mushroom_train = remove_rare_classes(df_mushroom_train, \"class\", min_count=5)\n",
    "print(df_mushroom_train[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c06d89d5d08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the class column\n",
    "df_mushroom_train['class'] = le.fit_transform(df_mushroom_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54aecccbc4a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bfd1ba9a511694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mushroom_train.to_csv(mushroom_train_path_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632917d76ce1cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"class-encoding\": label_mapping\n",
    "}, mushroom_train_path_out[:-4]+\".conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b43ce63c46b5",
   "metadata": {},
   "source": [
    "# nursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc95de461b8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "nursery_train_path = \"./datasets/private/multiclass datasets/nursery/nursery.data\"\n",
    "\n",
    "\n",
    "nursery_train_path_out = \"./datasets/private/multiclass datasets/nursery/all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a18a1e53901de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a portion of the file to analyze the separator\n",
    "num_lines_to_read = 10\n",
    "\n",
    "# Detect the delimiter\n",
    "with open(nursery_train_path, 'r') as file:\n",
    "    sample = file.read(num_lines_to_read)\n",
    "    dialect = csv.Sniffer().sniff(sample)\n",
    "    delimiter = dialect.delimiter\n",
    "    \n",
    "# Print the detected delimiter\n",
    "print(f\"Detected delimiter ({delimiter})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a983f27fcc0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nursery_names = [\n",
    "    \"parents\",\n",
    "    \"has_nurs\",\n",
    "    \"form\",\n",
    "    \"children\",\n",
    "    \"housing\",\n",
    "    \"finance\",\n",
    "    \"social\",\n",
    "    \"health\"\n",
    "] +  [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c556a396b245297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .data file using pandas and set the header names\n",
    "df_nursery_train = pd.read_csv(nursery_train_path, delimiter=delimiter, names=nursery_names, index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705950dd6f933923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nursery_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3170336040f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nursery_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b793bb29ae45eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nursery_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1cc5e4c6bf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Class\"\n",
    "stat = df_nursery_train[\"class\"].value_counts()\n",
    "print(stat)\n",
    "df_nursery_train = remove_rare_classes(df_nursery_train, \"class\", min_count=5)\n",
    "print(df_nursery_train[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7867cce3b87859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the class column\n",
    "df_nursery_train['class'] = le.fit_transform(df_nursery_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc59ce06a6d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572da70e0f6c21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nursery_train.to_csv(nursery_train_path_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacd9b155519f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"class-encoding\": label_mapping,\n",
    "    \"rare-class\": stat\n",
    "}, nursery_train_path_out[:-4]+\".conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fa889880ad6ae",
   "metadata": {},
   "source": [
    "# student+performance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c43885b383b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "student_train_path = \"./datasets/private/multiclass datasets/student+performance/student/student-por.csv\"\n",
    "\n",
    "student_train_path_out = \"./datasets/private/multiclass datasets/student+performance/student/all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fbad085b9ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .dat file using pandas and set the header names\n",
    "df_student_train = pd.read_csv(student_train_path, delimiter=';', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b31b5854f07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949323737dcbf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975100c0b62142d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561be013c0355e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train['G3_discrete'] = pd.cut(\n",
    "    df_student_train['G3'],\n",
    "    bins=[-1, 9, 14, 20],  # -1 au lieu de 0 pour inclure 0 dans le premier intervalle\n",
    "    labels=[0, 1, 2],\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# Vérification de la distribution\n",
    "print(df_student_train['G3_discrete'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9117f81d6bc0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c757f4769cb80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train.drop(columns=['G3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd91a7882ca2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Class\"\n",
    "stat = df_student_train[\"G3_discrete\"].value_counts()\n",
    "print(stat)\n",
    "df_student_train = remove_rare_classes(df_student_train, \"G3_discrete\", min_count=5)\n",
    "print(df_student_train[\"G3_discrete\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90580add7118cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_train.to_csv(student_train_path_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c640c9a60cb843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    \"class-encoding\": {\n",
    "        \"discretize\": {\n",
    "            \"bins\":[-1, 9, 14, 20],  # -1 au lieu de 0 pour inclure 0 dans le premier intervalle\n",
    "            \"labels\":[0, 1, 2],\n",
    "            \"right\":True\n",
    "        }\n",
    "    }\n",
    "}, student_train_path_out[:-4]+\".conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65cba2a-c414-44bf-9624-71666da42506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.report successfull loaded: 100%|██████████| 6/6 [00:35<00:00,  5.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from modules.pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AER RESULTS EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the root directory\n",
    "base = [\n",
    "    './outputs/AER/qualitative/mlna_1/data_selection_storage',\n",
    "    './outputs/AER/qualitative/mlna_1/personalized',\n",
    "    './outputs/AER/qualitative/mlna_1/global',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Évaluer l'impact sur les métriques de classification\n",
    "- Pour chaque couche, créer figure matplotlib:\n",
    "    - pour chaque approche: graph mining avec personnalisation global ou graph mining avec personalisation à un emprunteur\n",
    "        - donc chaque variable \n",
    "            - a pour chaque modèle d'apprentissage\n",
    "                - un trace une diagramme en barre qui présente: précision, accuracy, recall et f1-score \n",
    "                    - pour les 4 variations d'entrainement: \n",
    "                        - avec données classique\n",
    "                        - avec données classique diminuée de la variable\n",
    "                        - avec données classique augmentée de la version numérique de la variables extraite du graphe\n",
    "                        - avec les données classique diminuée de la variable et augmentée de la version numérique de la variables extraite du graphe\n",
    "\n",
    "# Évaluer l'importance des indicateurs extraites des graphes dans les modeles de ML\n",
    "- Pour chaque couche, créer figure matplotlib:\n",
    "    - pour chaque approche: graph mining avec personnalisation global ou graph mining avec personalisation à un emprunteur\n",
    "        - donc chaque variable \n",
    "            - a pour chaque modèle d'apprentissage\n",
    "                - un trace une diagramme en barre qui présente: précision, accuracy, recall et f1-score \n",
    "                    - pour les 4 variations d'entrainement: \n",
    "                        - avec données classique\n",
    "                        - avec données classique diminuée de la variable\n",
    "                        - avec données classique augmentée de la version numérique de la variables extraite du graphe\n",
    "                        - avec les données classique diminuée de la variable et augmentée de la version numérique de la variables extraite du graphe\n",
    "                        \n",
    "- Pour chaque couche, créer figure matplotlib:\n",
    "    - pour chaque approche: graph mining avec personnalisation global ou graph mining avec personalisation à un emprunteur\n",
    "        - donc chaque variable \n",
    "            - a pour chaque modèle d'apprentissage\n",
    "                - un trace une diagramme en barre qui présente: précision, accuracy, recall et f1-score \n",
    "                    - pour les 4 variations d'entrainement: \n",
    "                        - avec données classique\n",
    "                        - avec données classique diminuée de la variable\n",
    "                        - avec données classique augmentée de la version numérique de la variables extraite du graphe\n",
    "                        - avec les données classique diminuée de la variable et augmentée de la version numérique de la variables extraite du graphe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance_data_filenames(root_dir, func, verbose=False):\n",
    "    data_filenames = []\n",
    "    # Walk through the directories and files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # dirpath: current directory path\n",
    "        # dirnames: list of directories in the current directory\n",
    "        # filenames: list of files in the current directory\n",
    "\n",
    "        # Print the current directory\n",
    "        print('Directory:', dirpath)  if verbose else None\n",
    "        # Print all the subdirectories\n",
    "        for dirname in dirnames:\n",
    "            print('Subdirectory:', os.path.join(dirpath, dirname))  if verbose else None\n",
    "\n",
    "        # Print all the files\n",
    "        for filename in filenames:\n",
    "            if func(filename) and not ('x_' in filename or 'y_' in filename or 'metric' in filename):\n",
    "                print('File:', os.path.join(dirpath, filename)) if verbose else None\n",
    "                data_filenames.append(os.path.join(dirpath, filename))\n",
    "\n",
    "        # Print an empty line to separate directories\n",
    "        print()  if verbose else None\n",
    "    return data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLN_F = lambda x: (('classic_mln_' in x) and not('classic_mln_-' in x)) # find metric of model where mln were added\n",
    "MLN__F = lambda x: (('classic_mln_-' in x)) # where mln attribut were removed first\n",
    "MLN_C_F = lambda x: (('classic_-' in x)) # where mln attribut were removed first\n",
    "\n",
    "INTER_F = lambda x: (not('_max_' in x) and ('inter' in x))\n",
    "INTRA_F = lambda x: (not('_max_' in x) and ('intra' in x))\n",
    "COMBINE_F = lambda x: (not('_max_' in x) and ('combine' in x))\n",
    "ULTRA_F = lambda x: (not('_max_' in x) and ('ultra' in x))\n",
    "INTER_MAX_F = lambda x: (('_max_' in x) and ('inter' in x))\n",
    "INTRA_MAX_F = lambda x: (('_max_' in x) and ('intra' in x))\n",
    "COMBINE_MAX_F = lambda x: (('_max_' in x) and ('combine' in x))\n",
    "ULTRA_MAX_F = lambda x: (('_max_' in x) and ('ultra' in x))\n",
    "DEGREE_F = lambda x: (('degree' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model_desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dirs = [\n",
    "    './outputs/AER/qualitative/mlna_1/data_selection_storage',\n",
    "    './outputs/AER/qualitative/mlna_1/personalized/data_selection_storage',\n",
    "    './outputs/AER/qualitative/mlna_1/global/data_selection_storage',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classic-mln': ['./outputs/AER/qualitative/mlna_1/data_selection_storage/classic_-_mlna_owner_2024_01_20_16_10_39.csv',\n",
       "  './outputs/AER/qualitative/mlna_1/data_selection_storage/classic_-_mlna_owner_2024_01_22_09_58_46.csv',\n",
       "  './outputs/AER/qualitative/mlna_1/data_selection_storage/classic_-_mlna_selfemp_2024_01_22_10_05_36.csv'],\n",
       " 'mln': [['./outputs/AER/qualitative/mlna_1/personalized/data_selection_storage/classic_mln_owner_2024_01_20_16_02_44.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/personalized/data_selection_storage/classic_mln_owner_2024_01_22_09_55_42.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/personalized/data_selection_storage/classic_mln_selfemp_2024_01_22_10_03_00.csv'],\n",
       "  ['./outputs/AER/qualitative/mlna_1/global/data_selection_storage/classic_mln_owner_2024_01_20_16_06_30.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/global/data_selection_storage/classic_mln_owner_2024_01_22_09_57_18.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/global/data_selection_storage/classic_mln_selfemp_2024_01_22_10_04_09.csv']],\n",
       " 'mln-mlna': [['./outputs/AER/qualitative/mlna_1/personalized/data_selection_storage/classic_mln_-_mlna_owner_2024_01_20_16_13_24.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/personalized/data_selection_storage/classic_mln_-_mlna_owner_2024_01_22_10_00_07.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/personalized/data_selection_storage/classic_mln_-_mlna_selfemp_2024_01_22_10_06_36.csv'],\n",
       "  ['./outputs/AER/qualitative/mlna_1/global/data_selection_storage/classic_mln_-_mlna_owner_2024_01_20_16_16_48.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/global/data_selection_storage/classic_mln_-_mlna_owner_2024_01_22_10_01_10.csv',\n",
       "   './outputs/AER/qualitative/mlna_1/global/data_selection_storage/classic_mln_-_mlna_selfemp_2024_01_22_10_07_38.csv']]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = {}\n",
    "\n",
    "links['classic-mln'] = get_importance_data_filenames(root_dirs[0],MLN_C_F)\n",
    "links['mln'] = [get_importance_data_filenames(ele,MLN_F) for ele in root_dirs[1:]]\n",
    "links['mln-mlna'] = [get_importance_data_filenames(ele,MLN__F) for ele in root_dirs[1:]]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n",
      "file ext know as .csv\n"
     ]
    }
   ],
   "source": [
    "dataframes = {}\n",
    "\n",
    "dataframes['classic-mln'] = [\n",
    "    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "    for file in links['classic-mln']]\n",
    "dataframes['mln'] = [\n",
    "    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "    for logic in links['mln'] for file in logic ]\n",
    "dataframes['mln-mlna'] = [\n",
    "    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "    for logic in links['mln-mlna'] for file in logic ]\n",
    "#dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor_order_for_a_model(dataframes, model, func):\n",
    "        ranking_vector = [\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            []\n",
    "        ]\n",
    "        for dataframe in dataframes: # each metric output\n",
    "            # drop metrics column in dataframe\n",
    "            target= dataframe.drop(['precision', 'accuracy', 'recall', 'f1-score'], axis=1, inplace=False)\n",
    "            # sorting\n",
    "            _sorted = target.sort_values(\n",
    "                by = model,\n",
    "                axis = 1, \n",
    "                ascending = False\n",
    "                )\n",
    "\n",
    "            # get degree variable\n",
    "            degree = [(index+1,var) for index,var in enumerate(_sorted.columns.to_list()) if func(var)][0]\n",
    "            ranking_vector[0].append(_sorted.loc[model,degree[1]]) # the coef\n",
    "            ranking_vector[1].append(degree[0]/len(_sorted.columns.to_list())) # the rang\n",
    "            ranking_vector[2].append(str(degree[0])+'/'+str(len(_sorted.columns.to_list()))) # the rang in str\n",
    "            ranking_vector[3].append(degree[1]) # the name\n",
    "        return ranking_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor_details(data, models, func_1=None, func_2=None, func_3=None, func_4=None, func_5=None, func_6=None, func_7=None, func_8=None, func_9=None):\n",
    "    # define outputs columns\n",
    "    cols = [\n",
    "    'Degrée',\n",
    "    'PR Inter',\n",
    "    'PR Intra',\n",
    "    'PR Combine',\n",
    "    'PR 1-emprunteur',\n",
    "    'PR Inter Max',\n",
    "    'PR Intra Max',\n",
    "    'PR Combine Max',\n",
    "    'PR 1-emprunteur Max',\n",
    "\n",
    "    ]\n",
    "    results = {}\n",
    "    results['mln'] = {}\n",
    "    results['mln-mlna'] = {}\n",
    "    results['global'] = {}\n",
    "    for model in models: # fetch models\n",
    "        ## instanciate the result dictionnary\n",
    "        results['mln'][model] = pd.DataFrame(columns=cols)\n",
    "        results['global'][model] = pd.DataFrame(columns=cols)\n",
    "        results['mln-mlna'][model] = pd.DataFrame(columns=cols)\n",
    "        ## compute ranking\n",
    "        stage = [\n",
    "            'qualitative', \n",
    "            'quantitative',\n",
    "            'mixed'\n",
    "        ]\n",
    "        for i, name in enumerate(stage): # 0: categorial, 1: numeric, 2:mix\n",
    "            for j in range(len(data['mln'][i])): # 0: 1 layer, 1: 2 layers, 2: all variables layers\n",
    "                val_1 = []\n",
    "                val_2 = []\n",
    "                val_3 = []\n",
    "                # degree\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_1)[0])  if (func_1 != None) else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_1)[0]) if (func_1 != None) else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                # inter\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_2)[0]) if func_2 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_2)[0]) if func_2 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # intra\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_3)[0]) if func_3 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_3)[0]) if func_3 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # combine\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_4)[0]) if func_4 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_4)[0]) if func_4 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # ultra\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_5)[0]) if func_5 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_5)[0]) if func_5 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # inter max\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_6)[0]) if func_6 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_6)[0]) if func_6 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # intra max\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_7)[0])) if func_7 != None else 0\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_7)[0])) if func_7 != None else 0\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # combine max\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_8)[0]) if func_8 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_8)[0]) if func_8 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # ultra max\n",
    "                val_1.append(sum(get_descriptor_order_for_a_model(data['mln'][i][j], model, func_9)[0]) if func_9 != None else 0)\n",
    "                val_2.append(sum(get_descriptor_order_for_a_model(data['mln-mlna'][i][j], model, func_9)[0]) if func_9 != None else 0)\n",
    "                val_3.append(val_1[-1]+val_2[-1])\n",
    "                \n",
    "                # assign\n",
    "                results['mln'][model].loc[f'MLN {j+1} Couche(s) {name}'] = pd.Series(\n",
    "                    val_1, \n",
    "                    index=cols\n",
    "                    )\n",
    "                results['global'][model].loc[f'MLN {j+1} Couche(s) {name}'] = pd.Series(\n",
    "                    val_3, \n",
    "                    index=cols\n",
    "                    )\n",
    "                results['mln-mlna'][model].loc[f'MLN {j+1} Couche(s) {name}'] = pd.Series(\n",
    "                    val_2, \n",
    "                    index=cols\n",
    "                    )\n",
    "            \n",
    "            save_dataset(\n",
    "                cwd= os.getcwd()+f'/analyser/JAPAN/', \n",
    "                dataframe= results['mln'][model], \n",
    "                name= f'mln_{name}_{model}', \n",
    "                prefix= 'EDA', \n",
    "                sep= ','\n",
    "                )\n",
    "            save_dataset(\n",
    "                cwd= os.getcwd()+f'/analyser/JAPAN/', \n",
    "                dataframe= results['global'][model], \n",
    "                name= f'global_{name}_{model}', \n",
    "                prefix= 'EDA', \n",
    "                sep= ','\n",
    "                )\n",
    "            save_dataset(\n",
    "                cwd= os.getcwd()+f'/analyser/JAPAN/', \n",
    "                dataframe= results['mln-mlna'][model], \n",
    "                name= f'mln-mlna_{name}_{model}', \n",
    "                prefix= 'EDA', \n",
    "                sep= ','\n",
    "                )\n",
    "        \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' created successfully.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2/Thesis/implementation/scripting/analyser/JAPAN//data_selection_storage' already exists.\n"
     ]
    }
   ],
   "source": [
    "res= get_descriptor_details(dataframes, models, func_1=DEGREE_F, func_2=INTER_F, func_3=INTRA_F, func_4=COMBINE_F, func_5=None, func_6=INTER_MAX_F, func_7=INTRA_MAX_F, func_8=COMBINE_MAX_F, func_9=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Degrée</th>\n",
       "      <th>PR Inter</th>\n",
       "      <th>PR Intra</th>\n",
       "      <th>PR Combine</th>\n",
       "      <th>PR 1-emprunteur</th>\n",
       "      <th>PR Inter Max</th>\n",
       "      <th>PR Intra Max</th>\n",
       "      <th>PR Combine Max</th>\n",
       "      <th>PR 1-emprunteur Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLN 1 Couche(s) qualitative</th>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 2 Couche(s) qualitative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207508</td>\n",
       "      <td>0.456776</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 3 Couche(s) qualitative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.060526</td>\n",
       "      <td>0.064912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 1 Couche(s) quantitative</th>\n",
       "      <td>0.163593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 2 Couche(s) quantitative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719961</td>\n",
       "      <td>0.886661</td>\n",
       "      <td>0.294048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.137775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 3 Couche(s) quantitative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093978</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.038321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 1 Couche(s) mixed</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102541</td>\n",
       "      <td>0.101633</td>\n",
       "      <td>0.094374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLN 2 Couche(s) mixed</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.137512</td>\n",
       "      <td>2.763740</td>\n",
       "      <td>0.540267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205908</td>\n",
       "      <td>0.290198</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Degrée  PR Inter  PR Intra  PR Combine  \\\n",
       "MLN 1 Couche(s) qualitative   0.081900  0.000000  0.000000    0.000000   \n",
       "MLN 2 Couche(s) qualitative   0.000000  0.207508  0.456776    0.018876   \n",
       "MLN 3 Couche(s) qualitative   0.000000  0.042105  0.060526    0.064912   \n",
       "MLN 1 Couche(s) quantitative  0.163593  0.000000  0.000000    0.000000   \n",
       "MLN 2 Couche(s) quantitative  0.000000  0.719961  0.886661    0.294048   \n",
       "MLN 3 Couche(s) quantitative  0.000000  0.093978  0.129562    0.038321   \n",
       "MLN 1 Couche(s) mixed         0.000000  0.102541  0.101633    0.094374   \n",
       "MLN 2 Couche(s) mixed         0.000000  2.137512  2.763740    0.540267   \n",
       "\n",
       "                              PR 1-emprunteur  PR Inter Max  PR Intra Max  \\\n",
       "MLN 1 Couche(s) qualitative               0.0      0.000000      0.000000   \n",
       "MLN 2 Couche(s) qualitative               0.0      0.024001      0.016241   \n",
       "MLN 3 Couche(s) qualitative               0.0      0.000000      0.000000   \n",
       "MLN 1 Couche(s) quantitative              0.0      0.000000      0.000000   \n",
       "MLN 2 Couche(s) quantitative              0.0      0.031333      0.137775   \n",
       "MLN 3 Couche(s) quantitative              0.0      0.000000      0.003650   \n",
       "MLN 1 Couche(s) mixed                     0.0      0.000000      0.000000   \n",
       "MLN 2 Couche(s) mixed                     0.0      0.205908      0.290198   \n",
       "\n",
       "                              PR Combine Max  PR 1-emprunteur Max  \n",
       "MLN 1 Couche(s) qualitative         0.000000                  0.0  \n",
       "MLN 2 Couche(s) qualitative         0.000000                  0.0  \n",
       "MLN 3 Couche(s) qualitative         0.000000                  0.0  \n",
       "MLN 1 Couche(s) quantitative        0.000000                  0.0  \n",
       "MLN 2 Couche(s) quantitative        0.000000                  0.0  \n",
       "MLN 3 Couche(s) quantitative        0.000000                  0.0  \n",
       "MLN 1 Couche(s) mixed               0.000000                  0.0  \n",
       "MLN 2 Couche(s) mixed               0.002662                  0.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['mln']['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

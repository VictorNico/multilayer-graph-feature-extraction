{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.report successfull loaded: 100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from modules.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(root_dir, func, verbose=False):\n",
    "    data_filenames = []\n",
    "    # Walk through the directories and files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # dirpath: current directory path\n",
    "        # dirnames: list of directories in the current directory\n",
    "        # filenames: list of files in the current directory\n",
    "\n",
    "        # Print the current directory\n",
    "        print('Directory:', dirpath)  if verbose else None\n",
    "        # Print all the subdirectories\n",
    "        if verbose:\n",
    "            for dirname in dirnames:\n",
    "                print('Subdirectory:', os.path.join(dirpath, dirname))\n",
    "\n",
    "        # Print all the files\n",
    "        for filename in filenames:\n",
    "            if func(filename) and not ('x_' in filename or 'y_' in filename or 'metric' in filename):\n",
    "                print('File:', os.path.join(dirpath, filename)) if verbose else None\n",
    "                data_filenames.append(os.path.join(dirpath, filename))\n",
    "\n",
    "        # Print an empty line to separate directories\n",
    "        print()  if verbose else None\n",
    "    return data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLN_F = lambda x: (('classic_mln_' in x) and not('classic_mln_-' in x)) # find metric of model where mln were added\n",
    "MLN__F = lambda x: (('classic_mln_-' in x)) # where mln attribut were removed first\n",
    "MLN_C_F = lambda x: (('classic_-' in x)) # where mln attribut were removed first\n",
    "MLN_C= lambda x: (('classic_' in x)) # where mln attribut were removed first\n",
    "\n",
    "INTER_F = lambda x: (not('_max_' in x) and ('inter' in x))\n",
    "INTRA_F = lambda x: (not('_max_' in x) and ('intra' in x))\n",
    "COMBINE_F = lambda x: (not('_max_' in x) and ('combine' in x))\n",
    "ULTRA_F = lambda x: (not('_max_' in x) and ('ultra' in x))\n",
    "INTER_MAX_F = lambda x: (('_max_' in x) and ('inter' in x))\n",
    "INTRA_MAX_F = lambda x: (('_max_' in x) and ('intra' in x))\n",
    "COMBINE_MAX_F = lambda x: (('_max_' in x) and ('combine' in x))\n",
    "ULTRA_MAX_F = lambda x: (('_max_' in x) and ('ultra' in x))\n",
    "DEGREE_F = lambda x: (('degree' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_plots(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    outputs = {}\n",
    "    \n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "        for k in list(set([1, 2, len(cols)])):\n",
    "            #for logic in ['global', 'personalized']:\n",
    "            #outputs[logic] = {}\n",
    "            ### get all combination of col\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                if sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode('cb_person_default_on_file±loan_intent'))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k: # check mission context\n",
    "                    continue\n",
    "                print(case_k)\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                models = {}\n",
    "                models_1 = {}\n",
    "                for model in models_list:\n",
    "                    data = {\n",
    "                        'global':{},\n",
    "                        'personalized':{}\n",
    "                    }\n",
    "                    for key in files['global'].keys():\n",
    "                        data['global'][key] = [files['global'][key].loc[model,metric] for metric in metrics]\n",
    "                        data['personalized'][key] = [files['personalized'][key].loc[model,metric] for metric in metrics]\n",
    "\n",
    "                    data['global']['Metrics'] = metrics\n",
    "                    data['personalized']['Metrics'] = metrics\n",
    "                    models[model] = pd.DataFrame(data=data['global'])\n",
    "                    models_1[model] = pd.DataFrame(data=data['personalized'])\n",
    "                ### generate figures\n",
    "                nrow = 2\n",
    "                ncol = 4\n",
    "                \n",
    "                fig, axs = plt.subplots(nrows=nrow, ncols=ncol, figsize=(20, 15))\n",
    "                count=0\n",
    "                for r in range(ncol): \n",
    "                    # Barplot i\n",
    "                    models[models_list[count]].plot(kind='bar', x='Metrics', y=files['global'].keys(), ax=axs[0,r])\n",
    "                    axs[0,r].set_title(f'{models_name[models_list[count]]}')\n",
    "                    axs[0,r].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                    \n",
    "                    models_1[models_list[count]].plot(kind='bar', x='Metrics', y=files['personalized'].keys(), ax=axs[1,r])\n",
    "                    axs[1,r].set_title(f'{models_name[models_list[count]]}')\n",
    "                    axs[1,r].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                    \n",
    "                    axs[0,r].legend().set_visible(False)\n",
    "                    axs[1,r].legend().set_visible(False)\n",
    "                    if r == ncol-1:\n",
    "                        axs[1,r].legend().set_visible(True)\n",
    "                    count+=1\n",
    "                axs[0,0].set_ylabel('global')\n",
    "                axs[1,0].set_ylabel('personalized')\n",
    "                if True:\n",
    "                    create_domain(f'{cwd}/analyser/{data_folder}/plots/mlna_{k}/mixed')\n",
    "\n",
    "                    timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "                    filename1 = f'{cwd}/analyser/{data_folder}/plots/mlna_{k}/mixed/_metrics_comparaison_for_{case_k}'+'_'+timestr+'.png'\n",
    "                    # Adjust the layout to cover all content\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    plt.savefig(filename1,dpi=150) #.png,.pdf will also support here\n",
    "                    plt.close() # close the plot windows\n",
    "                ### generate reports\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_reports(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "        head_lambda = lambda x: f'<tr><td rowspan=\"2\" colspan=\"3\">{x}</td><td colspan=\"4\">Classic</td><td colspan=\"4\">Classic - Att</td><td colspan=\"4\">Classic + mln</td><td colspan=\"4\">Classic + mln - Att</td></tr><tr class=\"metrics\">{\"<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\" * 4}</tr>'\n",
    "        head = {\n",
    "            'xgb': head_lambda('xgb'),\n",
    "            'dtc': head_lambda('dtc'),\n",
    "            'lrc': head_lambda('lrc'),\n",
    "            'rfc': head_lambda('rfc')\n",
    "        }\n",
    "        body = {\n",
    "            'xgb': '',\n",
    "            'dtc': '',\n",
    "            'lrc': '',\n",
    "            'rfc': ''\n",
    "        }\n",
    "        style = '<style>tr:nth-child(even) {background-color: #dddddd;} table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            f'{x}': models_name[x],\n",
    "            'MLN': 'MultiLayer Network',\n",
    "            'MLN k Layer(s)': 'MLN with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'mln': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + mln': f'Learning from classic dataset of {data_folder} where mln had been added',\n",
    "            'Classic + mln - Att': f'Learning from classic dataset of {data_folder} where mln had been added and Att removed'\n",
    "            }.items()])\n",
    "\n",
    "        for k in list(set([1, 2, len(cols)])):\n",
    "            #for logic in ['global', 'personalized']:\n",
    "            #outputs[logic] = {}\n",
    "            ### get all combination of col\n",
    "            body_l = {\n",
    "                'xgb': '',\n",
    "                'dtc': '',\n",
    "                'lrc': '',\n",
    "                'rfc': ''\n",
    "            }\n",
    "            LayerLines = f'<tr style=\"border-top: 2px solid black;\"><td rowspan=\"{len(get_combinations(range(len(cols)),k)) * 2}\" >MLN {k} layer(s)</td>'\n",
    "            \n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                #if sum(\n",
    "                #        [\n",
    "                #            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode('cb_person_default_on_file±loan_intent'))\n",
    "                #            for partern in case_k.split(\"±\")\n",
    "                #            ]\n",
    "                #        ) == k: # check mission context\n",
    "                #    continue\n",
    "                print(case_k)\n",
    "                \n",
    "                VarLines = f'<td rowspan=\"2\" >{case_k if k < len(cols) else \"All\"}</td>'\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                for model in models_list:\n",
    "                    max_g = {metric:\n",
    "                        max([round(files['global'][key].loc[model,metric],4) for key in files['global'].keys()]) for metric in metrics\n",
    "                        }\n",
    "                    max_p = {metric:\n",
    "                        max([round(files['personalized'][key].loc[model,metric],4) for key in files['personalized'].keys()]) for metric in metrics\n",
    "                        }\n",
    "                    data = {\n",
    "                        'global':'<td>Global</td>',\n",
    "                        'personalized':f'<tr><td>Personalized</td>'\n",
    "                    }\n",
    "                    for key in files['global'].keys():\n",
    "                        data['global']+= ''.join([ \n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * int(round(files[\"global\"][key].loc[model,metric],4) == max_g[metric])}>{round(files[\"global\"][key].loc[model,metric],4)}</td>' \n",
    "                            for metric in metrics\n",
    "                            ])\n",
    "                        data['personalized']+= ''.join([ \n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * int(round(files[\"personalized\"][key].loc[model,metric],4) == max_p[metric])}>{round(files[\"personalized\"][key].loc[model,metric],4)}</td>' \n",
    "                            for metric in metrics\n",
    "                            ])\n",
    "                    data['global']+= '</tr>'\n",
    "                    data['personalized']+= '</tr>'\n",
    "                    body_l[model] += (LayerLines + VarLines + data['global'] + data['personalized'])  if len(body_l[model]) == 0 else ( f'<tr >' + VarLines + data['global'] + data['personalized'])\n",
    "            \n",
    "            for model in models_name.keys():\n",
    "                body[model]+= body_l[model]\n",
    "                caption = f'<caption><h2>Legend</h2>{caption_content_lambda(model)}</caption>'\n",
    "                table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{head[model]}{body_l[model]}</table>'\n",
    "                htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "\n",
    "                create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/mlna_{k}/report')\n",
    "                timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "                filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/mlna_{k}/report/Summary {data_folder} for {model} '+'_'+timestr+'.html'\n",
    "                _file= open(filename1,\"w\")\n",
    "                _file.write(htm)\n",
    "                _file.close()\n",
    "        for model in models_name.keys():\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(model)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{head[model]}{body[model]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/report')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/report/Summary {data_folder} for {model} '+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\">{x}<td><td>Classic</td><td>Best Accuracy</td><td>Up (%)</td><td>Approach(s)</td><td>Logic(s)</td></tr>'\n",
    "        tab1_head = {\n",
    "            'accuracy': head_lambda('accuracy'),\n",
    "            'precision': head_lambda('precision'),\n",
    "            'recall': head_lambda('recall'),\n",
    "            'f1-score': head_lambda('f1-score')\n",
    "        }\n",
    "        tab1_body = {\n",
    "            'accuracy': '',\n",
    "            'precision': '',\n",
    "            'recall': '',\n",
    "            'f1-score': ''\n",
    "        }\n",
    "\n",
    "        # analyse the impact of each approach on classic\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}<td><td colspan=\"3\">Classic - Att Vs Classic</td><td colspan=\"3\">Classic + MLN Vs Classic</td><td colspan=\"3\">Classic + MLN - Att Vs Classic</td></tr><tr>{\"<td>></td><td>=</td><td><</td>\"*3}</tr>'\n",
    "        tab2_head_g = {\n",
    "            'accuracy': head_lambda('accuracy'),\n",
    "            'precision': head_lambda('precision'),\n",
    "            'recall': head_lambda('recall'),\n",
    "            'f1-score': head_lambda('f1-score')\n",
    "        }\n",
    "        tab2_head_p = tab2_head_g\n",
    "        tab2_body_g = {\n",
    "            'accuracy': '',\n",
    "            'precision': '',\n",
    "            'recall': '',\n",
    "            'f1-score': ''\n",
    "        }\n",
    "        tab2_head_p = tab2_head_g\n",
    "\n",
    "        # check if corelation between class of Att in MLN1 and their classe in MLN 2+\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}<td><td colspan=\"3\">(Good MLN 1, Good MLN 1)</td><td colspan=\"3\">(Good MLN 1, Bad MLN 1)</td><td colspan=\"3\">(Bad MLN 1, Bad MLN 1)</td></tr><tr>{\"<td>></td><td>=</td><td><</td>\"*3}</tr>'\n",
    "        tab3_head_g = {\n",
    "            'accuracy': head_lambda('accuracy'),\n",
    "            'precision': head_lambda('precision'),\n",
    "            'recall': head_lambda('recall'),\n",
    "            'f1-score': head_lambda('f1-score')\n",
    "        }\n",
    "        tab3_head_p = tab3_head_g\n",
    "        tab3_body_g1 = {\n",
    "            'accuracy': '',\n",
    "            'precision': '',\n",
    "            'recall': '',\n",
    "            'f1-score': ''\n",
    "        }\n",
    "        tab3_body_g2 = tab3_body_g1\n",
    "        tab3_body_p1 = tab3_body_g1\n",
    "        tab3_body_p2 = tab3_body_p1\n",
    "\n",
    "        # compare global and personalized logics\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}<td><td colspan=\"3\">Classic + MLN</td><td colspan=\"3\">Classic + MLN - Att</td></tr><tr>{\"<td>perso ></td><td>perso =</td><td>perso <</td>\"*2}</tr>'\n",
    "        tab4_head = {\n",
    "            'accuracy': head_lambda('accuracy'),\n",
    "            'precision': head_lambda('precision'),\n",
    "            'recall': head_lambda('recall'),\n",
    "            'f1-score': head_lambda('f1-score')\n",
    "        }\n",
    "        tab4_body = {\n",
    "            'accuracy': '',\n",
    "            'precision': '',\n",
    "            'recall': '',\n",
    "            'f1-score': ''\n",
    "        }\n",
    "        \n",
    "        style = '<style>tr:nth-child(even) {background-color: #dddddd;} table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        # save class of each Att\n",
    "        clusters = {\n",
    "            'accuracy': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'precision': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'recall': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            }\n",
    "        }\n",
    "        # base format for storing best metrics\n",
    "        best_metrics = {\n",
    "            'accuracy': {\n",
    "                'value': 0,\n",
    "                'approachs':[],\n",
    "                'logics':[]\n",
    "            },\n",
    "            'precision': {\n",
    "                'value': 0,\n",
    "                'approachs':[],\n",
    "                'logics':[]\n",
    "            },\n",
    "            'recall': {\n",
    "                'value': 0,\n",
    "                'approachs':[],\n",
    "                'logics':[]\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'value': 0,\n",
    "                'approachs':[],\n",
    "                'logics':[]\n",
    "            }\n",
    "        }\n",
    "        comp1 = {\n",
    "            'accuracy': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'precision': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'recall': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'f1-score': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }]\n",
    "        }\n",
    "        comp2 = {\n",
    "            'accuracy': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'precision': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':\n",
    "            }],\n",
    "            'recall': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':\n",
    "            }],\n",
    "            'f1-score': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }]\n",
    "        }\n",
    "        clusters_g1 = {key: clusters for key in models_name.keys()}\n",
    "        clusters_g2 = {key: clusters for key in models_name.keys()}\n",
    "        clusters_p1 = {key: clusters for key in models_name.keys()}\n",
    "        clusters_p2 = {key: clusters for key in models_name.keys()}\n",
    "        # save for each model, this best metric\n",
    "        body_best = {\n",
    "            key: best_metrics for key in models_name.keys()\n",
    "        }\n",
    "        for k in list(set([1, 2, len(cols)])):\n",
    "            #for logic in ['global', 'personalized']:\n",
    "            #outputs[logic] = {}\n",
    "            ### get all combination of col\n",
    "\n",
    "            body_compA_g = {\n",
    "                key: comp1 for key in models_name.keys()\n",
    "            }\n",
    "            body_compA_p = body_compA_g\n",
    "            body_compC_g1 = {\n",
    "                key: comp1 for key in models_name.keys()\n",
    "            }\n",
    "            body_compC_g2 = body_compC_g1\n",
    "            body_compC_p1 = body_compC_g1\n",
    "            body_compC_p2 = body_compC_g1\n",
    "            body_compL = {\n",
    "                key: comp2 for key in models_name.keys()\n",
    "            }\n",
    "            \n",
    "            # aside row config\n",
    "            LayerLines = f'<tr style=\"border-top: 2px solid black;\"><td rowspan=\"{len(models_name.keys()) }\" >MLN {k} layer(s): {len(get_combinations(range(len(cols)),k))} Att</td>'\n",
    "            \n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                for model in models_list:\n",
    "                    for metric in metrics:\n",
    "                        if k == 1: # in 1st layer, find Att which increase or not metrics\n",
    "                            clusters_g1[model][metric]['Good' if round(files['global']['classic_mln'].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 'Bad'].append(case_k)\n",
    "                            clusters_g2[model][metric]['Good' if round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 'Bad'].append(case_k)\n",
    "                            clusters_p1[model][metric]['Good' if round(files['personalized']['classic_mln'].loc[model,metric],4) > round(files['personalized']['classic'].loc[model,metric],4) else 'Bad'].append(case_k)\n",
    "                            clusters_p2[model][metric]['Good' if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) > round(files['personalized']['classic'].loc[model,metric],4) else 'Bad'].append(case_k)\n",
    "                        # count combination impact\n",
    "                        if k == 2:\n",
    "                            if sum([partern in clusters_g1[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_g1[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compc_g1[model][metric][indice]['s'] += 1 if round(files['global']['classic_mln'].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_g1[model][metric][indice]['e'] += 1 if round(files['global']['classic_mln'].loc[model,metric],4) == round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_g1[model][metric][indice]['i'] += 1 if round(files['global']['classic_mln'].loc[model,metric],4) < round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "\n",
    "                            if sum([partern in clusters_g2[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_g2[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compc_g2[model][metric][indice]['s'] += 1 if round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_g2[model][metric][indice]['e'] += 1 if round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) == round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_g2[model][metric][indice]['i'] += 1 if round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) < round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "\n",
    "                            if sum([partern in clusters_p1[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_p1[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compc_p1[model][metric][indice]['s'] += 1 if round(files['personalized']['classic_mln'].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_p1[model][metric][indice]['e'] += 1 if round(files['personalized']['classic_mln'].loc[model,metric],4) == round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_p1[model][metric][indice]['i'] += 1 if round(files['personalized']['classic_mln'].loc[model,metric],4) < round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "\n",
    "                            if sum([partern in clusters_p2[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_p2[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compc_p2[model][metric][indice]['s'] += 1 if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_p2[model][metric][indice]['e'] += 1 if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) == round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                            body_compc_p2[model][metric][indice]['i'] += 1 if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) < round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                        \n",
    "                        for i, key in enumerate(files['global'].keys()): \n",
    "                            # find the best metric\n",
    "                            temp = body_best[model][metric].value\n",
    "                            if round(files['global'][key].loc[model,metric],4) > temp:\n",
    "                                body_best[model][metric].value = round(files['global'][key].loc[model,metric],4)\n",
    "                                body_best[model][metric].approachs = [key]\n",
    "                                body_best[model][metric].logics = ['global']\n",
    "                            elif round(files['global'][key].loc[model,metric],4) == temp:\n",
    "                                body_best[model][metric].approachs.append(key)\n",
    "                                body_best[model][metric].logics.append('global')\n",
    "                            if round(files['personalized'][key].loc[model,metric],4) > temp:\n",
    "                                body_best[model][metric].value = round(files['global'][key].loc[model,metric],4)\n",
    "                                body_best[model][metric].approachs = [key]\n",
    "                                body_best[model][metric].logics = ['personalized']\n",
    "                            elif round(files['personalized'][key].loc[model,metric],4) == temp:\n",
    "                                body_best[model][metric].approachs.append(key)\n",
    "                                body_best[model][metric].logics.append('personalized')\n",
    "\n",
    "                            # count approachs impacts\n",
    "                            if i > 0:\n",
    "                                body_compA_g[model][metric][i-1]['s'] += 1 if round(files['global'][key].loc[model,metric],4) > round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                                body_compA_g[model][metric][i-1]['e'] += 1 if round(files['global'][key].loc[model,metric],4) == round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "                                body_compA_g[model][metric][i-1]['i'] += 1 if round(files['global'][key].loc[model,metric],4) < round(files['global']['classic'].loc[model,metric],4) else 0\n",
    "\n",
    "                                body_compA_p[model][metric][i-1]['s'] += 1 if round(files['personalized'][key].loc[model,metric],4) > round(files['personalized']['classic'].loc[model,metric],4) else 0\n",
    "                                body_compA_p[model][metric][i-1]['e'] += 1 if round(files['personalized'][key].loc[model,metric],4) == round(files['personalized']['classic'].loc[model,metric],4) else 0\n",
    "                                body_compA_p[model][metric][i-1]['i'] += 1 if round(files['personalized'][key].loc[model,metric],4) < round(files['personalized']['classic'].loc[model,metric],4) else 0\n",
    "                                \n",
    "                                \n",
    "                        # count logics impacts\n",
    "                        body_compL[model][metric][0]['s'] += 1 if round(files['personalized']['classic_mln'].loc[model,metric],4) > round(files['global']['classic_mln'].loc[model,metric],4) else 0\n",
    "                        body_compL[model][metric][0]['e'] += 1 if round(files['personalized']['classic_mln'].loc[model,metric],4) == round(files['global']['classic_mln'].loc[model,metric],4) else 0\n",
    "                        body_compL[model][metric][0]['i'] += 1 if round(files['personalized']['classic_mln'].loc[model,metric],4) < round(files['global']['classic_mln'].loc[model,metric],4) else 0\n",
    "                        \n",
    "                        body_compL[model][metric][1]['s'] += 1 if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) > round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) else 0\n",
    "                        body_compL[model][metric][1]['e'] += 1 if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) == round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) else 0\n",
    "                        body_compL[model][metric][1]['i'] += 1 if round(files['personalized']['classic_mln_-_mlna'].loc[model,metric],4) < round(files['global']['classic_mln_-_mlna'].loc[model,metric],4) else 0\n",
    "   \n",
    "            for metric in metrics:\n",
    "                for i, model in enumerate(models_name.keys()):\n",
    "                    # approachs\n",
    "                    tab2_body_g[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                        f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                        for vector in body_compA_g[model][metric]\n",
    "                        ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                        f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                        for vector in body_compA_g[model][metric]\n",
    "                        ]) + '</tr>')\n",
    "                    tab2_body_p[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                        f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                        for vector in body_compA_p[model][metric]\n",
    "                        ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                        f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                        for vector in body_compA_p[model][metric]\n",
    "                        ]) + '</tr>')\n",
    "                    # logics\n",
    "                    tab4_body += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                        f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                        for vector in body_compL[model][metric]\n",
    "                        ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                        f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                        for vector in body_compL[model][metric]\n",
    "                        ]) + '</tr>')\n",
    "                    # comparaison\n",
    "                    if k == 2:\n",
    "                        tab3_body_g1[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_g1[model][metric]\n",
    "                            ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_g1[model][metric]\n",
    "                            ]) + '</tr>')\n",
    "                        tab3_body_g2[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_g2[model][metric]\n",
    "                            ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_g2[model][metric]\n",
    "                            ]) + '</tr>')\n",
    "                        tab3_body_p1[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_p1[model][metric]\n",
    "                            ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_p1[model][metric]\n",
    "                            ]) + '</tr>')\n",
    "                        tab3_body_p2[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_p2[model][metric]\n",
    "                            ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                            f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                            for vector in body_compc_p2[model][metric]\n",
    "                            ]) + '</tr>')\n",
    "                    \n",
    "        for metric in metrics:\n",
    "\n",
    "            # approachs\n",
    "            #1\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab2_head_g[metric]}{tab2_body_g[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of approachs in {data_folder} for {metric} on global logic'+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "            #2\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab2_head_p[metric]}{tab2_body_p[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of approachs in {data_folder} for {metric} on personalized logic'+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "\n",
    "            # logics\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab4_head[metric]}{tab4_body[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of logics in {data_folder} for {metric}'+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "\n",
    "            # comparaison\n",
    "            #1\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of Tuple of MLN1 quality in {data_folder} for {metric} on global logic using Classic + MLN apporach '+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "            #2\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab3_head_g[metric]}{tab2_body_g2[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of Tuple of MLN1 quality in {data_folder} for {metric} on global logic using Classic + MLN - Att apporach'+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "            #3\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab3_head_g[metric]}{tab2_body_p1[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of Tuple of MLN1 quality in {data_folder} for {metric} on personalized logic using Classic + MLN apporach'+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "            #4\n",
    "            caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "            table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab3_head_g[metric]}{tab2_body_p2[metric]}</table>'\n",
    "            htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "            \n",
    "            create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats')\n",
    "            timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "            filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/Statistical comparaison of Tuple of MLN1 quality in {data_folder} for {metric} on personalized logic using Classic + MLN - Att apporach'+'_'+timestr+'.html'\n",
    "            _file= open(filename1,\"w\")\n",
    "            _file.write(htm)\n",
    "            _file.close()\n",
    "\n",
    "            # best metrics\n",
    "            for i, model in enumerate(models_name.keys()):\n",
    "                # approachs\n",
    "                tab2_body_g[metric] += (LayerLines + f'<td>{model}</td>'+ ''.join([\n",
    "                    f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                    for vector in body_best[model][metric]\n",
    "                    ]) + '</tr>') if i == 0 else (f'<tr><td>{model}</td>'+ ''.join([\n",
    "                    f'<td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.s >= max([ap.s for ap in vector])}>{vector.s}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.e >= max([ap.e for ap in vector])}>{vector.e}<td><td style={\"color:blue; font-size: 40px; font-weight: bold;\" * vector.i >= max([ap.i for ap in vector])}>{vector.i}<td>'  \n",
    "                    for vector in body_compA_g[model][metric]\n",
    "                    ]) + '</tr>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_from_cols = lambda x:(list(set([\n",
    "    var.split(\"__\")[1] for var in [\n",
    "        coll \n",
    "        for coll in [\n",
    "            col \n",
    "            for col in x \n",
    "                if not (\n",
    "                    ('precision' in col ) \n",
    "                    or ('accuracy' in col ) \n",
    "                    or ('recall' in col) \n",
    "                    or ('f1-score' in col)\n",
    "                )\n",
    "            ] \n",
    "            if (\"__\" in coll)\n",
    "        ]\n",
    "    ]\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_launcher(outputs_name=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models = model_desc()\n",
    "        \n",
    "        metrics_analyzer_reports(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_19_02_2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>xxx</title>\n",
    "<style>\n",
    ".metrics > td {\n",
    "writing-mode: vertical-rl;\n",
    "text-orientation: sideways;\n",
    "}\n",
    "</style>\n",
    "<table>\n",
    "<tr>\n",
    "<td rowspan=\"2\" colspan=\"3\">XGB<td>\n",
    "<td colspan=\"4\">Classic</td>\n",
    "<td colspan=\"4\">Classic - Att</td>\n",
    "<td colspan=\"4\">Classic + MLN</td>\n",
    "<td colspan=\"4\">Classic + MLN - Att</td>\n",
    "</tr>\n",
    "<tr class=\"metrics\">\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"2\">MLN 1</td>\n",
    "<td rowspan=\"2\">Var 1</td>\n",
    "<td>Global</td>\n",
    "<td>0</td><td>1</td><td>2</td><td>3</td>\n",
    "<td>4</td><td>5</td><td>6</td><td>7</td>\n",
    "<td>8</td><td>9</td><td>10</td><td>11</td>\n",
    "<td>12</td><td>13</td><td>14</td><td>15</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Personalized</td>\n",
    "<td>0</td><td>1</td><td>2</td><td>3</td>\n",
    "<td>4</td><td>5</td><td>6</td><td>7</td>\n",
    "<td>8</td><td>9</td><td>10</td><td>11</td>\n",
    "<td>12</td><td>13</td><td>14</td><td>15</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_desc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFB\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m models_name \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_desc\u001b[49m()\n\u001b[1;32m      3\u001b[0m caption_content_lambda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<span><strong>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</strong>: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</span><br>\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiLayer Network\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLN k Layer(s)\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLN with k layer(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: models_name[x]\n\u001b[1;32m     13\u001b[0m             }\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m     14\u001b[0m caption \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<caption><h2>Legend</h2>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaption_content_lambda(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</caption>\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_desc' is not defined"
     ]
    }
   ],
   "source": [
    "data_folder = 'AFB'\n",
    "models_name = model_desc()\n",
    "caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            'MLN': 'MultiLayer Network',\n",
    "            'MLN k Layer(s)': 'MLN with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'Desc': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + Desc': f'Learning from classic dataset of {data_folder} where Desc had been added',\n",
    "            'Classic + Desc - Att': f'Learning from classic dataset of {data_folder} where Desc had been added and Att removed',\n",
    "            f'{x}': models_name[x]\n",
    "            }.items()])\n",
    "caption = f'<caption><h2>Legend</h2>{caption_content_lambda(\"xgb\")}</caption>'\n",
    "style = '<style>table, th, td {border: 1px solid black;border-collapse: collapse;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black; padding: 2px;} caption > h2 {text-align: center;} td {text-align: center;}</style>'\n",
    "fake = \"\"\"\n",
    "<tr>\n",
    "<td rowspan=\"2\" colspan=\"3\">XGB<td>\n",
    "<td colspan=\"4\">Classic</td>\n",
    "<td colspan=\"4\">Classic - Att</td>\n",
    "<td colspan=\"4\">Classic + MLN</td>\n",
    "<td colspan=\"4\">Classic + MLN - Att</td>\n",
    "</tr>\n",
    "<tr class=\"metrics\">\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "<td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"2\">MLN 1</td>\n",
    "<td rowspan=\"2\">Var 1</td>\n",
    "<td>Global</td>\n",
    "<td>0</td><td>1</td><td>2</td><td>3</td>\n",
    "<td>4</td><td>5</td><td>6</td><td>7</td>\n",
    "<td>8</td><td>9</td><td>10</td><td>11</td>\n",
    "<td>12</td><td>13</td><td>14</td><td>15</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Personalized</td>\n",
    "<td>0</td><td>1</td><td>2</td><td>3</td>\n",
    "<td>4</td><td>5</td><td>6</td><td>7</td>\n",
    "<td>8</td><td>9</td><td>10</td><td>11</td>\n",
    "<td>12</td><td>13</td><td>14</td><td>15</td>\n",
    "</tr>\n",
    "\"\"\"\n",
    "table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption} {fake}</table>'\n",
    "htm = f'<html><head>{style}<title> Summary </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "\n",
    "HTML(htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<html><head><style>table, th, td {border: 1px solid black;border-collapse: collapse;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;} td {text-align: center;}</style><title> Summary </title></head><body style=\"background-color: white;\"><table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\"><caption><h2>Legend</h2><span><strong>MLN</strong>: MultiLayer Network</span><br><span><strong>MLN k Layer(s)</strong>: MLN with k layer(s)</span><br><span><strong>Att</strong>: Attributs or modalities of variable(s) used to build MLN</span><br><span><strong>Desc</strong>: Descriptors extracted from MLN</span><br><span><strong>Classic</strong>: Learning from classic dataset of AFB</span><br><span><strong>Classic - Att</strong>: Learning from classic dataset of AFB where Att had been removed</span><br><span><strong>Classic + Desc</strong>: Learning from classic dataset of AFB where Desc had been added</span><br><span><strong>Classic + Desc - Att</strong>: Learning from classic dataset of AFB where Desc had been added and Att removed</span><br><span><strong>xgb</strong>: XGBOOST</span><br></caption> <tr class=\\'dd\\'><td rowspan=\"2\" colspan=\"3\">XGB<td><td colspan=\"4\">Classic</td><td colspan=\"4\">Classic - Att</td><td colspan=\"4\">Classic + MLN</td><td colspan=\"4\">Classic + MLN - Att</td></tr><tr class=\"metrics\"><td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td><td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td><td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td><td>Accuracy</td><td>Precision</td><td>Recall</td><td>F1-score</td></tr><tr><td rowspan=\"2\">MLN 1</td><td rowspan=\"2\">Var 1</td><td>Global</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td><td>13</td><td>14</td><td>15</td></tr><tr><td>Personalized</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td><td>13</td><td>14</td><td>15</td></tr></table></body></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0847995b-060f-41fc-980b-22424bfbddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.preprocessing successfull loaded: 100%|███| 6/6 [00:03<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from modules.statistical import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65447851-4513-47ea-b555-00962f3505a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264f7cc0-f4fd-4284-8904-4490c5a402b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = list(range(1,14))\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c87eeb-38d2-4380-a3b7-81508bc497cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.85]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [round(i,1) for i in np.arange(0.1,1.0,0.1)]\n",
    "alphas.append(0.85)\n",
    "#alphas = sorted(list(set(alphas)-set([0.2, 0.4])))\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596b078-ca70-45dd-aafe-5627da4b0514",
   "metadata": {},
   "source": [
    "# generation du tableau de comparaison de qualité de descripteurs dans la processus de selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafec57-1b71-4714-831d-f4b7158830f8",
   "metadata": {},
   "source": [
    "generate_g_b_impact_table(\n",
    "    outputs_name='outputs_lts', \n",
    "    cwd=os.getcwd(), \n",
    "    outputPath='result_lts',\n",
    "    layers=layers, \n",
    "    _type='qualitative',\n",
    "    alphas=alphas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072273ce-2535-443a-9f6b-f18ed1914358",
   "metadata": {},
   "source": [
    "# Generation de tableau de comparaison de l'impact metriques des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1d2f1-2c42-4bb5-8504-990a45af80de",
   "metadata": {},
   "source": [
    "generate_report_tables_v3_2(\n",
    "    outputs_name='outputs_lts', \n",
    "    cwd=os.getcwd(), \n",
    "    outputPath='result_lts',\n",
    "    layers=layers, \n",
    "    glo=True,\n",
    "    per=True,\n",
    "    gap=True,\n",
    "    logics=['GLO','PER'],#,'PER','GAP'\n",
    "    approachs=['MlC','MCA'],\n",
    "    configs=['MX','CX','CY','CXY'],#'MX',\n",
    "    metrics=['accuracy','precision1','precision0','financial-cost'],#'accuracy','f1-score','precision1','recall1','f1-score1','precision0','recall0','f1-score0','financial-cost'\n",
    "    metrics1=['precision1','financial-cost'],#'accuracy','f1-score','precision1','recall1','f1-score1','precision0','recall0','f1-score0','financial-cost'\n",
    "    _type='qualitative',\n",
    "    alphas=alphas,\n",
    "    result_=[1],\n",
    "    total_digits= None,\n",
    "    decimal_digits= 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad3cdb-6f48-469b-a93d-97f8a4eaad6e",
   "metadata": {},
   "source": [
    "a = {'precision1': {0.1: 0.5, 0.2: 0.6, 0.3: 1.0, 0.4: 0.7, 0.5: 0.7, 0.6: 0.5, 0.7: 0.5, 0.8: 0.8, 0.85: 0.8, 0.9: 6.8999999999999995}, 'financial-cost': {0.1: 4.0, 0.2: 2.7, 0.3: 1.1, 0.4: 1.5, 0.5: 3.5, 0.6: 1.5999999999999999, 0.7: 3.2, 0.8: 2.6, 0.85: 2.8000000000000003, 0.9: 2.4}}\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3f18d-4e7b-4ce6-b6b9-36882846d2fd",
   "metadata": {},
   "source": [
    "# Generation de bar chart pour l'evaluation des descripteurs et du tableau recapitulatifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3342afd-bd56-4913-885d-63eb3defcb95",
   "metadata": {},
   "source": [
    "generate_descriptor_ranking(\n",
    "    outputs_name='outputs_lts', \n",
    "    cwd=os.getcwd(), \n",
    "    outputPath='result_lts',\n",
    "    layers=layers, \n",
    "    _type='qualitative',\n",
    "    alphas=alphas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6d233-e829-4cff-aa6d-6f81842f7fa7",
   "metadata": {},
   "source": [
    "# Proc Selection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ce859b-338d-4d37-b235-d58279531616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vector_matching_precision(v1, v2, tolerance=0):\n",
    "    \"\"\"\n",
    "    Calcule la précision de correspondance entre deux vecteurs.\n",
    "    \n",
    "    :param v1: Premier vecteur\n",
    "    :param v2: Deuxième vecteur\n",
    "    :param tolerance: Tolérance pour considérer deux valeurs comme correspondantes\n",
    "    :return: Pourcentage de correspondance entre les vecteurs\n",
    "    \"\"\"\n",
    "    if len(v1) != len(v2):\n",
    "        raise ValueError(\"Les vecteurs doivent avoir la même longueur\")\n",
    "    \n",
    "    v1, v2 = np.array(v1), np.array(v2)\n",
    "    matches = np.abs(v1 - v2) <= tolerance\n",
    "    precision = np.mean(matches) * 100\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f5a66c-0619-4d9b-9571-4400e2d86833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_compare_feature_selection_protocole(\n",
    "    store,\n",
    "    output_path\n",
    "):\n",
    "    # add the resize box to ensure the scale of the table will be contain's inside the width space avalable.\n",
    "    # start setting up the tabular dimensions setting\n",
    "    table_header = \"\"\"\n",
    "        %\\\\begin{sidewaystable}\n",
    "        \\\\resizebox{\\\\textwidth}{!}{\n",
    "\n",
    "        \\\\begin{tabular}{|c|c|\"\"\"+(\"c|\"*10)\n",
    "    # setup information columns headears\n",
    "    nbMCol =  10\n",
    "    # add col for total results\n",
    "    table_header+= \"} \"\n",
    "    # add separator clines\n",
    "    nb_cols = (2+nbMCol)\n",
    "    table_header+= \" \\\\cline{1-\"+str(nb_cols)+\"}\" # corresponding to the number of columns\n",
    "\n",
    "    # build the first line: metrics' line\n",
    "    lines = ''\n",
    "    # add the blank block\n",
    "    lines += \"\"\"\n",
    "    \\\\multicolumn{2}{|c|}{}\"\"\"\n",
    "\n",
    "\n",
    "    datasets = list(store.keys())\n",
    "    methods = list(store[datasets[0]].keys())\n",
    "    alphas = sorted(list({el for data in datasets for el in store[data][methods[0]].keys() }))\n",
    "    # add alpha for metric\n",
    "    for alpha in alphas:\n",
    "        lines+= f\" & {alpha}\"\n",
    "    # add the total name\n",
    "    lines+= \" \\\\\\\\ \"\n",
    "    lines+= \" \\\\cline{1-\"+str(nb_cols)+\"\"\"}\n",
    "    \"\"\"\n",
    "    for folder in datasets:\n",
    "        # fetch on model\n",
    "        lines+= \"\"\"\n",
    "            \\\\multirow{3}{*}{\"\"\"+folder+\"\"\"}\"\"\"\n",
    "        for mi, meth in enumerate(methods): \n",
    "            lines+= f\"\"\" & {meth}\"\"\"\n",
    "            for ai, alpha in enumerate(alphas): # MlC, MCA\n",
    "                lines+= f\"\"\" & {store[folder][meth][alpha] }\"\"\" if alpha in list(store[folder][meth].keys()) else \" & \"\n",
    "            lines+= (\"\"\"\\\\\\\\ \"\"\"+ \"\"\" \\\\cline{2-\"\"\"+str(nb_cols)+\"\"\"}\n",
    "\n",
    "                    \"\"\") if mi != len(methods)-1 else (\"\"\"\\\\\\\\ \"\"\"+ \"\"\" \\\\cline{1-\"\"\"+str(nb_cols)+\"\"\"}\n",
    "\n",
    "                    \"\"\")\n",
    "                \n",
    "\n",
    "    lines+= \"\"\"\n",
    "\n",
    "    \\\\end{tabular}\n",
    "    }\n",
    "    %\\\\end{sidewaystable}\"\"\"\n",
    "\n",
    "    table = table_header + lines\n",
    "    create_domain(f\"{output_path}/descriptComp/alpha/mlnGrowth1\")\n",
    "    filename1 = f\"{output_path}/descriptComp/alpha/mlnGrowth1/mlnGrowth1.tex\"\n",
    "    _file = open(filename1, \"w\")\n",
    "    _file.write(header+\"\"\"\n",
    "                \\\\begin{table}[H]\n",
    "                \\\\centering\n",
    "                \"\"\"+table+\"\"\"\n",
    "                \\\\caption{default}\n",
    "                \\\\label{default}\n",
    "                \\\\end{table}\"\"\"+footer)\n",
    "    _file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29965eea-336b-4be5-882d-8013580e4adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'result_lts/descriptComp/alpha/mlnGrowth1' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djiemboutienctheuvictornico/Documents/MyFolders/ACADEMIC/M2_thesis/scripting/modules/pipeline.py:5265: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  if cumulative_diff / total_diff >= threshold_percent:\n"
     ]
    }
   ],
   "source": [
    "records = joblib.load('./result_lts/best.tex')\n",
    "\n",
    "# result structure\n",
    "resultDict = {\n",
    "    'dataset':[],\n",
    "    'alpha': [],\n",
    "    # 'QuartileThreshold':[],\n",
    "    'elbowThreshold':[],\n",
    "    'cumulative_difference_threshold':[],\n",
    "    # 'variance_explained_threshold':[],\n",
    "    'realThreshold':[]\n",
    "}\n",
    "res = {}\n",
    "getTheBestAcc = lambda store, k: round(max([acc for layer,_,acc in store if k == layer]),4)\n",
    "\n",
    "# walk on the datasets\n",
    "for dataset in records.keys():\n",
    "    # walk on alphas\n",
    "    res[dataset] = {key:{} for key in ['CUSUM','Elbow','réel']}\n",
    "    for alpha in records[dataset].keys():\n",
    "        if len(records[dataset][alpha]['predicted_best_k']) != 0:\n",
    "            resultDict['dataset'].append(dataset)\n",
    "            resultDict['alpha'].append(alpha)\n",
    "            # resultDict['QuartileThreshold'].append(getTheBestAcc(records[dataset][alpha]['list'],records[dataset][alpha]['predicted_best_k'][0]))\n",
    "            elb = elbow_method(list(records[dataset][alpha]['accuracies'].values()))\n",
    "            elb = elb if elb < max([layer for layer,_,_ in records[dataset][alpha]['list']]) else max([layer for layer,_,_ in records[dataset][alpha]['list']])\n",
    "            resultDict['elbowThreshold'].append(getTheBestAcc(records[dataset][alpha]['list'],elb))\n",
    "            res[dataset]['Elbow'][alpha] = getTheBestAcc(records[dataset][alpha]['list'],elb)\n",
    "            cum = cumulative_difference_threshold(list(records[dataset][alpha]['accuracies'].values()))\n",
    "            cum = cum if cum < max([layer for layer,_,_ in records[dataset][alpha]['list']]) else max([layer for layer,_,_ in records[dataset][alpha]['list']]) \n",
    "            resultDict['cumulative_difference_threshold'].append(getTheBestAcc(records[dataset][alpha]['list'],cum))\n",
    "            res[dataset]['CUSUM'][alpha] = getTheBestAcc(records[dataset][alpha]['list'],cum)\n",
    "            # resultDict['variance_explained_threshold'].append(getTheBestAcc(records[dataset][alpha]['list'],variance_explained_threshold(list(records[dataset][alpha]['accuracies'].values()))))\n",
    "            resultDict['realThreshold'].append(round(max([acc for _,_,acc in records[dataset][alpha]['list']]),4) )\n",
    "            res[dataset]['réel'][alpha] = round(max([acc for _,_,acc in records[dataset][alpha]['list']]),4)\n",
    "\n",
    "dat = pd.DataFrame(resultDict)\n",
    "print_compare_feature_selection_protocole(res,'result_lts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fa678d-d2e7-4078-a70c-7eb3ca5d2ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Précision elbowThreshold avec tolérance 1%: 70.27%\n",
      "\n",
      "Précision cumulative_difference_threshold avec tolérance 1%: 64.86%\n"
     ]
    }
   ],
   "source": [
    "# print(f\"\\nPrécision QuartileThreshold avec tolérance 0: {vector_matching_precision(resultDict['QuartileThreshold'], resultDict['realThreshold']):.2f}%\")\n",
    "print(f\"\\nPrécision elbowThreshold avec tolérance 1%: {vector_matching_precision(resultDict['elbowThreshold'], resultDict['realThreshold'],0.01):.2f}%\")\n",
    "print(f\"\\nPrécision cumulative_difference_threshold avec tolérance 1%: {vector_matching_precision(resultDict['cumulative_difference_threshold'], resultDict['realThreshold'], 0.01):.2f}%\")\n",
    "# print(f\"\\nPrécision variance_explained_threshold avec tolérance 0: {vector_matching_precision(resultDict['variance_explained_threshold'], resultDict['realThreshold']):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7562d-2fca-463e-a847-af19adad8388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

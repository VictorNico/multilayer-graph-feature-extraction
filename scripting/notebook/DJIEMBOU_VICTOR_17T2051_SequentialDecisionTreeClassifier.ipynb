{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d805f23-ef0c-4f9f-b981-30b97450a402",
   "metadata": {},
   "source": [
    "# Python Sequential Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de43c7a-ae34-4354-9925-5175e8d7be66",
   "metadata": {},
   "source": [
    "## [Version 1](https://anderfernandez.com/en/blog/code-decision-tree-python-from-scratch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1abffe-5aaf-45b5-b997-eef8e7e4a251",
   "metadata": {},
   "source": [
    "![](https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_600/https://anderfernandez.com/wp-content/uploads/2021/01/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0970423-1430-4050-bcc9-09f86b297c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723d1cb6-4d1b-4fa0-8b41-6796db361ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Index\n",
       "0    Male     174      96      4\n",
       "1    Male     189      87      2\n",
       "2  Female     185     110      4\n",
       "3  Female     195     104      3\n",
       "4    Male     149      61      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('500_Person_Gender_Height_Weight_Index.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d70dd82-5d65-40a8-9bb2-6bd838ea1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['obese'] = (dataframe.Index >= 4).astype('int')\n",
    "dataframe.drop('Index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215ba431-c94f-4476-b8bd-436ad55328a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>obese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  obese\n",
       "0    Male     174      96      1\n",
       "1    Male     189      87      0\n",
       "2  Female     185     110      1\n",
       "3  Female     195     104      0\n",
       "4    Male     149      61      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc06ab5-54db-4127-898f-0741d6013ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d834dbe1-8133-4a09-b1e0-400a2dbf7890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataframe.drop(['obese'], axis=1)\n",
    "Y = dataframe['obese']\n",
    "\n",
    "data, test, y_train, y_test = train_test_split(X,Y)\n",
    "data['obese'] = y_train\n",
    "test['obese'] = y_test\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e90cb-2518-4046-99cc-6692a887b7ab",
   "metadata": {},
   "source": [
    "## Calculate impurity using the Gini index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0854b4-0958-474d-bfb1-d6e6fb62177d",
   "metadata": {},
   "source": [
    "$Gini = 1 – \\sum^n_{i=1}(P_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5fad82-9dad-458d-9486-ae62c1b071fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(y):\n",
    "  '''\n",
    "  Given a Pandas Series, it calculates the Gini Impurity. \n",
    "  y: variable with which calculate Gini Impurity.\n",
    "  '''\n",
    "  if isinstance(y, pd.Series):\n",
    "    p = y.value_counts()/y.shape[0]\n",
    "    gini = 1-np.sum(p**2)\n",
    "    return(gini)\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107a4952-94e2-4bae-a881-c1e160a3335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.499911111111111"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_impurity(data.Gender) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7011455a-721b-41c1-9506-941572fd7c86",
   "metadata": {},
   "source": [
    "## Calculate impurity with entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7b683-a1ff-4ac5-8492-84b821e1be6e",
   "metadata": {},
   "source": [
    "$E(S) = \\sum^c_{i=1}-p_ilog_2p_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00455d41-4d30-46aa-881e-3f4ab554cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "  '''\n",
    "  Given a Pandas Series, it calculates the entropy. \n",
    "  y: variable with which calculate entropy.\n",
    "  '''\n",
    "  if isinstance(y, pd.Series):\n",
    "    a = y.value_counts()/y.shape[0]\n",
    "    entropy = np.sum(-a*np.log2(a+1e-9))\n",
    "    return(entropy)\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d511f746-0628-466d-9546-b80d9a478daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998717537554589"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(data.Gender) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339cba16-a2da-47d1-9ef8-05dd57833b73",
   "metadata": {},
   "source": [
    "## How to choose the cuts for our decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76265e0-276d-48cb-9a9c-9f498df3b78e",
   "metadata": {},
   "source": [
    "$Information Gain_{Classification}= E(d) – \\sum \\frac{|s|}{|d|}E(s)$\n",
    "\n",
    "\n",
    "$Information Gain_{Regresion}= Variance(d) – \\sum \\frac{|s|}{|d|}Variance(s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd5cb14-c496-4bd1-88ca-173b6f6d5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y):\n",
    "  '''\n",
    "  Function to help calculate the variance avoiding nan.\n",
    "  y: variable to calculate variance to. It should be a Pandas Series.\n",
    "  '''\n",
    "  if(len(y) == 1):\n",
    "    return 0\n",
    "  else:\n",
    "    return y.var()\n",
    "\n",
    "def information_gain(y, mask, func=entropy):\n",
    "  '''\n",
    "  It returns the Information Gain of a variable given a loss function.\n",
    "  y: target variable.\n",
    "  mask: split choice.\n",
    "  func: function to be used to calculate Information Gain in case os classification.\n",
    "  '''\n",
    "  \n",
    "  a = sum(mask)\n",
    "  b = mask.shape[0] - a\n",
    "  \n",
    "  if(a == 0 or b ==0): \n",
    "    ig = 0\n",
    "  \n",
    "  else:\n",
    "    if y.dtypes != 'O':\n",
    "      ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
    "    else:\n",
    "      ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
    "  \n",
    "  return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b3e79b-7508-4f32-b386-f891bc9607ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0003936306186945321"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain(data['obese'], data['Gender'] == 'Male')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00d6cc-4ad1-4842-bd42-50c2895ddb97",
   "metadata": {},
   "source": [
    "## How to calculate the best split for a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "447725b3-79bb-4d5d-ab6b-274616c0b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_options(a):\n",
    "  '''\n",
    "  Creates all possible combinations from a Pandas Series.\n",
    "  a: Pandas Series from where to get all possible combinations. \n",
    "  '''\n",
    "  a = a.unique()\n",
    "\n",
    "  opciones = []\n",
    "  for L in range(0, len(a)+1):\n",
    "      for subset in itertools.combinations(a, L):\n",
    "          subset = list(subset)\n",
    "          opciones.append(subset)\n",
    "\n",
    "  return opciones[1:-1]\n",
    "\n",
    "def max_information_gain_split(x, y, func=entropy):\n",
    "  '''\n",
    "  Given a predictor & target variable, returns the best split, the error and the type of variable based on a selected cost function.\n",
    "  x: predictor variable as Pandas Series.\n",
    "  y: target variable as Pandas Series.\n",
    "  func: function to be used to calculate the best split.\n",
    "  '''\n",
    "\n",
    "  split_value = []\n",
    "  ig = [] \n",
    "\n",
    "  numeric_variable = True if x.dtypes != 'O' else False\n",
    "\n",
    "  # Create options according to variable type\n",
    "  if numeric_variable:\n",
    "    options = x.sort_values().unique()[1:]\n",
    "  else: \n",
    "    options = categorical_options(x)\n",
    "\n",
    "  # Calculate ig for all values\n",
    "  for val in options:\n",
    "    mask =   x < val if numeric_variable else x.isin(val)\n",
    "    val_ig = information_gain(y, mask, func)\n",
    "    # Append results\n",
    "    ig.append(val_ig)\n",
    "    split_value.append(val)\n",
    "\n",
    "  # Check if there are more than 1 results if not, return False\n",
    "  if len(ig) == 0:\n",
    "    return(None,None,None, False)\n",
    "\n",
    "  else:\n",
    "  # Get results with highest IG\n",
    "    best_ig = max(ig)\n",
    "    best_ig_index = ig.index(best_ig)\n",
    "    best_split = split_value[best_ig_index]\n",
    "    return(best_ig,best_split,numeric_variable, True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6913c53-8af7-44d7-8ecf-5426fc0054b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best split for Weight is when the variable is less than  95 \n",
      "Information Gain for that split is: 0.11056257157992241\n"
     ]
    }
   ],
   "source": [
    "weight_ig, weight_slpit, _, _ = max_information_gain_split(data['Weight'], data['obese'],)  \n",
    "\n",
    "\n",
    "print(\n",
    "  \"The best split for Weight is when the variable is less than \",\n",
    "  weight_slpit,\"\\nInformation Gain for that split is:\", weight_ig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278cded-0ec2-424b-b5fd-663185f9fd71",
   "metadata": {},
   "source": [
    "## How to choose the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50c594e-e228-464e-90bd-204b9dff4587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.021483</td>\n",
       "      <td>0.110563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Male]</td>\n",
       "      <td>174</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender    Height    Weight\n",
       "0 -0.000394  0.021483  0.110563\n",
       "1    [Male]       174        95\n",
       "2     False      True      True\n",
       "3      True      True      True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('obese', axis= 1).apply(max_information_gain_split, y = data['obese'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b63054-5e83-4ba2-8681-f7b8f9899237",
   "metadata": {},
   "source": [
    "## How to train a decision tree in Python from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f92506-d793-4d40-a6d2-3038fc0872ef",
   "metadata": {},
   "source": [
    "### Determining the depth of the tree\n",
    "We already have all the ingredients to calculate our decision tree. Now, we must create a function that, given a mask, makes us a split.\n",
    "\n",
    "In addition, we will include the different hyperparameters that a decision tree generally offers. Although we could include more, the most relevant are those that prevent the tree from growing too much, thus avoiding overfitting. These hyperparameters are as follows:\n",
    "\n",
    "__max_depth__: maximum depth of the tree. If we set it to None, the tree will grow until all the leaves are pure or the hyperparameter min_samples_split has been reached.\n",
    "\n",
    "__min_samples_split__: indicates the minimum number of observations a sheet must have to continue creating new nodes.\n",
    "\n",
    "__min_information_gain__: the minimum amount the Information Gain must increase for the tree to continue growing.\n",
    "With this in mind, let’s finish creating our decision tree from 0 in Python. To do this, we will:\n",
    "\n",
    "- Make sure that the conditions established by min_samples_split and max_depth are being fulfilled.\n",
    "- Make the split.\n",
    "- Ensure that min_information_gain if fulfilled.\n",
    "- Save the data of the split and repeat the process.\n",
    "\n",
    "\n",
    "To do this, first of all, I will create three functions: one that, given some data, returns the best split with its corresponding information, another that, given some data and a split, makes the split and returns the prediction and finally, a function that given some data, makes a prediction.\n",
    "\n",
    "Note: the prediction will only be given in the branches and basically consists of returning the mean of the data in the case of the regression or the mode in the case of the classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58671f6a-cf35-4f99-a37f-36cb694902b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(y, data):\n",
    "  '''\n",
    "  Given a data, select the best split and return the variable, the value, the variable type and the information gain.\n",
    "  y: name of the target variable\n",
    "  data: dataframe where to find the best split.\n",
    "  '''\n",
    "  masks = data.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])\n",
    "  if sum(masks.loc[3,:]) == 0:\n",
    "    return(None, None, None, None)\n",
    "\n",
    "  else:\n",
    "    # Get only masks that can be splitted\n",
    "    masks = masks.loc[:,masks.loc[3,:]]\n",
    "\n",
    "    # Get the results for split with highest IG\n",
    "    split_variable = masks.iloc[0].astype(np.float32).idxmax()\n",
    "    #split_valid = masks[split_variable][]\n",
    "    split_value = masks[split_variable][1] \n",
    "    split_ig = masks[split_variable][0]\n",
    "    split_numeric = masks[split_variable][2]\n",
    "\n",
    "    return(split_variable, split_value, split_ig, split_numeric)\n",
    "\n",
    "\n",
    "def make_split(variable, value, data, is_numeric):\n",
    "  '''\n",
    "  Given a data and a split conditions, do the split.\n",
    "  variable: variable with which make the split.\n",
    "  value: value of the variable to make the split.\n",
    "  data: data to be splitted.\n",
    "  is_numeric: boolean considering if the variable to be splitted is numeric or not.\n",
    "  '''\n",
    "  if is_numeric:\n",
    "    data_1 = data[data[variable] < value]\n",
    "    data_2 = data[(data[variable] < value) == False]\n",
    "\n",
    "  else:\n",
    "    data_1 = data[data[variable].isin(value)]\n",
    "    data_2 = data[(data[variable].isin(value)) == False]\n",
    "\n",
    "  return(data_1,data_2)\n",
    "\n",
    "def make_prediction(data, target_factor):\n",
    "  '''\n",
    "  Given the target variable, make a prediction.\n",
    "  data: pandas series for target variable\n",
    "  target_factor: boolean considering if the variable is a factor or not\n",
    "  '''\n",
    "\n",
    "  # Make predictions\n",
    "  if target_factor:\n",
    "    pred = data.value_counts().idxmax()\n",
    "  else:\n",
    "    pred = data.mean()\n",
    "\n",
    "  return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bd820-b8f5-45b9-b68c-5f021e25659e",
   "metadata": {},
   "source": [
    "### Training our decision tree in Python\n",
    "Now that we have these three functions, we can, let’s train the decision tree that we just programmed in Python.\n",
    "\n",
    "- We ensure that both min_samples_split and max_depth are fulfilled.\n",
    "\n",
    "- If they are fulfilled, we get the best split and obtain the Information Gain. If any of the conditions are not fulfilled, we make the prediction.\n",
    "\n",
    "- We check that the Information Gain Comprobamos passes the minimum amount set by min_information_gain.\n",
    "\n",
    "- If the condition above is fulfilled, we make the split and save the decision. If it is not fulfilled, then we make the prediction.\n",
    "\n",
    "We will do this process recursively, that is, the function will call itself. The result of the function will be the rules you follow to make the decision:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ccfd2b-8af7-4c08-af06-34536150b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
    "  '''\n",
    "  Trains a Decission Tree\n",
    "  data: Data to be used to train the Decission Tree\n",
    "  y: target variable column name\n",
    "  target_factor: boolean to consider if target variable is factor or numeric.\n",
    "  max_depth: maximum depth to stop splitting.\n",
    "  min_samples_split: minimum number of observations to make a split.\n",
    "  min_information_gain: minimum ig gain to consider a split to be valid.\n",
    "  max_categories: maximum number of different values accepted for categorical values. High number of values will slow down learning process. R\n",
    "  '''\n",
    "\n",
    "  # Check that max_categories is fulfilled\n",
    "  if counter==0:\n",
    "    types = data.dtypes\n",
    "    check_columns = types[types == \"object\"].index\n",
    "    for column in check_columns:\n",
    "      var_length = len(data[column].value_counts()) \n",
    "      if var_length > max_categories:\n",
    "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
    "\n",
    "  # Check for depth conditions\n",
    "  if max_depth == None:\n",
    "    depth_cond = True\n",
    "\n",
    "  else:\n",
    "    if counter < max_depth:\n",
    "      depth_cond = True\n",
    "\n",
    "    else:\n",
    "      depth_cond = False\n",
    "\n",
    "  # Check for sample conditions\n",
    "  if min_samples_split == None:\n",
    "    sample_cond = True\n",
    "\n",
    "  else:\n",
    "    if data.shape[0] > min_samples_split:\n",
    "      sample_cond = True\n",
    "\n",
    "    else:\n",
    "      sample_cond = False\n",
    "\n",
    "  # Check for ig condition\n",
    "  if depth_cond & sample_cond:\n",
    "\n",
    "    var,val,ig,var_type = get_best_split(y, data)\n",
    "\n",
    "    # If ig condition is fulfilled, make split \n",
    "    if ig is not None and ig >= min_information_gain:\n",
    "\n",
    "      counter += 1\n",
    "\n",
    "      left,right = make_split(var, val, data,var_type)\n",
    "\n",
    "      # Instantiate sub-tree\n",
    "      split_type = \"<=\" if var_type else \"in\"\n",
    "      question =   \"{} {}  {}\".format(var,split_type,val)\n",
    "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val) \n",
    "      subtree = {question: []}\n",
    "\n",
    "\n",
    "      # Find answers (recursion)\n",
    "      yes_answer = recursive_train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      no_answer = recursive_train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      if yes_answer == no_answer:\n",
    "        subtree = yes_answer\n",
    "\n",
    "      else:\n",
    "        subtree[question].append(yes_answer)\n",
    "        subtree[question].append(no_answer)\n",
    "\n",
    "    # If it doesn't match IG condition, make prediction\n",
    "    else:\n",
    "      pred = make_prediction(data[y],target_factor)\n",
    "      return pred\n",
    "\n",
    "   # Drop dataset if doesn't match depth or sample conditions\n",
    "  else:\n",
    "    pred = make_prediction(data[y],target_factor)\n",
    "    return pred\n",
    "\n",
    "  return subtree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180b5f76-3964-47f8-910a-ef8ca99883b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weight <=  95': [{'Height <=  148': [1,\n",
       "    {'Height <=  173': [{'Weight <=  74': [0, 1]}, 0]}]},\n",
       "  {'Height <=  187': [1, {'Weight <=  114': [0, 1]}]}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 5\n",
    "min_samples_split = 20\n",
    "min_information_gain  = 1e-5\n",
    "\n",
    "\n",
    "decisiones = recursive_train_tree(data,'obese',True, max_depth,min_samples_split,min_information_gain)\n",
    "\n",
    "\n",
    "decisiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c3aa5-6539-40f9-b264-481beba0cdb7",
   "metadata": {},
   "source": [
    "It is done! The decision tree we just coded in Python has created all the rules that it will use to make predictions.\n",
    "\n",
    "Now, there would only be one thing left: convert those rules into concrete actions that the algorithm can use to classify new data. Let’s go for it!\n",
    "\n",
    "Predict using our decision tree in Python\n",
    "To make the prediction, we are going to take an observation and the decision tree. These decisions can be converted into real conditions by splitting them.\n",
    "\n",
    "So, to make the prediction we are going to:\n",
    "\n",
    "- Break the decision into several chunks.\n",
    "\n",
    "- Check the type of decision that it is (numerical or categorical).\n",
    "\n",
    "- Considering the type of variable that it is, check the decision boundary. If the decision is fulfilled, return the result, if it is not, then continue with the decision.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "085a370d-c2a0-4b8b-a536-19c7dcd66de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_datos(observacion, arbol):\n",
    "    # print(arbol.keys())\n",
    "    question = list(arbol.keys())[0] \n",
    "    \n",
    "    if question.split()[1] == '<=':\n",
    "    \n",
    "        if observacion[question.split()[0]] <= float(question.split()[2]):\n",
    "          answer = arbol[question][0]\n",
    "        else:\n",
    "          answer = arbol[question][1]\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if observacion[question.split()[0]] in (question.split()[2]):\n",
    "          answer = arbol[question][0]\n",
    "        else:\n",
    "          answer = arbol[question][1]\n",
    "    \n",
    "    # If the answer is not a dictionary\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "    return clasificar_datos(observacion, answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "438753bf-debf-4ee8-bf48-4da84c78a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(true_labels, predicted_labels, labels):\n",
    "    num_classes = len(labels)\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "\n",
    "    for true, predicted in zip(true_labels, predicted_labels):\n",
    "        true_index = labels.index(true)\n",
    "        predicted_index = labels.index(predicted)\n",
    "        confusion_matrix[true_index, predicted_index] += 1\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, labels):\n",
    "    df = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n",
    "    html_table = df.to_html()\n",
    "\n",
    "    return HTML(html_table)\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = sum([(y_true[i] == 1) and (y_pred[i] == 1) for i in list(range(len(y_pred)))])\n",
    "    false_positives = sum([(y_true[i] == 0) and (y_pred[i] == 1) for i in list(range(len(y_pred)))])\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_predictions = sum([y_true[i] == y_pred[i]  for i in list(range(len(y_pred)))])\n",
    "    total_predictions = len(y_true)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_val = precision(y_true, y_pred)\n",
    "    recall_val = recall(y_true, y_pred)\n",
    "    f1 = 2 * ((precision_val * recall_val) / (precision_val + recall_val))\n",
    "    return f1\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = sum([(y_true[i] == 1) and (y_pred[i] == 1) for i in list(range(len(y_pred)))])\n",
    "    false_negatives = sum([(y_true[i] == 1) and (y_pred[i] == 0) for i in list(range(len(y_pred)))])\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "294dcfc7-a0d5-4040-aa0a-492008ff5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop('obese', axis= 1).apply(clasificar_datos, arbol = decisiones)\n",
    "#clasificar_datos(data.drop('obese', axis= 1),decisiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49d3bad7-50f3-47b9-b95c-9ea77a4df85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298    0\n",
       "159    1\n",
       "427    1\n",
       "450    1\n",
       "123    1\n",
       "      ..\n",
       "308    0\n",
       "80     1\n",
       "396    1\n",
       "267    1\n",
       "352    0\n",
       "Length: 125, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = test.apply(lambda row: clasificar_datos(row.drop('obese'), arbol=decisiones), axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84ea4583-72ed-44b2-9ae9-28f48825eaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "true_labels = test['obese'].values.tolist()\n",
    "predicted_labels = result.tolist()\n",
    "labels = np.unique(result).tolist()\n",
    "\n",
    "cm = compute_confusion_matrix(true_labels, predicted_labels, labels)\n",
    "html_table = plot_confusion_matrix(cm, labels)\n",
    "\n",
    "# Display the HTML table inside the notebook\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1bf372f-1b4e-4294-8f23-1466e82eba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.912,\n",
      "precision: 0.8764044943820225,\n",
      "Recall: 1.0,\n",
      "F1-score: 0.9341317365269461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Accuracy: {accuracy(true_labels,predicted_labels)},\n",
    "precision: {precision(true_labels,predicted_labels)},\n",
    "Recall: {recall(true_labels,predicted_labels)},\n",
    "F1-score: {f1_score(true_labels,predicted_labels)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "611310a0-8926-40ed-bc6f-6112ed382076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interative_train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
    "    '''\n",
    "        Trains a Decission Tree\n",
    "        data: Data to be used to train the Decission Tree\n",
    "        y: target variable column name\n",
    "        target_factor: boolean to consider if target variable is factor or numeric.\n",
    "        max_depth: maximum depth to stop splitting.\n",
    "        min_samples_split: minimum number of observations to make a split.\n",
    "        min_information_gain: minimum ig gain to consider a split to be valid.\n",
    "        max_categories: maximum number of different values accepted for categorical values. High number of values will slow down learning process. R\n",
    "    '''\n",
    "    \n",
    "\n",
    "    stack = []  # Stack to store nodes to be processed\n",
    "    root = {\n",
    "        'data': data,\n",
    "        'depth': 0,\n",
    "        'node': {}\n",
    "    }\n",
    "    stack.append(root)\n",
    "    while len(stack) != 0:\n",
    "        \n",
    "        current = stack.pop()\n",
    "        xy_current = current['data']\n",
    "        depth = current['depth']\n",
    "        current_node = current['node']\n",
    "        # Check for ig condition\n",
    "        # print(f\"{root} --- {current}\")\n",
    "          # Check that max_categories is fulfilled\n",
    "        if depth == 0:\n",
    "            types = xy_current.dtypes\n",
    "            check_columns = types[types == \"object\"].index\n",
    "            for column in check_columns:\n",
    "              var_length = len(data[column].value_counts()) \n",
    "              if var_length > max_categories:\n",
    "                raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
    "        \n",
    "        # Check for depth conditions\n",
    "        if max_depth == None:\n",
    "            depth_cond = True\n",
    "        \n",
    "        else:\n",
    "            if counter < max_depth:\n",
    "              depth_cond = True\n",
    "            \n",
    "            else:\n",
    "              depth_cond = False\n",
    "        \n",
    "        # Check for sample conditions\n",
    "        if min_samples_split == None:\n",
    "            sample_cond = True\n",
    "        \n",
    "        else:\n",
    "            if data.shape[0] > min_samples_split:\n",
    "              sample_cond = True\n",
    "            \n",
    "            else:\n",
    "              sample_cond = False\n",
    "        \n",
    "        # Check for ig condition\n",
    "        if depth_cond & sample_cond:\n",
    "            \n",
    "            var,val,ig,var_type = get_best_split(y, xy_current)\n",
    "            \n",
    "            # If ig condition is fulfilled, make split \n",
    "            if ig is not None and ig >= min_information_gain:\n",
    "                left,right = make_split(var, val, xy_current,var_type)\n",
    "                \n",
    "                # Instantiate sub-tree\n",
    "                split_type = \"<=\" if var_type else \"in\"\n",
    "                question =   \"{} {}  {}\".format(var,split_type,val)\n",
    "\n",
    "                # Update current node with split information\n",
    "            \n",
    "                current_node['col'] = var\n",
    "                current_node['cutoff'] = ig\n",
    "                current_node['val'] = val\n",
    "                current_node['condition'] = question\n",
    "                current_node['depth'] = depth\n",
    "    \n",
    "                # Create left and right child nodes\n",
    "                current_node['left'] = {}\n",
    "                current_node['right'] = {}\n",
    "    \n",
    "                # Push child nodes onto the stack\n",
    "                stack.append({\n",
    "                    'data': left,\n",
    "                    'depth': depth + 1,\n",
    "                    'node': current_node['left']\n",
    "                })\n",
    "                stack.append({\n",
    "                    'data': right,\n",
    "                    'depth': depth + 1,\n",
    "                    'node': current_node['right']\n",
    "                })\n",
    "    \n",
    "            # If it doesn't match IG condition, make prediction\n",
    "            else:\n",
    "                pred = make_prediction(xy_current[y],target_factor)\n",
    "                current_node['col'] = var\n",
    "                current_node['cutoff'] = ig\n",
    "                current_node['val'] = val\n",
    "                current_node['condition'] = pred\n",
    "                \n",
    "            \n",
    "        # Drop dataset if doesn't match depth or sample conditions\n",
    "        else:\n",
    "            pred = make_prediction(xy_current[y],target_factor)\n",
    "            current_node['col'] = var\n",
    "            current_node['cutoff'] = ig\n",
    "            current_node['val'] = val\n",
    "            current_node['condition'] = pred\n",
    "    \n",
    "    return root\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3280b2f6-24d9-4bed-a7fd-6e607ee48fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':      Gender  Height  Weight  obese\n",
       " 279    Male     188      57      0\n",
       " 349  Female     157      60      0\n",
       " 109    Male     149      66      0\n",
       " 210  Female     150      84      1\n",
       " 52     Male     163     110      1\n",
       " ..      ...     ...     ...    ...\n",
       " 226    Male     166      70      0\n",
       " 489  Female     179     150      1\n",
       " 476  Female     164     142      1\n",
       " 206    Male     145      99      1\n",
       " 34   Female     157     153      1\n",
       " \n",
       " [375 rows x 4 columns],\n",
       " 'depth': 0,\n",
       " 'node': {'col': 'Weight',\n",
       "  'cutoff': 0.11056257157992241,\n",
       "  'val': 95,\n",
       "  'condition': 'Weight <=  95',\n",
       "  'depth': 0,\n",
       "  'left': {'col': 'Height',\n",
       "   'cutoff': 0.07581614151187768,\n",
       "   'val': 148,\n",
       "   'condition': 'Height <=  148',\n",
       "   'depth': 1,\n",
       "   'left': {'col': 'Gender', 'cutoff': 0.0, 'val': ['Female'], 'condition': 1},\n",
       "   'right': {'col': 'Height',\n",
       "    'cutoff': 0.021336780188078344,\n",
       "    'val': 173,\n",
       "    'condition': 'Height <=  173',\n",
       "    'depth': 2,\n",
       "    'left': {'col': 'Weight',\n",
       "     'cutoff': 0.13242859470658067,\n",
       "     'val': 74,\n",
       "     'condition': 'Weight <=  74',\n",
       "     'depth': 3,\n",
       "     'left': {'col': 'Height',\n",
       "      'cutoff': 0.005976479660690183,\n",
       "      'val': 151,\n",
       "      'condition': 'Height <=  151',\n",
       "      'depth': 4,\n",
       "      'left': {'col': 'Weight',\n",
       "       'cutoff': 0.21428571428571427,\n",
       "       'val': 67,\n",
       "       'condition': 'Weight <=  67',\n",
       "       'depth': 5,\n",
       "       'left': {'col': 'Gender',\n",
       "        'cutoff': 0.0,\n",
       "        'val': ['Male'],\n",
       "        'condition': 0},\n",
       "       'right': {'col': 'Height', 'cutoff': 0.0, 'val': 150, 'condition': 1}},\n",
       "      'right': {'col': 'Gender',\n",
       "       'cutoff': 0.0,\n",
       "       'val': ['Female'],\n",
       "       'condition': 0}},\n",
       "     'right': {'col': 'Weight',\n",
       "      'cutoff': 0.02801120448179273,\n",
       "      'val': 82,\n",
       "      'condition': 'Weight <=  82',\n",
       "      'depth': 4,\n",
       "      'left': {'col': 'Height',\n",
       "       'cutoff': 0.26785714285714285,\n",
       "       'val': 162,\n",
       "       'condition': 'Height <=  162',\n",
       "       'depth': 5,\n",
       "       'left': {'col': 'Gender',\n",
       "        'cutoff': 0.0,\n",
       "        'val': ['Male'],\n",
       "        'condition': 1},\n",
       "       'right': {'col': 'Gender',\n",
       "        'cutoff': 0.0,\n",
       "        'val': ['Male'],\n",
       "        'condition': 0}},\n",
       "      'right': {'col': 'Gender',\n",
       "       'cutoff': 0.0,\n",
       "       'val': ['Female'],\n",
       "       'condition': 1}}},\n",
       "    'right': {'col': 'Gender',\n",
       "     'cutoff': 0.0,\n",
       "     'val': ['Male'],\n",
       "     'condition': 0}}},\n",
       "  'right': {'col': 'Height',\n",
       "   'cutoff': 0.014507144920161176,\n",
       "   'val': 187,\n",
       "   'condition': 'Height <=  187',\n",
       "   'depth': 1,\n",
       "   'left': {'col': 'Height',\n",
       "    'cutoff': 0.0007205908845253125,\n",
       "    'val': 183,\n",
       "    'condition': 'Height <=  183',\n",
       "    'depth': 2,\n",
       "    'left': {'col': 'Gender', 'cutoff': 0.0, 'val': ['Male'], 'condition': 1},\n",
       "    'right': {'col': 'Weight',\n",
       "     'cutoff': 0.1238095238095238,\n",
       "     'val': 106,\n",
       "     'condition': 'Weight <=  106',\n",
       "     'depth': 3,\n",
       "     'left': {'col': 'Gender',\n",
       "      'cutoff': 0.0,\n",
       "      'val': ['Female'],\n",
       "      'condition': 0},\n",
       "     'right': {'col': 'Gender',\n",
       "      'cutoff': 0.0,\n",
       "      'val': ['Female'],\n",
       "      'condition': 1}}},\n",
       "   'right': {'col': 'Weight',\n",
       "    'cutoff': 0.1979638009049774,\n",
       "    'val': 114,\n",
       "    'condition': 'Weight <=  114',\n",
       "    'depth': 2,\n",
       "    'left': {'col': 'Gender', 'cutoff': 0.0, 'val': ['Male'], 'condition': 0},\n",
       "    'right': {'col': 'Weight',\n",
       "     'cutoff': 3.469446951953614e-18,\n",
       "     'val': 149,\n",
       "     'condition': 1}}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 5\n",
    "min_samples_split = 20\n",
    "min_information_gain  = 1e-5\n",
    "\n",
    "\n",
    "decisiones1 = interative_train_tree(data,'obese',True, max_depth,min_samples_split,min_information_gain)\n",
    "\n",
    "\n",
    "decisiones1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f561980-9cb0-4909-8314-11b32da238c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(observation, tree):\n",
    "    # print(arbol.keys())\n",
    "    question = tree['condition']\n",
    "    \n",
    "    if question.split()[1] == '<=':\n",
    "    \n",
    "        if observation[question.split()[0]] <= float(question.split()[2]):\n",
    "          answer = tree['left']\n",
    "        else:\n",
    "          answer = tree['right']\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if observation[question.split()[0]] in (question.split()[2]):\n",
    "          answer = tree['left']\n",
    "        else:\n",
    "          answer = tree['right']\n",
    "    \n",
    "    # If the answer is not a dictionary\n",
    "    if not isinstance(answer['condition'], str):\n",
    "        return answer['condition']\n",
    "        \n",
    "    return predict(observation, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ee0c4f6-fe85-41bd-b911-0a3b5d0f0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = test.apply(lambda row: predict(row.drop('obese'), tree=decisiones1['node']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc00537-e9f9-4094-95c6-8e45aaf219fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>obese</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Female</td>\n",
       "      <td>187</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Male</td>\n",
       "      <td>181</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Female</td>\n",
       "      <td>187</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Male</td>\n",
       "      <td>162</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Female</td>\n",
       "      <td>184</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Male</td>\n",
       "      <td>196</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Male</td>\n",
       "      <td>164</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Male</td>\n",
       "      <td>187</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Male</td>\n",
       "      <td>154</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Female</td>\n",
       "      <td>160</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Height  Weight  obese  predicted\n",
       "298  Female     187      92      0          0\n",
       "159    Male     181     105      1          1\n",
       "427  Female     187     130      1          1\n",
       "450    Male     162     157      1          1\n",
       "123  Female     184     160      1          1\n",
       "..      ...     ...     ...    ...        ...\n",
       "308    Male     196      69      0          0\n",
       "80     Male     164      75      0          0\n",
       "396    Male     187      96      0          0\n",
       "267    Male     154     145      1          1\n",
       "352  Female     160      51      0          0\n",
       "\n",
       "[125 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = test.copy(deep=True)\n",
    "dt['predicted'] = result1\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b5dfa1e-c637-4795-8d81-1bde3b35ffe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "true_labels = test['obese'].values.tolist()\n",
    "predicted_labels = result1.tolist()\n",
    "labels = np.unique(result1).tolist()\n",
    "\n",
    "cm = compute_confusion_matrix(true_labels, predicted_labels, labels)\n",
    "html_table = plot_confusion_matrix(cm, labels)\n",
    "\n",
    "# Display the HTML table inside the notebook\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beae6870-9e70-43be-857b-60c61cc26387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.952,\n",
      "precision: 0.9285714285714286,\n",
      "Recall: 1.0,\n",
      "F1-score: 0.962962962962963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Accuracy: {accuracy(true_labels,predicted_labels)},\n",
    "precision: {precision(true_labels,predicted_labels)},\n",
    "Recall: {recall(true_labels,predicted_labels)},\n",
    "F1-score: {f1_score(true_labels,predicted_labels)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c378f-9f10-4458-8bb1-93110bc729b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

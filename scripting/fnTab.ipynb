{
 "cells": [
  {
   "cell_type": "code",
   "id": "6bdcc12f-4384-45a2-98bd-5232a6a26ff6",
   "metadata": {
    "tags": [],
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "795ba9f3-b812-4c82-8d7e-df304cb6fc9f",
   "metadata": {},
   "source": [
    "!pip install unidecode"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e849a3f5eb2a9cbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73d2b14e5a3472e",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append(f'{os.getcwd()}/modules')"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb4dae4e-486b-4e8a-8fa2-f2000fa0d7ca",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-25T12:35:00.336702Z",
     "start_time": "2024-04-25T12:34:57.053684Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "import importlib\n",
    "# List des modules to load\n",
    "modules = [\n",
    "    'modules.file',\n",
    "    'modules.eda',\n",
    "    'modules.graph',\n",
    "    'modules.report',\n",
    "    'modules.preprocessing',\n",
    "    'modules.modeling',\n",
    "    # 'memory_profiler'\n",
    "]\n",
    "\n",
    "# Charger les bibliothèques en utilisant importlib\n",
    "with tqdm(total=len(modules), desc=\"MODULES LOADING\", ncols=80) as pbar:\n",
    "    for module_name in modules:\n",
    "        try:\n",
    "            # module = importlib.import_module(library_name)\n",
    "            exec(f'from {module_name} import *')\n",
    "\n",
    "        except ImportError:\n",
    "            # En cas d'erreur lors du chargement de la bibliothèque\n",
    "            pbar.set_description(f\"Unable to load {module_name}\")\n",
    "        else:\n",
    "            # Succès lors du chargement de la bibliothèque\n",
    "            pbar.set_description(f\"{module_name} successfull loaded\")\n",
    "        finally:\n",
    "            pbar.update(1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.modeling successfull loaded: 100%|████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "23c335eecb11b273",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.version"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89d704b7-48fb-4391-a1f2-432a0ad6cbc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "from unidecode import unidecode"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1aff5d8-972a-4876-ad9b-c38578e9b559",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as pl\n",
    "from matplotlib.patches import Patch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3260abe5-bbb2-4aac-9f68-0eda36cb2dd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17427ee1-81f1-4ce7-ae59-844140a9c1eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#!pip install --upgrade shap\n",
    "from matplotlib.font_manager import FontProperties"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e3a60ed-2aec-4322-8ce3-763536688465",
   "metadata": {
    "tags": []
   },
   "source": [
    "import shap"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "886a2309-131f-4f25-90a4-a721d7d347f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "from copy import deepcopy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d77e7ba0-d568-4584-b0c3-e938d1c17f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "svg = \"<?xml version='1.0' ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background='new 0 0 32 32' height='12px' id='Layer_1' version='1.1' viewBox='0 0 32 32' width='12px' xml:space='preserve' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><path d='M18.221,7.206l9.585,9.585c0.879,0.879,0.879,2.317,0,3.195l-0.8,0.801c-0.877,0.878-2.316,0.878-3.194,0  l-7.315-7.315l-7.315,7.315c-0.878,0.878-2.317,0.878-3.194,0l-0.8-0.801c-0.879-0.878-0.879-2.316,0-3.195l9.587-9.585  c0.471-0.472,1.103-0.682,1.723-0.647C17.115,6.524,17.748,6.734,18.221,7.206z' fill='#515151'/></svg>\"\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67d2ed2d-66ce-4df3-b112-69c5d9cb35ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# coding: utf-8\n",
    "import statistics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3091a1cf-f7be-4be4-b44d-87c31ad7a02e",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_filenames(root_dir, func, verbose=False):\n",
    "    data_filenames = []\n",
    "    # Walk through the directories and files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # dirpath: current directory path\n",
    "        # dirnames: list of directories in the current directory\n",
    "        # filenames: list of files in the current directory\n",
    "\n",
    "        # Print the current directory\n",
    "        print('Directory:', dirpath)  if verbose else None\n",
    "        # Print all the subdirectories\n",
    "        if verbose:\n",
    "            for dirname in dirnames:\n",
    "                print('Subdirectory:', os.path.join(dirpath, dirname))\n",
    "\n",
    "        # Print all the files\n",
    "        for filename in filenames:\n",
    "            if func(filename) and not (('x_' in filename) or ('y_' in filename) or ('metric' in filename)):\n",
    "                print('File:', os.path.join(dirpath, filename)) if verbose else None\n",
    "                data_filenames.append(os.path.join(dirpath, filename))\n",
    "\n",
    "        # Print an empty line to separate directories\n",
    "        print()  if verbose else None\n",
    "    return data_filenames"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8cda763e-846d-42d2-ae9d-0dc162e134c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "MLN_F = lambda x: (('classic_mln_' in x) and not('classic_mln_-' in x)) # find metric of model where mln were added\n",
    "MLN__F = lambda x: (('classic_mln_-' in x)) # where mln attribut were removed first\n",
    "MLN_C_F = lambda x: (('classic_-' in x)) # where mln attribut were removed first\n",
    "MLN_C= lambda x: (('classic_' in x)) # where mln attribut were removed first\n",
    "\n",
    "INTER_F = lambda x: (not('_max_' in x) and ('inter' in x))\n",
    "INTRA_F = lambda x: (not('_max_' in x) and ('intra' in x))\n",
    "COMBINE_F = lambda x: (not('_max_' in x) and ('combine' in x))\n",
    "INTER_P_F = lambda x: (not('_max_' in x) and ('inter' in x) and ('perso' in x))\n",
    "INTRA_P_F = lambda x: (not('_max_' in x) and ('intra' in x) and ('perso' in x))\n",
    "COMBINE_P_F = lambda x: (not('_max_' in x) and ('combine' in x) and ('perso' in x))\n",
    "INTER_MAX_F = lambda x: (('_max_' in x) and ('inter' in x))\n",
    "INTRA_MAX_F = lambda x: (('_max_' in x) and ('intra' in x))\n",
    "COMBINE_MAX_F = lambda x: (('_max_' in x) and ('combine' in x))\n",
    "INTER_P_MAX_F = lambda x: (('_max_' in x) and ('inter' in x) and ('perso' in x))\n",
    "INTRA_P_MAX_F = lambda x: (('_max_' in x) and ('intra' in x) and ('perso' in x))\n",
    "COMBINE_P_MAX_F = lambda x: (('_max_' in x) and ('combine' in x) and ('perso' in x))\n",
    "DEGREE_F = lambda x: (('degree' in x))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install memory_profiler",
   "id": "9727e97bc1f13adf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T12:37:10.977110Z",
     "start_time": "2024-04-25T12:35:04.139833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from memory_profiler import profile\n",
    "from modules.pipeline import *\n",
    "\n",
    "graph = read_graph(\"/Users/djiemboutienctheuvictornico/Documents/MyFolders/ACADEMIC/M2_thesis/scripting/outputs1/AFB/withClass/0.1/qualitative/mlna_1/graph_storage/Motif_mln_1436_9_2024_04_24_21_01_19.gml.gz\")\n",
    "\n",
    "@profile\n",
    "def gpuP():\n",
    "    for i in range(100):\n",
    "        gpu  = dict(sorted(pagerank(graph).items(), key=lambda x: abs(x[1]), reverse=False)[-5:])\n",
    "@profile\n",
    "def cpuP():\n",
    "    for i in range(100):\n",
    "        cpu  = dict(sorted(nx.pagerank(graph).items(), key=lambda x: abs(x[1]), reverse=False)[-5:])\n",
    "gpuP()\n",
    "cpuP()\n",
    "print(f\"\"\"\n",
    "cpu : {cpu},\n",
    "gpu : {gpu}\n",
    "\"\"\")"
   ],
   "id": "ed9005d54307c140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /var/folders/1w/cp3gd6d5749_6bq40_6_35vh0000gn/T/ipykernel_2256/373955235.py\n",
      "ERROR: Could not find file /var/folders/1w/cp3gd6d5749_6bq40_6_35vh0000gn/T/ipykernel_2256/373955235.py\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m gpuP()\n\u001B[1;32m     14\u001B[0m cpuP()\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;124mcpu : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcpu\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;124mgpu : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgpu\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cpu' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# classic_f = [\n",
    "#     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None)\n",
    "#     for file in get_filenames(\n",
    "#         root_dir=f'{os.getcwd()}/outputs/AFB/data_selection_storage',\n",
    "#         func=MLN_C,\n",
    "#         verbose=False\n",
    "#     )\n",
    "# ][-1]\n",
    "# classic_f"
   ],
   "id": "5b31f33de2b14054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# best = classic_f.sort_values(\n",
    "#     by=\"accuracy\",\n",
    "#     axis=0,\n",
    "#     ascending=False\n",
    "#     # ,key=lambda row: abs(row)\n",
    "# ).head(1)\n",
    "# (list(best.index)[0],best[\"accuracy\"][list(best.index)[0]])"
   ],
   "id": "341d776f3b48d21c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9208f6cc-f0fc-40da-9cbd-4e494d23b239",
   "metadata": {
    "tags": []
   },
   "source": [
    "def metrics_analyzer_statistics_tab_f_1(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, alpha=None, type='qualitative'):\n",
    "    \"\"\" build comparative table for P, G and M logics on personalisation\n",
    "    \n",
    "    Args:\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">Accuracy</td><td colspan=\"3\">Precision</td><td colspan=\"3\">Recall</td><td colspan=\"3\">F1-score</td></tr><tr>{\"<td>G</td><td>P</td><td>M</td>\"*4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'precision': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'recall': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                print(f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', case_k)\n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                \n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    'mixed':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/{type}/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/mixed/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/mixed/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/{type}/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                #print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key]['G'].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key]['P'].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key]['M'].append(round(files['mixed'][key].loc[model,metric],4))\n",
    "                            #totalImpact[metric][\"P\"].append(tab1_body_model[model][metric][key]['P'] >= tab1_body_model[model][metric][key]['G'])\n",
    "                            #totalImpact[metric][\"G\"].append(tab1_body_model[model][metric][key]['P'] <= tab1_body_model[model][metric][key]['P'])\n",
    "        \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "            tab1_body+= f'<tr> <td rowspan=\"2\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # add metric in the vector\n",
    "                    totalImpact[metric][\"P\"].append((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) <= max(tab1_body_model[model][metric][key][\"P\"])))\n",
    "                    totalImpact[metric][\"G\"].append((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))\n",
    "                    totalImpact[metric][\"M\"].append((max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"G\"])))\n",
    "        \n",
    "                    tab1_body+= (f'<td>{\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'+\n",
    "                                 f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"M\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'\n",
    "                                ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"M\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}</td></tr>')\n",
    "        tab1_body+= f'<tr> <td colspan=\"2\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            tab1_body+= (f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"P\"]) >= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"P\"]) >= sum(totalImpact[metric][\"M\"])))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"P\"]) <= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"M\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"P\"]) <= sum(totalImpact[metric][\"M\"])))}</td>'\n",
    "                            ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"P\"]) >= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"P\"]) >= sum(totalImpact[metric][\"M\"])))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"P\"]) <= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"M\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"P\"]) <= sum(totalImpact[metric][\"M\"])))}</td></tr>')\n",
    "            \n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab1')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab1/Statistical comparaison of approachs in {data_folder} on global logic {alpha}.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e624bca0-8b98-49df-b047-0e47596eb585",
   "metadata": {
    "tags": []
   },
   "source": [
    "get_qualitative_from_cols = lambda x:(list(set([\n",
    "    var.split(\"__\")[1] for var in [\n",
    "        coll \n",
    "        for coll in [\n",
    "            col \n",
    "            for col in x \n",
    "                if not (\n",
    "                    ('precision' in col ) \n",
    "                    or ('accuracy' in col ) \n",
    "                    or ('recall' in col) \n",
    "                    or ('f1-score' in col)\n",
    "                )\n",
    "            ] \n",
    "            if (\"__\" in coll)\n",
    "        ]\n",
    "    ]\n",
    ")))\n",
    "get_quantitative_from_cols = lambda x:(list(set([\n",
    "    var.split(\"_\")[1] for var in [#___\n",
    "        coll\n",
    "        for coll in [\n",
    "            col\n",
    "            for col in x\n",
    "            if not (\n",
    "                    ('precision' in col )\n",
    "                    or ('accuracy' in col )\n",
    "                    or ('recall' in col)\n",
    "                    or ('f1-score' in col)\n",
    "            )\n",
    "        ]\n",
    "        if (\"__\" in coll)\n",
    "    ]\n",
    "]\n",
    ")))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e5aecf1-35ec-49cf-ae19-297913705389",
   "metadata": {
    "tags": []
   },
   "source": [
    "def analyzer_launcher(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None,logics=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        quant_col = get_quantitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)])) if layers == None else layers\n",
    "        for i in [0.1,0.5,0.9,0.85]:\n",
    "            analytical_func(\n",
    "                cols=quali_col if not('_' in dataset_name) else quant_col, \n",
    "                outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}/{i}', \n",
    "                cwd=os.getcwd(), \n",
    "                data_folder=dataset_name, \n",
    "                classic_metrics=classic_f, \n",
    "                models_name=models_name,\n",
    "                layers= layers, \n",
    "                approach= approach,\n",
    "                alpha = i,\n",
    "                type='qualitative' if not('_' in dataset_name) else 'quantitative'\n",
    "                ) if aggregation_f == None else analytical_func(\n",
    "                cols=quali_col if not('_' in dataset_name) else quant_col, \n",
    "                outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}/{i}', \n",
    "                cwd=os.getcwd(), \n",
    "                data_folder=dataset_name, \n",
    "                classic_metrics=classic_f, \n",
    "                models_name=models_name,\n",
    "                layers= layers if layers != None else list(set([1, 2, len(quali_col)])), \n",
    "                approach= approach,\n",
    "                aggregation_f=aggregation_f,\n",
    "                alpha=i,\n",
    "                logics=logics,\n",
    "                type='qualitative' if not('_' in dataset_name) else 'quantitative'\n",
    "                )\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a85acf7f-4569-409d-a8a6-36ea94b241e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "layers = [1]\n",
    "approach = ['classic_mln','classic_mln_-_mlna']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "364ed4f10ed5e418",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60ea6117-dc08-4397-a515-5c559e5179a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "analyzer_launcher(outputs_name=\"outputs\", analytical_func=metrics_analyzer_statistics_tab_f_1, layers=layers, approach=approach)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea955056-7e98-4092-af2d-28439430809c",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_2(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for i, key in enumerate(layers)}\n",
    "        totalImpact = {\n",
    "            'accuracy': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'precision': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'recall': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'f1-score': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)}\n",
    "        }\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"3\" rowspan=\"2\">{x}</td><td colspan=\"{len(mlnL)}\">Accuracy</td><td colspan=\"{len(mlnL)}\">Precision</td><td colspan=\"{len(mlnL)}\">Recall</td><td colspan=\"{len(mlnL)}\">F1-score</td></tr><tr>{\"\".join([\"<td>\"+key+\"</td>\" for key in mlnL.keys()]) *4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "            \n",
    "        dictio = {\n",
    "            'classic_-_mlna': 'Classic - Att',\n",
    "            'classic_mln': 'Classic + MLN',\n",
    "            'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "            'classic': 'Classic'\n",
    "        }\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"G\"].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"P\"].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            \n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}    \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                tab1_body+= f'<tr> <td rowspan=\"4\">{model}</td>'\n",
    "                # fetch approach\n",
    "                for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                    # fetch evaluation metric\n",
    "                    tab1_body+= (f'<tr> <td rowspan=\"2\">{dictio[key]}</td>') if i != 0 else (f'<td rowspan=\"2\">{dictio[key]}</td>')\n",
    "                    for l,logic in enumerate(logics.keys()):\n",
    "                        tab1_body+= (f'<tr><td>{logics[logic]}</td>') if l != 0 else (f'<td>{logics[logic]}</td>')\n",
    "                        for y, metric in enumerate(metrics):\n",
    "                            #print(f\"{y}--\")\n",
    "                            # fetch layers\n",
    "                            for z, layer in enumerate(mlnL.keys()):\n",
    "                                #print(f\"{z};\")\n",
    "                                # add metric in the vector\n",
    "                                maxi = [max(tab1_body_model[model][metric][key][lay][logic]) for lay in mlnL ]\n",
    "                                totalImpact[metric][layer].append(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))\n",
    "                    \n",
    "                                tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td></tr>') if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                            f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td>')\n",
    "                            \n",
    "        tab1_body+= f'<tr> <td colspan=\"3\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            for z, layer in enumerate(mlnL.keys()):\n",
    "                maxi = [sum(totalImpact[metric][lay]) for lay in mlnL]\n",
    "                tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td></tr>'\n",
    "                                ) if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td>')\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle et modélisation </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab2')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab2/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1728349-50fb-459e-9eaa-b685a9267fea",
   "metadata": {},
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_2, layers=layers, approach=approach)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0338183-5233-455a-96de-c6135915f215",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_3(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, alpha = 0.85, type='qualitative'):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"4\">Accuracy</td><td colspan=\"4\">Precision</td><td colspan=\"4\">Recall</td><td colspan=\"4\">F1-score</td></tr><tr>{(\"<td>Classic</td><td>G\"+svg+\"</td><td>P\"+svg+\"</td><td>M\"+svg+\"</td>\")*4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'precision': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'recall': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'P':[],\n",
    "                    'M':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/{type}/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    'mixed':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/{type}/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                        #       )\n",
    "                        #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None)\n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/mixed/data_selection_storage',\n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))),\n",
    "                                verbose=False\n",
    "                            )\n",
    "                        ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None)\n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/mixed/data_selection_storage',\n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))),\n",
    "                                verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/{type}/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key]['G'].append(round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) if round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            tab1_body_model[model][metric][key]['P'].append(round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) if round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            tab1_body_model[model][metric][key]['M'].append(round(((round(files['mixed'][key].loc[model,metric],4) - round(files['mixed']['classic'].loc[model,metric],4))/round(files['mixed']['classic'].loc[model,metric],4))*100,4) if round(((round(files['mixed'][key].loc[model,metric],4) - round(files['mixed']['classic'].loc[model,metric],4))/round(files['mixed']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            #totalImpact[metric][\"P\"].append(tab1_body_model[model][metric][key]['P'] >= tab1_body_model[model][metric][key]['G'])\n",
    "                            #totalImpact[metric][\"G\"].append(tab1_body_model[model][metric][key]['P'] <= tab1_body_model[model][metric][key]['P'])\n",
    "        \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "            tab1_body+= f'<tr> <td rowspan=\"{len(approach)}\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # add metric in the vector\n",
    "                    totalImpact[metric][\"P\"].append((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) <= max(tab1_body_model[model][metric][key][\"P\"])))\n",
    "                    totalImpact[metric][\"G\"].append((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))\n",
    "                    totalImpact[metric][\"M\"].append((max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) >= max(tab1_body_model[model][metric][key][\"P\"])))\n",
    "        \n",
    "                    tab1_body+= (f'<td>{round(files[\"global\"][\"classic\"].loc[model,metric],4)}</td><td>{\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) <= max(tab1_body_model[model][metric][key][\"P\"])))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) <= max(tab1_body_model[model][metric][key][\"P\"])))}</td>'+\n",
    "                                 f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"M\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'\n",
    "                                ) if y != len(metrics)-1 else (f'<td>{round(files[\"global\"][\"classic\"].loc[model,metric],4)}</td><td>{\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"M\"])))}</td>'+\n",
    "                                                               f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) <= max(tab1_body_model[model][metric][key][\"P\"])))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"])) and (max(tab1_body_model[model][metric][key][\"M\"]) <= max(tab1_body_model[model][metric][key][\"P\"])))}</td>'+\n",
    "                                                               f'<td> {\"<strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}{max(tab1_body_model[model][metric][key][\"M\"])}{\"</strong>\"*int((max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"M\"])) and (max(tab1_body_model[model][metric][key][\"P\"]) <= max(tab1_body_model[model][metric][key][\"M\"])))}</td></tr>')\n",
    "        tab1_body+= f'<tr> <td colspan=\"2\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            tab1_body+= (f'<td></td><td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"M\"]) <= sum(totalImpact[metric][\"P\"])))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"M\"]) <= sum(totalImpact[metric][\"P\"])))}</td>'+\n",
    "                         f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"M\"]) >= sum(totalImpact[metric][\"P\"])))}{sum(totalImpact[metric][\"M\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"M\"]) >= sum(totalImpact[metric][\"P\"])))}</td>'\n",
    "                            ) if y != len(metrics)-1 else (f'<td></td><td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"M\"])))}</td>'+\n",
    "                                                           f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"M\"]) <= sum(totalImpact[metric][\"P\"])))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"])) and (sum(totalImpact[metric][\"M\"]) <= sum(totalImpact[metric][\"P\"])))}</td>'+\n",
    "                                                           f'<td>{\"<strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"M\"]) >= sum(totalImpact[metric][\"P\"])))}{sum(totalImpact[metric][\"M\"])}{\"</strong>\"*int((sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"M\"])) and (sum(totalImpact[metric][\"M\"]) >= sum(totalImpact[metric][\"P\"])))}</td></tr>')\n",
    "            \n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best outperforming metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab3')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab3/Statistical comparaison of approachs in {data_folder} on global logic{alpha}.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c95f49b3-011c-45b7-b3e0-30d28491dde2",
   "metadata": {},
   "source": "analyzer_launcher(outputs_name=\"outputs\", analytical_func=metrics_analyzer_statistics_tab_f_3, layers=layers, approach=approach)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63cb1c58-5784-4c85-8d58-aaa68434ba0d",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_4(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build logics increasment on models\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for i, key in enumerate(layers)}\n",
    "        totalImpact = {\n",
    "            'accuracy': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'precision': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'recall': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'f1-score': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)}\n",
    "        }\n",
    "        ele = \"\".join([\"<td>\"+key+\"\"+svg+\"</td>\" for key in mlnL.keys()])\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"3\" rowspan=\"2\">{x}</td><td colspan=\"{len(mlnL)+1}\">Accuracy</td><td colspan=\"{len(mlnL)+1}\">Precision</td><td colspan=\"{len(mlnL)+1}\">Recall</td><td colspan=\"{len(mlnL)+1}\">F1-score</td></tr><tr>{(\"<td>classic</td>\"+ele) *4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "            \n",
    "        dictio = {\n",
    "            'classic_-_mlna': 'Classic - Att',\n",
    "            'classic_mln': 'Classic + MLN',\n",
    "            'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "            'classic': 'Classic'\n",
    "        }\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"G\"].append(round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) if round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"P\"].append(round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) if round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            \n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}    \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                tab1_body+= f'<tr> <td rowspan=\"4\">{model}</td>'\n",
    "                # fetch approach\n",
    "                for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                    # fetch evaluation metric\n",
    "                    tab1_body+= (f'<tr> <td rowspan=\"2\">{dictio[key]}</td>') if i != 0 else (f'<td rowspan=\"2\">{dictio[key]}</td>')\n",
    "                    for l,logic in enumerate(logics.keys()):\n",
    "                        tab1_body+= (f'<tr><td>{logics[logic]}</td>') if l != 0 else (f'<td>{logics[logic]}</td>')\n",
    "                        for y, metric in enumerate(metrics):\n",
    "                            #print(f\"{y}--\")\n",
    "                            # fetch layers\n",
    "                            for z, layer in enumerate(mlnL.keys()):\n",
    "                                #print(f\"{z};\")\n",
    "                                # add metric in the vector\n",
    "                                maxi = [max(tab1_body_model[model][metric][key][lay][logic]) for lay in mlnL ]\n",
    "                                totalImpact[metric][layer].append(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))\n",
    "                                prefix = f'<td>{round(files[\"global\"][\"classic\"].loc[model,metric],4)}</td>' if z == 0 else \"\"\n",
    "                                tab1_body+= (f'{prefix}<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td></tr>') if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                            f'{prefix}<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td>')\n",
    "                            \n",
    "        tab1_body+= f'<tr> <td colspan=\"3\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            for z, layer in enumerate(mlnL.keys()):\n",
    "                maxi = [sum(totalImpact[metric][lay]) for lay in mlnL]\n",
    "                prefix = \"<td></td>\" if z == 0 else \"\"\n",
    "                tab1_body+= (f'{prefix}<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td></tr>'\n",
    "                                ) if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                f'{prefix}<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td>')\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best outperforming metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle et modélisation </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab4')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab4/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6631ccbe-c674-4b22-a937-27bf8b881fe8",
   "metadata": {},
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_4, layers=layers, approach=approach)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82e2ec93-aa9e-4c8c-a05e-f0e651e64624",
   "metadata": {},
   "source": [
    "def custom_color(list_col, graph_a=[]):\n",
    "    colors= []\n",
    "    for col in list_col:\n",
    "        if col in graph_a:\n",
    "            colors.append('yellow')\n",
    "        elif 'MLN_' in col:\n",
    "            colors.append('green')\n",
    "        # elif 'STAT_' in col:\n",
    "        #     colors.append('blue')\n",
    "        else:\n",
    "            colors.append('dodgerblue')\n",
    "    return [colors, list_col]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b7670c7-2a39-4a8c-bc26-99e0081b6cf3",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_5(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, aggregation_f=None,alpha=None,logics = [\"global\",\"personalized\",\"mixed\"],type='qualitative'):\n",
    "    \"\"\" build relevance comparison of extracted descriptors\n",
    "    \n",
    "    Args:\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        descripteurs= {\n",
    "            'MLN_degree': [],\n",
    "            'MLN_bipart_intra': [],\n",
    "            'MLN_bipart_inter': [],\n",
    "            'MLN_bipart_combine': [],\n",
    "            'MLN_bipart_combine_perso': [],\n",
    "            'MLN_bipart_inter_perso': [],\n",
    "            'MLN_bipart_intra_perso': [],\n",
    "            'MLN_bipart_intra_max': [],\n",
    "            'MLN_bipart_inter_max': [],\n",
    "            'MLN_bipart_combine_max': [],\n",
    "            'MLN_bipart_combine_perso_max': [],\n",
    "            'MLN_bipart_inter_perso_max': [],\n",
    "            'MLN_bipart_intra_perso_max': []\n",
    "        }\n",
    "        \n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': descripteurs for i, key in enumerate(layers)}\n",
    "        \n",
    "        \n",
    "        \n",
    "        tab1_body_model_f = {key: deepcopy(descripteurs) for key in models_name.keys()}\n",
    "        tab1_body_model = {key: deepcopy(mlnL) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                #print(f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage')\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    'mixed':{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/mixed/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/mixed/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/{type}/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files[logics[0]]['classic_mln'].index.values.tolist()\n",
    "                # print(models_list)\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for logic in logics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # fetch on column or attributs\n",
    "                            colo = files[logic][key].columns\n",
    "                            for att in colo:\n",
    "                                if not(att in [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]):\n",
    "                                    #print(f\"{att} : Inter -> {INTER_P_F(att)}, Intra -> {INTRA_P_F(att)}, combine -> {COMBINE_P_F(att)}, Inter_m -> {INTER_P_MAX_F(att)}, Intra_m -> {INTRA_P_MAX_F(att)}, Combine_m -> {COMBINE_P_MAX_F(att)}\")\n",
    "                                    \n",
    "                                    if INTER_P_F(att):\n",
    "                                        #print(att)\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter_perso'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_P_F(att):\n",
    "                                        #print(att)\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra_perso'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_P_F(att):\n",
    "                                        #print(att)\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine_perso'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTER_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTER_P_MAX_F(att):\n",
    "                                        #print(att)\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter_perso_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_P_MAX_F(att):\n",
    "                                        #print(att)\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra_perso_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_P_MAX_F(att):\n",
    "                                        #print(att)\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine_perso_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTER_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif DEGREE_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_degree'].append(files[logic][key].loc[model,att])\n",
    "                                    else:\n",
    "                                        if not(att in tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'].keys()):\n",
    "                                            tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'][att] = []\n",
    "                                            tab1_body_model_f[model][att] = []\n",
    "                                            descripteurs[att] = []\n",
    "                                            #print(tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'])\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'][att].append(files[logic][key].loc[model,att])\n",
    "\n",
    "              \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                # fetch layers\n",
    "                for z, layer in enumerate(mlnL.keys()):\n",
    "                    # fetch attributs\n",
    "                    for att in tab1_body_model[model][layer].keys():\n",
    "                        #print(att)\n",
    "                        #print(att,tab1_body_model[model][layer][att])\n",
    "                        tab1_body_model_f[model][att] = [*tab1_body_model_f[model][att], *tab1_body_model[model][layer][att]]\n",
    "                        descripteurs[att] = [*descripteurs[att], *tab1_body_model[model][layer][att]]\n",
    "                for att in tab1_body_model_f[model].keys():   \n",
    "                    #print(att,tab1_body_model_f[model][att])\n",
    "                    tab1_body_model_f[model][att] = aggregation_f(tab1_body_model_f[model][att])\n",
    "                    #print(tab1_body_model_f[model])\n",
    "                # Conversion du dictionnaire en un format accepté par SHAP\n",
    "                #attributs = list(tab1_body_model_f[model].keys())\n",
    "                #coefficients = np.array([abs(val) for val in tab1_body_model_f[model].values()]).reshape(1, -1)\n",
    "                #explication_shap = shap.Explanation(values=coefficients, feature_names=attributs)\n",
    "\n",
    "                # Affichage de l'explication SHAP\n",
    "                # print(f'{explication_shap.values}{len(explication_shap.values)} {attributs}{len(attributs)}')\n",
    "                # shap.summary_plot(explication_shap.values, attributs)\n",
    "                # print(model)\n",
    "                \n",
    "                #shap.summary_plot(explication_shap, plot_type='bar')\n",
    "                create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/{\"_\".join(logics)}')\n",
    "                #timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "                #filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/{\"_\".join(approach)}_{data_folder}_{model}_shapley'\n",
    "                filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/{\"_\".join(logics)}/{data_folder}_{model}_{alpha}_shapley.png'\n",
    "                \n",
    "                #pl.show()\n",
    "                #pl.savefig(filename1+\".png\", dpi=300)\n",
    "\n",
    "                # fig setup\n",
    "                width = 15\n",
    "                height = int(len(np.unique(tab1_body_model_f[model].keys()))*1.5)\n",
    "                # Set a larger figure size\n",
    "                pl.figure(figsize=(width, height))\n",
    "                data = dict(sorted(tab1_body_model_f[model].items(), key=lambda x: abs(x[1]), reverse=False)[-30:])\n",
    "                df = pd.DataFrame({'features':data.keys(),'importances':data.values()})\n",
    "                bars = df.plot.barh(x='features', y='importances', color=custom_color(df.features, [])[0])\n",
    "                \n",
    "                pl.title(f\"{model}\")\n",
    "                # Custom colors for the legend\n",
    "                mln_color = 'green'\n",
    "                classic_color = 'dodgerblue'\n",
    "                \n",
    "                # Add custom colors to the legend\n",
    "                legend_elements = [\n",
    "                    Patch(facecolor=mln_color, edgecolor='black', label='MLN'),\n",
    "                    Patch(facecolor=classic_color, edgecolor='black', label='Classic')\n",
    "                ]\n",
    "                \n",
    "                \n",
    "                # Reduce the font size of x-axis label\n",
    "                pl.xlabel('Importances', fontsize=8)\n",
    "                \n",
    "                # Reduce the font size of y-axis label\n",
    "                pl.ylabel('Features', fontsize=8)\n",
    "                \n",
    "                # Reduce the font size of tick labels on x-axis\n",
    "                pl.xticks(fontsize=6)\n",
    "                \n",
    "                # Reduce the font size of tick labels on y-axis\n",
    "                pl.yticks(fontsize=5)\n",
    "                \n",
    "                # Reduce the font size of the plot title\n",
    "                pl.title(f'{models_name[model]} - {data_folder}', fontsize=10)\n",
    "                \n",
    "                # Reduce the font size of the legend\n",
    "                pl.legend(fontsize=8)\n",
    "                # Add values on top of the bars\n",
    "                for i, bar in enumerate(bars.containers[0]):\n",
    "                    width = bar.get_width()\n",
    "                    pl.annotate(f'{width:.2f}', xy=(width, bar.get_y() + bar.get_height() / 2), xytext=(3, 0), textcoords='offset points', ha='left', va='center',fontsize=8)\n",
    "                pl.legend(handles=legend_elements, facecolor='white', framealpha=1, bbox_to_anchor=(1, 1), loc='upper left', title='Legend Title')\n",
    "                \n",
    "                #pl.axvline(x=0, color=\".5\")\n",
    "                #pl.subplots_adjust(left=0.3)\n",
    "                pl.tight_layout()\n",
    "            \n",
    "                # Mise en gras des xticks\n",
    "                font = FontProperties(weight='bold')\n",
    "                pl.xticks(fontproperties=font, fontsize=8)\n",
    "                pl.yticks(fontproperties=font, fontsize=6)\n",
    "\n",
    "                # Suppression de la légende\n",
    "                pl.legend().remove()\n",
    "                pl.savefig(filename1,dpi=300) #.png,.pdf will also support here\n",
    "                pl.close() # close the plot windows\n",
    "\n",
    "        \n",
    "        #for att in descripteurs.keys():\n",
    "        #    descripteurs[att] = aggregation_f(descripteurs[att])\n",
    "            \n",
    "        #attributs = list(descripteurs.keys())\n",
    "        #coefficients = np.array([abs(val) for val in descripteurs.values()]).reshape(1, -1)\n",
    "        #explication_shap = shap.Explanation(values=coefficients, feature_names=attributs)\n",
    "\n",
    "        # Affichage de l'explication SHAP\n",
    "        # print(f'{explication_shap.values}{len(explication_shap.values)} {attributs}{len(attributs)}')\n",
    "        # shap.summary_plot(explication_shap.values, attributs)\n",
    "        # print(model)\n",
    "        \n",
    "        #shap.summary_plot(explication_shap, plot_type='bar')\n",
    "\n",
    "        #create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/all/')\n",
    "        #timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        #filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/all/shapley_'+timestr\n",
    "\n",
    "        # fig setup\n",
    "        #width = 10\n",
    "        #height = int(len(np.unique(descripteurs.keys()))/2)\n",
    "        # Set a larger figure size\n",
    "        #pl.figure(figsize=(width, height))\n",
    "        #data = dict(sorted(descripteurs.items(), key=lambda x: x[1], reverse=False))\n",
    "        #df = pd.DataFrame({'features':data.keys(),'importances':data.values()})\n",
    "        #bars = df.plot.barh(x='features', y='importances', color=custom_color(df.features, [])[0])\n",
    "        \n",
    "        #pl.title(f\"Global importances\")\n",
    "        # Custom colors for the legend\n",
    "        #mln_color = 'green'\n",
    "        #classic_color = 'dodgerblue'\n",
    "        \n",
    "        # Add custom colors to the legend\n",
    "        #legend_elements = [\n",
    "        #    Patch(facecolor=mln_color, edgecolor='black', label='MLN'),\n",
    "        #    Patch(facecolor=classic_color, edgecolor='black', label='Classic')\n",
    "        #]\n",
    "        \n",
    "        #pl.legend(handles=legend_elements, facecolor='white', framealpha=1, bbox_to_anchor=(1, 1), loc='upper left', title='Legend Title')\n",
    "        # Add values on top of the bars\n",
    "        #for i, bar in enumerate(bars.containers[0]):\n",
    "        #    width = bar.get_width()\n",
    "        #    pl.annotate(f'{width:.2f}', xy=(width, bar.get_y() + bar.get_height() / 2), xytext=(3, 0), textcoords='offset points', ha='left', va='center',fontsize=8)\n",
    "#\n",
    "        # Reduce the font size of x-axis label\n",
    "        #pl.xlabel('Importances', fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of y-axis label\n",
    "        #pl.ylabel('Features', fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of tick labels on x-axis\n",
    "        #pl.xticks(fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of tick labels on y-axis\n",
    "        #pl.yticks(fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of the plot title\n",
    "        #pl.title('Global Importance', fontsize=10)\n",
    "        \n",
    "        # Reduce the font size of the legend\n",
    "        #pl.legend(fontsize=8)\n",
    "        #pl.axvline(x=0, color=\".5\")\n",
    "        #pl.subplots_adjust(left=0.3)\n",
    "        #pl.tight_layout()\n",
    "\n",
    "        #pl.savefig(filename1,dpi=700) #.png,.pdf will also support here\n",
    "        #pl.close() # close the plot windows\n",
    "                \n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f633ad96-1853-4de7-bd3d-2aa7ebd482be",
   "metadata": {},
   "source": [
    "layers = [1]\n",
    "approach = [\n",
    "    'classic_mln'\n",
    "    #,'classic_mln_-_mlna'\n",
    "]\n",
    "logics = [\n",
    "    #\"global\",\n",
    "    #\"personalized\",\n",
    "    \"mixed\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7bd2b23f-e58f-4434-addb-fa55c1f96e9e",
   "metadata": {},
   "source": "analyzer_launcher(outputs_name=\"outputs\", analytical_func=metrics_analyzer_statistics_tab_f_5, layers=layers, approach=approach, aggregation_f= statistics.mean, logics=logics)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7b6090d-0898-433f-8302-b9e06da8aebf",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_5_1(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, aggregation_f=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        descripteurs= {\n",
    "            'MLN_degree': [],\n",
    "            'MLN_bipart_intra': [],\n",
    "            'MLN_bipart_inter': [],\n",
    "            'MLN_bipart_combine': [],\n",
    "            'MLN_bipart_ultra': [],\n",
    "            'MLN_bipart_intra_max': [],\n",
    "            'MLN_bipart_inter_max': [],\n",
    "            'MLN_bipart_combine_max': [],\n",
    "            'MLN_bipart_ultra_max': []\n",
    "        }\n",
    "        \n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': descripteurs for i, key in enumerate(layers)}\n",
    "        \n",
    "        \n",
    "        \n",
    "        tab1_body_model_f = {key: deepcopy(descripteurs) for key in models_name.keys()}\n",
    "        tab1_body_model = {key: deepcopy(mlnL) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic_mln'].index.values.tolist()\n",
    "                # print(models_list)\n",
    "                logics = [\"global\",\"personalized\"]\n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for logic in logics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # fetch on column or attributs\n",
    "                            colo = files[logic][key].columns\n",
    "                            for att in colo:\n",
    "                                if not(att in [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]):\n",
    "                                    if INTER_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine'].append(files[logic][key].loc[model,att])\n",
    "                                    elif ULTRA_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_ultra'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTER_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif ULTRA_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_ultra_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif DEGREE_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_degree'].append(files[logic][key].loc[model,att])\n",
    "                                    else:\n",
    "                                        if not(att in tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'].keys()):\n",
    "                                            tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'][att] = []\n",
    "                                            tab1_body_model_f[model][att] = []\n",
    "                                            descripteurs[att] = []\n",
    "                                            #print(tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'])\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'][att].append(files[logic][key].loc[model,att])\n",
    "\n",
    "              \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                # fetch layers\n",
    "                for z, layer in enumerate(mlnL.keys()):\n",
    "                    # fetch attributs\n",
    "                    for att in tab1_body_model[model][layer].keys():\n",
    "                        #print(att)\n",
    "                        #print(tab1_body_model[model][layer][att])\n",
    "                        tab1_body_model_f[model][att] = [*tab1_body_model_f[model][att], *tab1_body_model[model][layer][att]]\n",
    "                        descripteurs[att] = [*descripteurs[att], *tab1_body_model[model][layer][att]]\n",
    "                for att in tab1_body_model_f[model].keys():   \n",
    "                    tab1_body_model_f[model][att] = aggregation_f(tab1_body_model_f[model][att])\n",
    "        #data = dict(sorted(tab1_body_model_f[model].items(), key=lambda x: abs(x[1]), reverse=False)[-25:])    \n",
    "        return tab1_body_model_f\n",
    "                "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e73b0479-fa56-4c66-9a50-79f153d45aa5",
   "metadata": {},
   "source": [
    "top_limit = [\n",
    "    10, \n",
    "    12\n",
    "    , \n",
    "    15, \n",
    "    20\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2081b46-4add-456a-bfdd-1f982ecb87bf",
   "metadata": {},
   "source": [
    "def analyzer_launcher_descriptor_rank(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None, top=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    head_lambda = None\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    model_lines = {dataset:None for dataset in result_folders}\n",
    "    \n",
    "    result_content = {\n",
    "        \"nb\":\"<tr>\",\n",
    "        \"pos\":\"<tr>\"\n",
    "    }\n",
    "    style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} .data {text-align: left;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "    \n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        if model_lines[dataset_name] == None:\n",
    "            model_lines[dataset_name] = { model : {\n",
    "                'nb': {},\n",
    "                'pos': {},\n",
    "                'var': 0\n",
    "            } for model in models_name}\n",
    "        if head_lambda == None:\n",
    "            head_lambda = lambda x: f'<tr><td colspan=\"1\">{x}</td>{\"\".join([\"<td>\"+modeli+\"</td>\" for modeli in models_name.keys()])}</tr>'\n",
    "    \n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        rank = analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2, len(quali_col)])), \n",
    "            approach= approach\n",
    "            ) if aggregation_f == None else analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2, len(quali_col)])), \n",
    "            approach= approach,\n",
    "            aggregation_f=aggregation_f\n",
    "            )\n",
    "        # fetch result on dataset base on model\n",
    "        for model in models_name.keys():\n",
    "            # compute the number time that MLN attribut appear in the top list\n",
    "            data = dict(sorted(rank[model].items(), key=lambda x: abs(x[1]), reverse=False)[-top:])\n",
    "            data1 = dict(sorted(rank[model].items(), key=lambda x: abs(x[1]), reverse=False))\n",
    "            nb = sum([('MLN' in key) for key in data.keys()])\n",
    "            vec_id = [i for i,key in enumerate(data1.keys()) if ('MLN' in key)]\n",
    "            #print(f\"{dataset_name} {model} {data}\")\n",
    "            pos = (len(data1.keys()) - vec_id[len(vec_id)-1]) if len(vec_id) != 0 else 'NA'\n",
    "            model_lines[dataset_name][model][\"nb\"] = f\"<td>{nb}</td>\"\n",
    "            model_lines[dataset_name][model][\"pos\"] = f\"<td>{pos}</td>\"\n",
    "            model_lines[dataset_name][model][\"var\"] = len(data1.keys())\n",
    "\n",
    "    for dataset_name in result_folders:\n",
    "        for p in result_content.keys():\n",
    "            result_content[p] += f'<td class=\"data\">{dataset_name} ({model_lines[dataset_name][model][\"var\"]-9} + 9)</td>'\n",
    "            for i,model in enumerate(models_name.keys()):\n",
    "                    result_content[p] += (f'{model_lines[dataset_name][model][p]}')\n",
    "            result_content[p] += \"</tr>\"  \n",
    "    for p in result_content.keys(): \n",
    "        tab3_head_g = head_lambda(f'TOP {top} {p.upper()}')      \n",
    "        # comparaison\n",
    "        tabs = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g}{result_content[p]}</table>'\n",
    "        \n",
    "        #caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        #table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "        htm = f'<html><head>{style}<title> Top {top} {p.upper()} MLN attributs ranking </title></head><body style=\"background-color: white;\">{tabs}</body></html>'\n",
    "        \n",
    "        create_domain(f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/rank')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/rank/Top {top} {p.upper()} MLN attributs ranking.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "155e25aa-57ae-426a-b274-7b9389ece6f0",
   "metadata": {},
   "source": [
    "[analyzer_launcher_descriptor_rank(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_5_1, layers=layers, approach=approach, aggregation_f= statistics.mean, top=top) for top in top_limit]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a155a534-a8e8-4be1-ac74-67c40ba4f7bc",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_6(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, aggregation_f=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # check if corelation between class of Att in MLN1 and their classe in MLN 2+\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">(Good MLN 1, Good MLN 1)</td><td colspan=\"3\">(Good MLN 1, Bad MLN 1)</td><td colspan=\"3\">(Bad MLN 1, Bad MLN 1)</td></tr><tr>{\"<td>Classic ></td><td>Classic =</td><td>Classic <</td>\"*3}</tr>'\n",
    "        tab3_head_g = {\n",
    "            'accuracy': head_lambda('accuracy'),\n",
    "            'precision': head_lambda('precision'),\n",
    "            'recall': head_lambda('recall'),\n",
    "            'f1-score': head_lambda('f1-score')\n",
    "        }\n",
    "        tab3_head_p = deepcopy(tab3_head_g)\n",
    "        tab3_body_g1 = {\n",
    "            'accuracy': '',\n",
    "            'precision': '',\n",
    "            'recall': '',\n",
    "            'f1-score': ''\n",
    "        }\n",
    "        tab3_body_g2 = deepcopy(tab3_body_g1)\n",
    "        tab3_body_p1 = deepcopy(tab3_body_g1)\n",
    "        tab3_body_p2 = deepcopy(tab3_body_p1)\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        # save class of each Att\n",
    "        clusters = {\n",
    "            'accuracy': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'precision': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'recall': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        comp1 = {\n",
    "            'accuracy': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'precision': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'recall': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'f1-score': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }]\n",
    "        }\n",
    "        comp1Counterg1 = deepcopy(comp1)\n",
    "        comp1Counterg2 = deepcopy(comp1)\n",
    "        comp1Counterp1 = deepcopy(comp1)\n",
    "        comp1Counterp2 = deepcopy(comp1)\n",
    "        clusters_g1 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        clusters_g2 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        clusters_p1 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        clusters_p2 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        body_compC_g1 = {\n",
    "            key: deepcopy(comp1) for key in models_name.keys()\n",
    "        }\n",
    "        body_compC_g2 = deepcopy(body_compC_g1)\n",
    "        body_compC_p1 = deepcopy(body_compC_g1)\n",
    "        body_compC_p2 = deepcopy(body_compC_g1)\n",
    "        for d, k in enumerate(layers):\n",
    "            \n",
    "            # aside row config\n",
    "            LayerLines = f'<tr style=\"border-top: 2px solid black;\"><td rowspan=\"{len(models_name.keys()) }\" >MLN {k} layer(s): {len(get_combinations(range(len(cols)),k))} Att</td>'\n",
    "            \n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                for model in models_list:\n",
    "                    #print(body_best, '\\n----------------------')\n",
    "                    for metric in metrics:\n",
    "                        if k == 1: # in 1st layer, find Att which increase or not metrics\n",
    "                            clusters_g1[model][metric]['Good' if files['global']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                            clusters_g2[model][metric]['Good' if files['global']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                            clusters_p1[model][metric]['Good' if files['personalized']['classic_mln'].loc[model,metric] > files['personalized']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                            clusters_p2[model][metric]['Good' if files['personalized']['classic_mln_-_mlna'].loc[model,metric] > files['personalized']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                        # count combination impact\n",
    "                        if k == 2:\n",
    "                            if sum([partern in clusters_g1[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_g1[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_g1[model][metric][indice][\"s\"] += 1 if files['global']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g1[model][metric][indice][\"e\"] += 1 if files['global']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g1[model][metric][indice][\"i\"] += 1 if files['global']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            comp1Counterg1[metric][indice][\"s\"] += 1 if files['global']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg1[metric][indice][\"e\"] += 1 if files['global']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg1[metric][indice][\"i\"] += 1 if files['global']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            if sum([partern in clusters_g2[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_g2[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_g2[model][metric][indice][\"s\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g2[model][metric][indice][\"e\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g2[model][metric][indice][\"i\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            comp1Counterg2[metric][indice][\"s\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg2[metric][indice][\"e\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg2[metric][indice][\"i\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            \n",
    "                            if sum([partern in clusters_p1[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_p1[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_p1[model][metric][indice][\"s\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p1[model][metric][indice][\"e\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p1[model][metric][indice][\"i\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            comp1Counterp1[metric][indice][\"s\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp1[metric][indice][\"e\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp1[metric][indice][\"i\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            if sum([partern in clusters_p2[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_p2[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_p2[model][metric][indice][\"s\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p2[model][metric][indice][\"e\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p2[model][metric][indice][\"i\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric]  else 0\n",
    "\n",
    "                            comp1Counterp2[metric][indice][\"s\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp2[metric][indice][\"e\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp2[metric][indice][\"i\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric]  else 0\n",
    "                        \n",
    "        for metric in metrics:\n",
    "            total = ('<tr><td rowspan=\"2\"><strong>Global</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg1[metric]\n",
    "                ])+'</tr>')\n",
    "            \n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg2[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td rowspan=\"2\"><strong>Personalized</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp1[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp2[metric]\n",
    "                ])+'</tr>')\n",
    "            tab3_body_g1[metric] = total\n",
    "\n",
    "        # comparaison\n",
    "        #1\n",
    "        tabs = ''\n",
    "        for metric in metrics:\n",
    "            tabs += f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        #table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "        htm = f'<html><head>{style}<title> Tuple qualitity comparaison on {data_folder} based on Classic + MLN and Classic + MLN + Att Approachs and Global Logic </title></head><body style=\"background-color: white;\">{caption}{tabs}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/tab3')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/tab3/Statistical comparaison of Tuple of MLN1 quality in {data_folder} on global logic using Classic + MLN and Classic + MLN + Att apporachs '+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        return (comp1Counterg1, comp1Counterg2, comp1Counterp1, comp1Counterp2)\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f770b03c-63e7-497f-ad64-a35c5859a2a8",
   "metadata": {},
   "source": [
    "def analyzer_launcher_comp(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">(Good MLN 1, Good MLN 1)</td><td colspan=\"3\">(Good MLN 1, Bad MLN 1)</td><td colspan=\"3\">(Bad MLN 1, Bad MLN 1)</td></tr><tr>{\"<td>Classic ></td><td>Classic =</td><td>Classic <</td>\"*3}</tr>'\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    tab3_head_g = {\n",
    "        'accuracy': head_lambda('accuracy'),\n",
    "        'precision': head_lambda('precision'),\n",
    "        'recall': head_lambda('recall'),\n",
    "        'f1-score': head_lambda('f1-score')\n",
    "    }\n",
    "    tab3_body_g1 = {\n",
    "        'accuracy': '',\n",
    "        'precision': '',\n",
    "        'recall': '',\n",
    "        'f1-score': ''\n",
    "    }\n",
    "    comp1 = {\n",
    "        'accuracy': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'precision': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'recall': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'f1-score': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }]\n",
    "    }\n",
    "    style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "    \n",
    "    comp1Counterg1 = deepcopy(comp1)\n",
    "    comp1Counterg2 = deepcopy(comp1)\n",
    "    comp1Counterp1 = deepcopy(comp1)\n",
    "    comp1Counterp2 = deepcopy(comp1)\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        (tg1\n",
    "        ,tg2\n",
    "        ,tp1\n",
    "        ,tp2) = analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2])), \n",
    "            approach= approach\n",
    "            )\n",
    "        for metric in comp1Counterg1.keys():\n",
    "            for i,vector in enumerate(tg1[metric]):\n",
    "                comp1Counterg1[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterg1[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterg1[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tg2[metric]):\n",
    "                comp1Counterg2[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterg2[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterg2[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tp1[metric]):\n",
    "                comp1Counterp1[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterp1[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterp1[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tp2[metric]):\n",
    "                comp1Counterp2[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterp2[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterp2[metric][i][\"i\"] += vector[\"i\"]\n",
    "    caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "    **models_name,\n",
    "    'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "    'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "    'MLN': 'Descriptors extracted from MLN',\n",
    "    'Classic': f'Learning from classic dataset',\n",
    "    'Classic - Att': f'Learning from classic dataset where Att had been removed',\n",
    "    'Classic + MLN': f'Learning from classic dataset where MLN had been added',\n",
    "    'Classic + MLN - Att': f'Learning from classic dataset where MLN had been added and Att removed'\n",
    "    }.items()])\n",
    "    for metric in comp1Counterg1.keys():\n",
    "            total = ('<tr><td rowspan=\"2\"><strong>Global</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg1[metric]\n",
    "                ])+'</tr>')\n",
    "            \n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg2[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td rowspan=\"2\"><strong>Personalized</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp1[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp2[metric]\n",
    "                ])+'</tr>')\n",
    "            tab3_body_g1[metric] = total\n",
    "    # comparaison\n",
    "    #1\n",
    "    tabs = ''\n",
    "    for metric in comp1Counterg1.keys():\n",
    "        tabs += f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "    \n",
    "    caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "    #table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "    htm = f'<html><head>{style}<title> Tuple qualitity comparaison on all datasets based on Classic + MLN and Classic + MLN + Att Approachs and Global Logic </title></head><body style=\"background-color: white;\">{caption}{tabs}</body></html>'\n",
    "    \n",
    "    create_domain(f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/tab3')\n",
    "    timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    filename1 = f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/tab3/Statistical comparaison of Tuple of MLN1 quality in all datasets on global logic using Classic + MLN and Classic + MLN + Att apporachs '+'_'+timestr+'.html'\n",
    "    _file= open(filename1,\"w\")\n",
    "    _file.write(htm)\n",
    "    _file.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "175452fa-4f30-4015-ba8f-5d40fd5c1f1d",
   "metadata": {},
   "source": [
    "analyzer_launcher_comp(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_6, layers=layers, approach=approach)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56e8d14c-7461-428d-ba1b-85c90643c2c1",
   "metadata": {},
   "source": [
    "def metrics_analyzer_statistics_tab_f_7(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for i, key in enumerate(layers)}\n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                key:deepcopy(mlnL) for key in dictio.keys()\n",
    "            },\n",
    "            'precision': {\n",
    "                key:deepcopy(mlnL) for key in dictio.keys()\n",
    "            },\n",
    "            'recall': {\n",
    "                key:deepcopy(mlnL) for key in dictio.keys()\n",
    "            },\n",
    "            'f1-score': {\n",
    "                key:deepcopy(mlnL) for key in dictio.keys()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'value': -1,\n",
    "                    'models': {key: 0 for key in models_name.keys()},\n",
    "                    'approachs': {key: 0 for key in dictio.values()},\n",
    "                    'logics': {\n",
    "                        'Global': 0,\n",
    "                        'Personalized': 0\n",
    "                    },\n",
    "                    'layers': {f'MLN {key if i != len(layers) - 1 else \"All\"}': 0 for i, key in enumerate(layers)}\n",
    "                },\n",
    "            'precision': {\n",
    "                    'value': -1,\n",
    "                    'models': {key: 0 for key in models_name.keys()},\n",
    "                    'approachs': {key: 0 for key in dictio.values()},\n",
    "                    'logics': {\n",
    "                        'Global': 0,\n",
    "                        'Personalized': 0\n",
    "                    },\n",
    "                    'layers': {f'MLN {key if i != len(layers) - 1 else \"All\"}': 0 for i, key in enumerate(layers)}\n",
    "                },\n",
    "            'recall': {\n",
    "                    'value': -1,\n",
    "                    'models': {key: 0 for key in models_name.keys()},\n",
    "                    'approachs': {key: 0 for key in dictio.values()},\n",
    "                    'logics': {\n",
    "                        'Global': 0,\n",
    "                        'Personalized': 0\n",
    "                    },\n",
    "                    'layers': {f'MLN {key if i != len(layers) - 1 else \"All\"}': 0 for i, key in enumerate(layers)}\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'value': -1,\n",
    "                    'models': {key: 0 for key in models_name.keys()},\n",
    "                    'approachs': {key: 0 for key in dictio.values()},\n",
    "                    'logics': {\n",
    "                        'Global': 0,\n",
    "                        'Personalized': 0\n",
    "                    },\n",
    "                    'layers': {f'MLN {key if i != len(layers) - 1 else \"All\"}': 0 for i, key in enumerate(layers)}\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d,k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                #print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            #tab1_body_model[model][metric][key]['G'].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            #tab1_body_model[model][metric][key]['P'].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"G\"].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"P\"].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "        \n",
    "        # fetch each model\n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}  \n",
    "        \n",
    "        for model in models_list:\n",
    "            #tab1_body+= f'<tr> <td rowspan=\"2\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                #tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # fetch layers\n",
    "                    for z, layer in enumerate(mlnL.keys()):\n",
    "                        # add metric in the vector\n",
    "                        if totalImpact[metric][\"value\"] < max(tab1_body_model[model][metric][key][layer][\"G\"]):\n",
    "                            totalImpact[metric][\"value\"] = max(tab1_body_model[model][metric][key][layer][\"G\"])\n",
    "                            totalImpact[metric][\"models\"] = {k: 1 if k == model else 0 for k in models_name.keys()}\n",
    "                            totalImpact[metric][\"logics\"] = {\"Global\":1, \"Personalized\":0}\n",
    "                            totalImpact[metric][\"approachs\"] = {k: 1 if  k == dictio[key] else 0 for k in dictio.values()}\n",
    "                            totalImpact[metric][\"layers\"] = {f'MLN {key if i != len(layers) - 1 else \"All\"}': 1 if f'MLN {key if i != len(layers) - 1 else \"All\"}' == layer else 0  for i, key in enumerate(layers)}\n",
    "                        elif totalImpact[metric][\"value\"] == max(tab1_body_model[model][metric][key][layer][\"G\"]):\n",
    "                            totalImpact[metric][\"value\"] = max(tab1_body_model[model][metric][key][layer][\"G\"])\n",
    "                            totalImpact[metric][\"models\"][model] = 1\n",
    "                            totalImpact[metric][\"logics\"][\"Global\"] = 1\n",
    "                            totalImpact[metric][\"approachs\"][dictio[key]] = 1\n",
    "                            totalImpact[metric][\"layers\"][layer] = 1\n",
    "                        if totalImpact[metric][\"value\"] < max(tab1_body_model[model][metric][key][layer][\"P\"]):\n",
    "                            totalImpact[metric][\"value\"] = max(tab1_body_model[model][metric][key][layer][\"P\"])\n",
    "                            totalImpact[metric][\"models\"] = {k: 1 if k == model else 0 for k in models_name.keys()}\n",
    "                            totalImpact[metric][\"logics\"] = {\"Global\":0, \"Personalized\":1}\n",
    "                            totalImpact[metric][\"approachs\"] = {k: 1 if  k == dictio[key] else 0 for k in dictio.values()}\n",
    "                            totalImpact[metric][\"layers\"] = {f'MLN {key if i != len(layers) - 1 else \"All\"}': 1 if f'MLN {key if i != len(layers) - 1 else \"All\"}' == layer else 0  for i, key in enumerate(layers)}\n",
    "                        elif totalImpact[metric][\"value\"] == max(tab1_body_model[model][metric][key][layer][\"P\"]):\n",
    "                            totalImpact[metric][\"value\"] = max(tab1_body_model[model][metric][key][layer][\"P\"])\n",
    "                            totalImpact[metric][\"models\"][model] = 1\n",
    "                            totalImpact[metric][\"logics\"][\"Personalized\"] = 1\n",
    "                            totalImpact[metric][\"approachs\"][dictio[key]] = 1\n",
    "                            totalImpact[metric][\"layers\"][layer] = 1\n",
    "                    \n",
    "\n",
    "        return totalImpact\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0655930d-6199-48ee-a9e9-66560d7211d2",
   "metadata": {},
   "source": [
    "def analyzer_launcher_best_computation(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    dictio = {\n",
    "                'classic_-_mlna': 'Classic - Att',\n",
    "                'classic_mln': 'Classic + MLN',\n",
    "                'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                'classic': 'Classic'\n",
    "            }\n",
    "    \n",
    "    totalImpact = None\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        if totalImpact == None:\n",
    "            totalImpact = {\n",
    "                'accuracy': {\n",
    "                        'models': {key: 0 for key in models_name.keys()},\n",
    "                        'approachs': {key: 0 for key in dictio.values()},\n",
    "                        'logics': {\n",
    "                            'Global': 0,\n",
    "                            'Personalized': 0\n",
    "                        },\n",
    "                        'layers': {'MLN 1': 0,'MLN 2': 0,'MLN All': 0}\n",
    "                    },\n",
    "                'precision': {\n",
    "                        'models': {key: 0 for key in models_name.keys()},\n",
    "                        'approachs': {key: 0 for key in dictio.values()},\n",
    "                        'logics': {\n",
    "                            'Global': 0,\n",
    "                            'Personalized': 0\n",
    "                        },\n",
    "                        'layers': {'MLN 1': 0,'MLN 2': 0,'MLN All': 0}\n",
    "                    },\n",
    "                'recall': {\n",
    "                        'models': {key: 0 for key in models_name.keys()},\n",
    "                        'approachs': {key: 0 for key in dictio.values()},\n",
    "                        'logics': {\n",
    "                            'Global': 0,\n",
    "                            'Personalized': 0\n",
    "                        },\n",
    "                        'layers': {'MLN 1': 0,'MLN 2': 0,'MLN All': 0}\n",
    "                    },\n",
    "                'f1-score': {\n",
    "                        'models': {key: 0 for key in models_name.keys()},\n",
    "                        'approachs': {key: 0 for key in dictio.values()},\n",
    "                        'logics': {\n",
    "                            'Global': 0,\n",
    "                            'Personalized': 0\n",
    "                        },\n",
    "                        'layers': {'MLN 1': 0,'MLN 2': 0,'MLN All': 0}\n",
    "                    }\n",
    "            }\n",
    "        temp = analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2])), \n",
    "            approach= approach\n",
    "            )\n",
    "        print(temp)\n",
    "        for metric in temp.keys():\n",
    "            for i,elt in enumerate(list(temp[metric].keys())[1:]):\n",
    "                for j,key in enumerate(temp[metric][elt].keys()):\n",
    "                    if (elt == \"layers\") and (key == \"MLN All\") and (max(layers)==2):\n",
    "                        totalImpact[metric][elt]['MLN 2'] += temp[metric][elt][key]\n",
    "                    else:\n",
    "                        totalImpact[metric][elt][key] += temp[metric][elt][key]\n",
    "                    \n",
    "    #for metric in totalImpact.keys():              \n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(len(totalImpact.keys()), 4, figsize=(12, 8), sharex='col')\n",
    "\n",
    "    # Adjust the vertical spacing between subplots\n",
    "    fig.subplots_adjust(hspace=0.7)\n",
    "    \n",
    "    # Iterate over each metric\n",
    "    for i, metric in enumerate(totalImpact.keys()):\n",
    "        # Get the details for the current metric\n",
    "        metric_details = totalImpact[metric]\n",
    "        \n",
    "        # Plot models\n",
    "        axs[i, 0].bar(metric_details['models'].keys(), metric_details['models'].values())\n",
    "        axs[i, 0].set_xlabel('Models') if i == len(totalImpact.keys()) - 1 else None\n",
    "        axs[i, 0].set_ylabel(metric.capitalize())\n",
    "        # axs[i, 0].set_title(f'{metric.capitalize()} - Models')\n",
    "        axs[i, 0].tick_params(axis='x', rotation=90) if i == len(totalImpact.keys()) - 1 else None\n",
    "        \n",
    "        # Plot approaches\n",
    "        axs[i, 1].bar(metric_details['approachs'].keys(), metric_details['approachs'].values())\n",
    "        axs[i, 1].set_xlabel('Approachs') if i == len(totalImpact.keys()) - 1 else None\n",
    "        axs[i, 1].set_ylabel(metric.capitalize())\n",
    "        # axs[i, 1].set_title(f'{metric.capitalize()} - Approachs')\n",
    "        axs[i, 1].tick_params(axis='x', rotation=90) if i == len(totalImpact.keys()) - 1 else None\n",
    "        \n",
    "        # Plot logics\n",
    "        axs[i, 2].bar(metric_details['logics'].keys(), metric_details['logics'].values())\n",
    "        axs[i, 2].set_xlabel('Logics') if i == len(totalImpact.keys()) - 1 else None\n",
    "        axs[i, 2].set_ylabel(metric.capitalize())\n",
    "        # axs[i, 2].set_title(f'{metric.capitalize()} - Logics')\n",
    "        axs[i, 2].tick_params(axis='x', rotation=90) if i == len(totalImpact.keys()) - 1 else None\n",
    "\n",
    "        # Plot layers\n",
    "        axs[i, 3].bar(metric_details['layers'].keys(), metric_details['layers'].values())\n",
    "        axs[i, 3].set_xlabel('Layers') if i == len(totalImpact.keys()) - 1 else None\n",
    "        axs[i, 3].set_ylabel(metric.capitalize())\n",
    "        # axs[i, 3].set_title(f'{metric.capitalize()} - Logics')\n",
    "        axs[i, 3].tick_params(axis='x', rotation=90) if i == len(totalImpact.keys()) - 1 else None\n",
    "    \n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    create_domain(f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/best_results/')\n",
    "    #timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    filename1 = f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/best_results/best_results.png'\n",
    "    pl.savefig(filename1,dpi=300) #.png,.pdf will also support here\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "    pl.close() # close the plot windows\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "adc78676-7ec7-4158-b970-fa05ada1a5db",
   "metadata": {},
   "source": [
    "analyzer_launcher_best_computation(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_7, layers=layers, approach=approach)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f793c00-ae4e-4688-90a2-114f1fb58609",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bdcc12f-4384-45a2-98bd-5232a6a26ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb4dae4e-486b-4e8a-8fa2-f2000fa0d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89d704b7-48fb-4391-a1f2-432a0ad6cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1aff5d8-972a-4876-ad9b-c38578e9b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3260abe5-bbb2-4aac-9f68-0eda36cb2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17427ee1-81f1-4ce7-ae59-844140a9c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e3a60ed-2aec-4322-8ce3-763536688465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "886a2309-131f-4f25-90a4-a721d7d347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d77e7ba0-d568-4584-b0c3-e938d1c17f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = \"<?xml version='1.0' ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background='new 0 0 32 32' height='12px' id='Layer_1' version='1.1' viewBox='0 0 32 32' width='12px' xml:space='preserve' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><path d='M18.221,7.206l9.585,9.585c0.879,0.879,0.879,2.317,0,3.195l-0.8,0.801c-0.877,0.878-2.316,0.878-3.194,0  l-7.315-7.315l-7.315,7.315c-0.878,0.878-2.317,0.878-3.194,0l-0.8-0.801c-0.879-0.878-0.879-2.316,0-3.195l9.587-9.585  c0.471-0.472,1.103-0.682,1.723-0.647C17.115,6.524,17.748,6.734,18.221,7.206z' fill='#515151'/></svg>\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67d2ed2d-66ce-4df3-b112-69c5d9cb35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3091a1cf-f7be-4be4-b44d-87c31ad7a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(root_dir, func, verbose=False):\n",
    "    data_filenames = []\n",
    "    # Walk through the directories and files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # dirpath: current directory path\n",
    "        # dirnames: list of directories in the current directory\n",
    "        # filenames: list of files in the current directory\n",
    "\n",
    "        # Print the current directory\n",
    "        print('Directory:', dirpath)  if verbose else None\n",
    "        # Print all the subdirectories\n",
    "        if verbose:\n",
    "            for dirname in dirnames:\n",
    "                print('Subdirectory:', os.path.join(dirpath, dirname))\n",
    "\n",
    "        # Print all the files\n",
    "        for filename in filenames:\n",
    "            if func(filename) and not ('x_' in filename or 'y_' in filename or 'metric' in filename):\n",
    "                print('File:', os.path.join(dirpath, filename)) if verbose else None\n",
    "                data_filenames.append(os.path.join(dirpath, filename))\n",
    "\n",
    "        # Print an empty line to separate directories\n",
    "        print()  if verbose else None\n",
    "    return data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cda763e-846d-42d2-ae9d-0dc162e134c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLN_F = lambda x: (('classic_mln_' in x) and not('classic_mln_-' in x)) # find metric of model where mln were added\n",
    "MLN__F = lambda x: (('classic_mln_-' in x)) # where mln attribut were removed first\n",
    "MLN_C_F = lambda x: (('classic_-' in x)) # where mln attribut were removed first\n",
    "MLN_C= lambda x: (('classic_' in x)) # where mln attribut were removed first\n",
    "\n",
    "INTER_F = lambda x: (not('_max_' in x) and ('inter' in x))\n",
    "INTRA_F = lambda x: (not('_max_' in x) and ('intra' in x))\n",
    "COMBINE_F = lambda x: (not('_max_' in x) and ('combine' in x))\n",
    "ULTRA_F = lambda x: (not('_max_' in x) and ('ultra' in x))\n",
    "INTER_MAX_F = lambda x: (('_max_' in x) and ('inter' in x))\n",
    "INTRA_MAX_F = lambda x: (('_max_' in x) and ('intra' in x))\n",
    "COMBINE_MAX_F = lambda x: (('_max_' in x) and ('combine' in x))\n",
    "ULTRA_MAX_F = lambda x: (('_max_' in x) and ('ultra' in x))\n",
    "DEGREE_F = lambda x: (('degree' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9208f6cc-f0fc-40da-9cbd-4e494d23b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_1(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"2\">Accuracy</td><td colspan=\"2\">Precision</td><td colspan=\"2\">Recall</td><td colspan=\"2\">F1-score</td></tr><tr>{\"<td>G</td><td>P</td>\"*4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'precision': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'recall': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key]['G'].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key]['P'].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            #totalImpact[metric][\"P\"].append(tab1_body_model[model][metric][key]['P'] >= tab1_body_model[model][metric][key]['G'])\n",
    "                            #totalImpact[metric][\"G\"].append(tab1_body_model[model][metric][key]['P'] <= tab1_body_model[model][metric][key]['P'])\n",
    "        \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "            tab1_body+= f'<tr> <td rowspan=\"2\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # add metric in the vector\n",
    "                    totalImpact[metric][\"P\"].append(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "                    totalImpact[metric][\"G\"].append(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "        \n",
    "                    tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'\n",
    "                                ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td></tr>')\n",
    "        tab1_body+= f'<tr> <td colspan=\"2\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td>'\n",
    "                            ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td></tr>')\n",
    "            \n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab1')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab1/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e624bca0-8b98-49df-b047-0e47596eb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_from_cols = lambda x:(list(set([\n",
    "    var.split(\"__\")[1] for var in [\n",
    "        coll \n",
    "        for coll in [\n",
    "            col \n",
    "            for col in x \n",
    "                if not (\n",
    "                    ('precision' in col ) \n",
    "                    or ('accuracy' in col ) \n",
    "                    or ('recall' in col) \n",
    "                    or ('f1-score' in col)\n",
    "                )\n",
    "            ] \n",
    "            if (\"__\" in coll)\n",
    "        ]\n",
    "    ]\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e5aecf1-35ec-49cf-ae19-297913705389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_launcher(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2, len(quali_col)])), \n",
    "            approach= approach\n",
    "            ) if aggregation_f == None else analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2, len(quali_col)])), \n",
    "            approach= approach,\n",
    "            aggregation_f=aggregation_f\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a85acf7f-4569-409d-a8a6-36ea94b241e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = None\n",
    "approach = ['classic_mln','classic_mln_-_mlna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60ea6117-dc08-4397-a515-5c559e5179a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AER\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_31_14H/AER/plots/fnTab/tab1' created successfully.\n",
      "AFB\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_31_14H/AFB/plots/fnTab/tab1' created successfully.\n",
      "CREDIT_RISK_DATASET\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_31_14H/CREDIT_RISK_DATASET/plots/fnTab/tab1' created successfully.\n",
      "GERMAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_1, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea955056-7e98-4092-af2d-28439430809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_2(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for i, key in enumerate(layers)}\n",
    "        totalImpact = {\n",
    "            'accuracy': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'precision': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'recall': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'f1-score': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)}\n",
    "        }\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"3\" rowspan=\"2\">{x}</td><td colspan=\"{len(mlnL)}\">Accuracy</td><td colspan=\"{len(mlnL)}\">Precision</td><td colspan=\"{len(mlnL)}\">Recall</td><td colspan=\"{len(mlnL)}\">F1-score</td></tr><tr>{\"\".join([\"<td>\"+key+\"</td>\" for key in mlnL.keys()]) *4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "            \n",
    "        dictio = {\n",
    "            'classic_-_mlna': 'Classic - Att',\n",
    "            'classic_mln': 'Classic + MLN',\n",
    "            'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "            'classic': 'Classic'\n",
    "        }\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"G\"].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"P\"].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            \n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}    \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                tab1_body+= f'<tr> <td rowspan=\"4\">{model}</td>'\n",
    "                # fetch approach\n",
    "                for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                    # fetch evaluation metric\n",
    "                    tab1_body+= (f'<tr> <td rowspan=\"2\">{dictio[key]}</td>') if i != 0 else (f'<td rowspan=\"2\">{dictio[key]}</td>')\n",
    "                    for l,logic in enumerate(logics.keys()):\n",
    "                        tab1_body+= (f'<tr><td>{logics[logic]}</td>') if l != 0 else (f'<td>{logics[logic]}</td>')\n",
    "                        for y, metric in enumerate(metrics):\n",
    "                            #print(f\"{y}--\")\n",
    "                            # fetch layers\n",
    "                            for z, layer in enumerate(mlnL.keys()):\n",
    "                                #print(f\"{z};\")\n",
    "                                # add metric in the vector\n",
    "                                maxi = [max(tab1_body_model[model][metric][key][lay][logic]) for lay in mlnL ]\n",
    "                                totalImpact[metric][layer].append(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))\n",
    "                    \n",
    "                                tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td></tr>') if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                            f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td>')\n",
    "                            \n",
    "        tab1_body+= f'<tr> <td colspan=\"3\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            for z, layer in enumerate(mlnL.keys()):\n",
    "                maxi = [sum(totalImpact[metric][lay]) for lay in mlnL]\n",
    "                tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td></tr>'\n",
    "                                ) if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td>')\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle et modélisation </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab2')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab2/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1728349-50fb-459e-9eaa-b685a9267fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_2, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0338183-5233-455a-96de-c6135915f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_3(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">Accuracy</td><td colspan=\"3\">Precision</td><td colspan=\"3\">Recall</td><td colspan=\"3\">F1-score</td></tr><tr>{(\"<td>Classic</td><td>G\"+svg+\"</td><td>P\"+svg+\"</td>\")*4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'precision': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'recall': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key]['G'].append(round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) if round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            tab1_body_model[model][metric][key]['P'].append(round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) if round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            #totalImpact[metric][\"P\"].append(tab1_body_model[model][metric][key]['P'] >= tab1_body_model[model][metric][key]['G'])\n",
    "                            #totalImpact[metric][\"G\"].append(tab1_body_model[model][metric][key]['P'] <= tab1_body_model[model][metric][key]['P'])\n",
    "        \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "            tab1_body+= f'<tr> <td rowspan=\"2\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # add metric in the vector\n",
    "                    totalImpact[metric][\"P\"].append(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "                    totalImpact[metric][\"G\"].append(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "        \n",
    "                    tab1_body+= (f'<td>{round(files[\"global\"][\"classic\"].loc[model,metric],4)}</td><td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'\n",
    "                                ) if y != len(metrics)-1 else (f'<td>{round(files[\"global\"][\"classic\"].loc[model,metric],4)}</td><td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td></tr>')\n",
    "        tab1_body+= f'<tr> <td colspan=\"2\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            tab1_body+= (f'<td></td><td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td>'\n",
    "                            ) if y != len(metrics)-1 else (f'<td></td><td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td></tr>')\n",
    "            \n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best outperforming metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab3')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab3/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f49b3-011c-45b7-b3e0-30d28491dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_3, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb1c58-5784-4c85-8d58-aaa68434ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_4(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for i, key in enumerate(layers)}\n",
    "        totalImpact = {\n",
    "            'accuracy': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'precision': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'recall': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)},\n",
    "            'f1-score': {f'MLN {key if i != len(layers) - 1 else \"All\"}': [] for i, key in enumerate(layers)}\n",
    "        }\n",
    "        ele = \"\".join([\"<td>\"+key+\"\"+svg+\"</td>\" for key in mlnL.keys()])\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"3\" rowspan=\"2\">{x}</td><td colspan=\"{len(mlnL)+1}\">Accuracy</td><td colspan=\"{len(mlnL)+1}\">Precision</td><td colspan=\"{len(mlnL)+1}\">Recall</td><td colspan=\"{len(mlnL)+1}\">F1-score</td></tr><tr>{(\"<td>classic</td>\"+ele) *4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "            \n",
    "        dictio = {\n",
    "            'classic_-_mlna': 'Classic - Att',\n",
    "            'classic_mln': 'Classic + MLN',\n",
    "            'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "            'classic': 'Classic'\n",
    "        }\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"G\"].append(round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) if round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k if d != len(layers) - 1 else \"All\"}'][\"P\"].append(round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) if round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) >= 0 else 0.0)\n",
    "                            \n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}    \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                tab1_body+= f'<tr> <td rowspan=\"4\">{model}</td>'\n",
    "                # fetch approach\n",
    "                for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                    # fetch evaluation metric\n",
    "                    tab1_body+= (f'<tr> <td rowspan=\"2\">{dictio[key]}</td>') if i != 0 else (f'<td rowspan=\"2\">{dictio[key]}</td>')\n",
    "                    for l,logic in enumerate(logics.keys()):\n",
    "                        tab1_body+= (f'<tr><td>{logics[logic]}</td>') if l != 0 else (f'<td>{logics[logic]}</td>')\n",
    "                        for y, metric in enumerate(metrics):\n",
    "                            #print(f\"{y}--\")\n",
    "                            # fetch layers\n",
    "                            for z, layer in enumerate(mlnL.keys()):\n",
    "                                #print(f\"{z};\")\n",
    "                                # add metric in the vector\n",
    "                                maxi = [max(tab1_body_model[model][metric][key][lay][logic]) for lay in mlnL ]\n",
    "                                totalImpact[metric][layer].append(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))\n",
    "                                prefix = f'<td>{round(files[\"global\"][\"classic\"].loc[model,metric],4)}</td>' if z == 0 else \"\"\n",
    "                                tab1_body+= (f'{prefix}<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td></tr>') if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                            f'{prefix}<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td>')\n",
    "                            \n",
    "        tab1_body+= f'<tr> <td colspan=\"3\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            for z, layer in enumerate(mlnL.keys()):\n",
    "                maxi = [sum(totalImpact[metric][lay]) for lay in mlnL]\n",
    "                prefix = \"<td></td>\" if z == 0 else \"\"\n",
    "                tab1_body+= (f'{prefix}<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td></tr>'\n",
    "                                ) if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                f'{prefix}<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td>')\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best outperforming metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle et modélisation </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab4')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab4/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631ccbe-c674-4b22-a937-27bf8b881fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_4, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2ec93-aa9e-4c8c-a05e-f0e651e64624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_color(list_col, graph_a=[]):\n",
    "    colors= []\n",
    "    for col in list_col:\n",
    "        if col in graph_a:\n",
    "            colors.append('yellow')\n",
    "        elif 'MLN_' in col:\n",
    "            colors.append('green')\n",
    "        # elif 'STAT_' in col:\n",
    "        #     colors.append('blue')\n",
    "        else:\n",
    "            colors.append('dodgerblue')\n",
    "    return [colors, list_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7670c7-2a39-4a8c-bc26-99e0081b6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_5(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, aggregation_f=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        descripteurs= {\n",
    "            'MLN_degree': [],\n",
    "            'MLN_bipart_intra': [],\n",
    "            'MLN_bipart_inter': [],\n",
    "            'MLN_bipart_combine': [],\n",
    "            'MLN_bipart_ultra': [],\n",
    "            'MLN_bipart_intra_max': [],\n",
    "            'MLN_bipart_inter_max': [],\n",
    "            'MLN_bipart_combine_max': [],\n",
    "            'MLN_bipart_ultra_max': []\n",
    "        }\n",
    "        \n",
    "        mlnL = {f'MLN {key if i != len(layers) - 1 else \"All\"}': descripteurs for i, key in enumerate(layers)}\n",
    "        \n",
    "        \n",
    "        \n",
    "        tab1_body_model_f = {key: deepcopy(descripteurs) for key in models_name.keys()}\n",
    "        tab1_body_model = {key: deepcopy(mlnL) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for d, k in enumerate(layers):\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic_mln'].index.values.tolist()\n",
    "                # print(models_list)\n",
    "                logics = [\"global\",\"personalized\"]\n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for logic in logics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # fetch on column or attributs\n",
    "                            colo = files[logic][key].columns\n",
    "                            for att in colo:\n",
    "                                if not(att in [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]):\n",
    "                                    if INTER_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine'].append(files[logic][key].loc[model,att])\n",
    "                                    elif ULTRA_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_ultra'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTER_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_inter_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif INTRA_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_intra_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif COMBINE_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_combine_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif ULTRA_MAX_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_bipart_ultra_max'].append(files[logic][key].loc[model,att])\n",
    "                                    elif DEGREE_F(att):\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}']['MLN_degree'].append(files[logic][key].loc[model,att])\n",
    "                                    else:\n",
    "                                        if not(att in tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'].keys()):\n",
    "                                            tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'][att] = []\n",
    "                                            tab1_body_model_f[model][att] = []\n",
    "                                            descripteurs[att] = []\n",
    "                                            #print(tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'])\n",
    "                                        tab1_body_model[model][f'MLN {k if d != len(layers) - 1 else \"All\"}'][att].append(files[logic][key].loc[model,att])\n",
    "\n",
    "              \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                # fetch layers\n",
    "                for z, layer in enumerate(mlnL.keys()):\n",
    "                    # fetch attributs\n",
    "                    for att in tab1_body_model[model][layer].keys():\n",
    "                        #print(att)\n",
    "                        #print(tab1_body_model[model][layer][att])\n",
    "                        tab1_body_model_f[model][att] = [*tab1_body_model_f[model][att], *tab1_body_model[model][layer][att]]\n",
    "                        descripteurs[att] = [*descripteurs[att], *tab1_body_model[model][layer][att]]\n",
    "                for att in tab1_body_model_f[model].keys():   \n",
    "                    tab1_body_model_f[model][att] = aggregation_f(tab1_body_model_f[model][att])\n",
    "                    #print(tab1_body_model_f[model])\n",
    "                # Conversion du dictionnaire en un format accepté par SHAP\n",
    "                #attributs = list(tab1_body_model_f[model].keys())\n",
    "                #coefficients = np.array([abs(val) for val in tab1_body_model_f[model].values()]).reshape(1, -1)\n",
    "                #explication_shap = shap.Explanation(values=coefficients, feature_names=attributs)\n",
    "\n",
    "                # Affichage de l'explication SHAP\n",
    "                # print(f'{explication_shap.values}{len(explication_shap.values)} {attributs}{len(attributs)}')\n",
    "                # shap.summary_plot(explication_shap.values, attributs)\n",
    "                # print(model)\n",
    "                \n",
    "                #shap.summary_plot(explication_shap, plot_type='bar')\n",
    "                create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/')\n",
    "                #timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "                filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/{data_folder}_{model}_shapley'\n",
    "                \n",
    "                #pl.show()\n",
    "                #pl.savefig(filename1+\".png\", dpi=300)\n",
    "\n",
    "                # fig setup\n",
    "                width = 15\n",
    "                height = int(len(np.unique(tab1_body_model_f[model].keys()))*1.5)\n",
    "                # Set a larger figure size\n",
    "                pl.figure(figsize=(width, height))\n",
    "                data = dict(sorted(tab1_body_model_f[model].items(), key=lambda x: x[1], reverse=False))\n",
    "                df = pd.DataFrame({'features':data.keys(),'importances':data.values()})\n",
    "                bars = df.plot.barh(x='features', y='importances', color=custom_color(df.features, [])[0])\n",
    "                \n",
    "                pl.title(f\"{model}\")\n",
    "                # Custom colors for the legend\n",
    "                mln_color = 'green'\n",
    "                classic_color = 'dodgerblue'\n",
    "                \n",
    "                # Add custom colors to the legend\n",
    "                legend_elements = [\n",
    "                    Patch(facecolor=mln_color, edgecolor='black', label='MLN'),\n",
    "                    Patch(facecolor=classic_color, edgecolor='black', label='Classic')\n",
    "                ]\n",
    "                \n",
    "                \n",
    "                # Reduce the font size of x-axis label\n",
    "                pl.xlabel('Importances', fontsize=8)\n",
    "                \n",
    "                # Reduce the font size of y-axis label\n",
    "                pl.ylabel('Features', fontsize=8)\n",
    "                \n",
    "                # Reduce the font size of tick labels on x-axis\n",
    "                pl.xticks(fontsize=6)\n",
    "                \n",
    "                # Reduce the font size of tick labels on y-axis\n",
    "                pl.yticks(fontsize=5)\n",
    "                \n",
    "                # Reduce the font size of the plot title\n",
    "                pl.title(f'{models_name[model]} - {data_folder}', fontsize=10)\n",
    "                \n",
    "                # Reduce the font size of the legend\n",
    "                pl.legend(fontsize=8)\n",
    "                # Add values on top of the bars\n",
    "                for i, bar in enumerate(bars.containers[0]):\n",
    "                    width = bar.get_width()\n",
    "                    pl.annotate(f'{width:.2f}', xy=(width, bar.get_y() + bar.get_height() / 2), xytext=(3, 0), textcoords='offset points', ha='left', va='center',fontsize=8)\n",
    "                pl.legend(handles=legend_elements, facecolor='white', framealpha=1, bbox_to_anchor=(1, 1), loc='upper left', title='Legend Title')\n",
    "                \n",
    "                #pl.axvline(x=0, color=\".5\")\n",
    "                #pl.subplots_adjust(left=0.3)\n",
    "                pl.tight_layout()\n",
    "    \n",
    "                pl.savefig(filename1,dpi=150) #.png,.pdf will also support here\n",
    "                pl.close() # close the plot windows\n",
    "\n",
    "        \n",
    "        for att in descripteurs.keys():\n",
    "            descripteurs[att] = aggregation_f(descripteurs[att])\n",
    "            \n",
    "        #attributs = list(descripteurs.keys())\n",
    "        #coefficients = np.array([abs(val) for val in descripteurs.values()]).reshape(1, -1)\n",
    "        #explication_shap = shap.Explanation(values=coefficients, feature_names=attributs)\n",
    "\n",
    "        # Affichage de l'explication SHAP\n",
    "        # print(f'{explication_shap.values}{len(explication_shap.values)} {attributs}{len(attributs)}')\n",
    "        # shap.summary_plot(explication_shap.values, attributs)\n",
    "        # print(model)\n",
    "        \n",
    "        #shap.summary_plot(explication_shap, plot_type='bar')\n",
    "\n",
    "        #create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/all/')\n",
    "        #timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        #filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/shap/all/shapley_'+timestr\n",
    "\n",
    "        # fig setup\n",
    "        #width = 10\n",
    "        #height = int(len(np.unique(descripteurs.keys()))/2)\n",
    "        # Set a larger figure size\n",
    "        #pl.figure(figsize=(width, height))\n",
    "        #data = dict(sorted(descripteurs.items(), key=lambda x: x[1], reverse=False))\n",
    "        #df = pd.DataFrame({'features':data.keys(),'importances':data.values()})\n",
    "        #bars = df.plot.barh(x='features', y='importances', color=custom_color(df.features, [])[0])\n",
    "        \n",
    "        #pl.title(f\"Global importances\")\n",
    "        # Custom colors for the legend\n",
    "        #mln_color = 'green'\n",
    "        #classic_color = 'dodgerblue'\n",
    "        \n",
    "        # Add custom colors to the legend\n",
    "        #legend_elements = [\n",
    "        #    Patch(facecolor=mln_color, edgecolor='black', label='MLN'),\n",
    "        #    Patch(facecolor=classic_color, edgecolor='black', label='Classic')\n",
    "        #]\n",
    "        \n",
    "        #pl.legend(handles=legend_elements, facecolor='white', framealpha=1, bbox_to_anchor=(1, 1), loc='upper left', title='Legend Title')\n",
    "        # Add values on top of the bars\n",
    "        #for i, bar in enumerate(bars.containers[0]):\n",
    "        #    width = bar.get_width()\n",
    "        #    pl.annotate(f'{width:.2f}', xy=(width, bar.get_y() + bar.get_height() / 2), xytext=(3, 0), textcoords='offset points', ha='left', va='center',fontsize=8)\n",
    "#\n",
    "        # Reduce the font size of x-axis label\n",
    "        #pl.xlabel('Importances', fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of y-axis label\n",
    "        #pl.ylabel('Features', fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of tick labels on x-axis\n",
    "        #pl.xticks(fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of tick labels on y-axis\n",
    "        #pl.yticks(fontsize=8)\n",
    "        \n",
    "        # Reduce the font size of the plot title\n",
    "        #pl.title('Global Importance', fontsize=10)\n",
    "        \n",
    "        # Reduce the font size of the legend\n",
    "        #pl.legend(fontsize=8)\n",
    "        #pl.axvline(x=0, color=\".5\")\n",
    "        #pl.subplots_adjust(left=0.3)\n",
    "        #pl.tight_layout()\n",
    "\n",
    "        #pl.savefig(filename1,dpi=700) #.png,.pdf will also support here\n",
    "        #pl.close() # close the plot windows\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2b23f-e58f-4434-addb-fa55c1f96e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_5, layers=layers, approach=approach, aggregation_f= statistics.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a155a534-a8e8-4be1-ac74-67c40ba4f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_6(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None, aggregation_f=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # check if corelation between class of Att in MLN1 and their classe in MLN 2+\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">(Good MLN 1, Good MLN 1)</td><td colspan=\"3\">(Good MLN 1, Bad MLN 1)</td><td colspan=\"3\">(Bad MLN 1, Bad MLN 1)</td></tr><tr>{\"<td>Classic ></td><td>Classic =</td><td>Classic <</td>\"*3}</tr>'\n",
    "        tab3_head_g = {\n",
    "            'accuracy': head_lambda('accuracy'),\n",
    "            'precision': head_lambda('precision'),\n",
    "            'recall': head_lambda('recall'),\n",
    "            'f1-score': head_lambda('f1-score')\n",
    "        }\n",
    "        tab3_head_p = deepcopy(tab3_head_g)\n",
    "        tab3_body_g1 = {\n",
    "            'accuracy': '',\n",
    "            'precision': '',\n",
    "            'recall': '',\n",
    "            'f1-score': ''\n",
    "        }\n",
    "        tab3_body_g2 = deepcopy(tab3_body_g1)\n",
    "        tab3_body_p1 = deepcopy(tab3_body_g1)\n",
    "        tab3_body_p2 = deepcopy(tab3_body_p1)\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        # save class of each Att\n",
    "        clusters = {\n",
    "            'accuracy': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'precision': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'recall': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'Good': [],\n",
    "                'Bad': []\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        comp1 = {\n",
    "            'accuracy': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'precision': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'recall': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }],\n",
    "            'f1-score': [{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            },{\n",
    "                's': 0,\n",
    "                'e':0,\n",
    "                'i':0\n",
    "            }]\n",
    "        }\n",
    "        comp1Counterg1 = deepcopy(comp1)\n",
    "        comp1Counterg2 = deepcopy(comp1)\n",
    "        comp1Counterp1 = deepcopy(comp1)\n",
    "        comp1Counterp2 = deepcopy(comp1)\n",
    "        clusters_g1 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        clusters_g2 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        clusters_p1 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        clusters_p2 = {key: deepcopy(clusters) for key in models_name.keys()}\n",
    "        body_compC_g1 = {\n",
    "            key: deepcopy(comp1) for key in models_name.keys()\n",
    "        }\n",
    "        body_compC_g2 = deepcopy(body_compC_g1)\n",
    "        body_compC_p1 = deepcopy(body_compC_g1)\n",
    "        body_compC_p2 = deepcopy(body_compC_g1)\n",
    "        for d, k in enumerate(layers):\n",
    "            \n",
    "            # aside row config\n",
    "            LayerLines = f'<tr style=\"border-top: 2px solid black;\"><td rowspan=\"{len(models_name.keys()) }\" >MLN {k} layer(s): {len(get_combinations(range(len(cols)),k))} Att</td>'\n",
    "            \n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                        'classic_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                for model in models_list:\n",
    "                    #print(body_best, '\\n----------------------')\n",
    "                    for metric in metrics:\n",
    "                        if k == 1: # in 1st layer, find Att which increase or not metrics\n",
    "                            clusters_g1[model][metric]['Good' if files['global']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                            clusters_g2[model][metric]['Good' if files['global']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                            clusters_p1[model][metric]['Good' if files['personalized']['classic_mln'].loc[model,metric] > files['personalized']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                            clusters_p2[model][metric]['Good' if files['personalized']['classic_mln_-_mlna'].loc[model,metric] > files['personalized']['classic'].loc[model,metric] else 'Bad'].append(case_k)\n",
    "                        # count combination impact\n",
    "                        if k == 2:\n",
    "                            if sum([partern in clusters_g1[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_g1[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_g1[model][metric][indice][\"s\"] += 1 if files['global']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g1[model][metric][indice][\"e\"] += 1 if files['global']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g1[model][metric][indice][\"i\"] += 1 if files['global']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            comp1Counterg1[metric][indice][\"s\"] += 1 if files['global']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg1[metric][indice][\"e\"] += 1 if files['global']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg1[metric][indice][\"i\"] += 1 if files['global']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            if sum([partern in clusters_g2[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_g2[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_g2[model][metric][indice][\"s\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g2[model][metric][indice][\"e\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_g2[model][metric][indice][\"i\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            comp1Counterg2[metric][indice][\"s\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg2[metric][indice][\"e\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterg2[metric][indice][\"i\"] += 1 if files['global']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            \n",
    "                            if sum([partern in clusters_p1[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_p1[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_p1[model][metric][indice][\"s\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p1[model][metric][indice][\"e\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p1[model][metric][indice][\"i\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            comp1Counterp1[metric][indice][\"s\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp1[metric][indice][\"e\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp1[metric][indice][\"i\"] += 1 if files['personalized']['classic_mln'].loc[model,metric] > files['global']['classic'].loc[model,metric] else 0\n",
    "\n",
    "                            if sum([partern in clusters_p2[model][metric]['Good'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 0\n",
    "                            elif sum([partern in clusters_p2[model][metric]['Bad'] for partern in case_k.split(\"±\")]) == k:\n",
    "                               indice = 2\n",
    "                            else:\n",
    "                               indice = 1\n",
    "                                \n",
    "                            body_compC_p2[model][metric][indice][\"s\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p2[model][metric][indice][\"e\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            body_compC_p2[model][metric][indice][\"i\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric]  else 0\n",
    "\n",
    "                            comp1Counterp2[metric][indice][\"s\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] < files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp2[metric][indice][\"e\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] == files['global']['classic'].loc[model,metric] else 0\n",
    "                            comp1Counterp2[metric][indice][\"i\"] += 1 if files['personalized']['classic_mln_-_mlna'].loc[model,metric] > files['global']['classic'].loc[model,metric]  else 0\n",
    "                        \n",
    "        for metric in metrics:\n",
    "            total = ('<tr><td rowspan=\"2\"><strong>Global</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg1[metric]\n",
    "                ])+'</tr>')\n",
    "            \n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg2[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td rowspan=\"2\"><strong>Personalized</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp1[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp2[metric]\n",
    "                ])+'</tr>')\n",
    "            tab3_body_g1[metric] = total\n",
    "\n",
    "        # comparaison\n",
    "        #1\n",
    "        tabs = ''\n",
    "        for metric in metrics:\n",
    "            tabs += f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        #table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "        htm = f'<html><head>{style}<title> Tuple qualitity comparaison on {data_folder} based on Classic + MLN and Classic + MLN + Att Approachs and Global Logic </title></head><body style=\"background-color: white;\">{caption}{tabs}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/tab3')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/stats/tab3/Statistical comparaison of Tuple of MLN1 quality in {data_folder} on global logic using Classic + MLN and Classic + MLN + Att apporachs '+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        return (comp1Counterg1, comp1Counterg2, comp1Counterp1, comp1Counterp2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f770b03c-63e7-497f-ad64-a35c5859a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_launcher_comp(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">(Good MLN 1, Good MLN 1)</td><td colspan=\"3\">(Good MLN 1, Bad MLN 1)</td><td colspan=\"3\">(Bad MLN 1, Bad MLN 1)</td></tr><tr>{\"<td>Classic ></td><td>Classic =</td><td>Classic <</td>\"*3}</tr>'\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    tab3_head_g = {\n",
    "        'accuracy': head_lambda('accuracy'),\n",
    "        'precision': head_lambda('precision'),\n",
    "        'recall': head_lambda('recall'),\n",
    "        'f1-score': head_lambda('f1-score')\n",
    "    }\n",
    "    tab3_body_g1 = {\n",
    "        'accuracy': '',\n",
    "        'precision': '',\n",
    "        'recall': '',\n",
    "        'f1-score': ''\n",
    "    }\n",
    "    comp1 = {\n",
    "        'accuracy': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'precision': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'recall': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'f1-score': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }]\n",
    "    }\n",
    "    style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "    \n",
    "    comp1Counterg1 = deepcopy(comp1)\n",
    "    comp1Counterg2 = deepcopy(comp1)\n",
    "    comp1Counterp1 = deepcopy(comp1)\n",
    "    comp1Counterp2 = deepcopy(comp1)\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        (tg1\n",
    "        ,tg2\n",
    "        ,tp1\n",
    "        ,tp2) = analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2])), \n",
    "            approach= approach\n",
    "            )\n",
    "        for metric in comp1Counterg1.keys():\n",
    "            for i,vector in enumerate(tg1[metric]):\n",
    "                comp1Counterg1[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterg1[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterg1[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tg2[metric]):\n",
    "                comp1Counterg2[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterg2[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterg2[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tp1[metric]):\n",
    "                comp1Counterp1[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterp1[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterp1[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tp2[metric]):\n",
    "                comp1Counterp2[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterp2[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterp2[metric][i][\"i\"] += vector[\"i\"]\n",
    "    caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "    **models_name,\n",
    "    'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "    'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "    'MLN': 'Descriptors extracted from MLN',\n",
    "    'Classic': f'Learning from classic dataset',\n",
    "    'Classic - Att': f'Learning from classic dataset where Att had been removed',\n",
    "    'Classic + MLN': f'Learning from classic dataset where MLN had been added',\n",
    "    'Classic + MLN - Att': f'Learning from classic dataset where MLN had been added and Att removed'\n",
    "    }.items()])\n",
    "    for metric in comp1Counterg1.keys():\n",
    "            total = ('<tr><td rowspan=\"2\"><strong>Global</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg1[metric]\n",
    "                ])+'</tr>')\n",
    "            \n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg2[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td rowspan=\"2\"><strong>Personalized</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp1[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp2[metric]\n",
    "                ])+'</tr>')\n",
    "            tab3_body_g1[metric] = total\n",
    "    # comparaison\n",
    "    #1\n",
    "    tabs = ''\n",
    "    for metric in comp1Counterg1.keys():\n",
    "        tabs += f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "    \n",
    "    caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "    #table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "    htm = f'<html><head>{style}<title> Tuple qualitity comparaison on all datasets based on Classic + MLN and Classic + MLN + Att Approachs and Global Logic </title></head><body style=\"background-color: white;\">{caption}{tabs}</body></html>'\n",
    "    \n",
    "    create_domain(f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/tab3')\n",
    "    timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    filename1 = f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/tab3/Statistical comparaison of Tuple of MLN1 quality in all datasets on global logic using Classic + MLN and Classic + MLN + Att apporachs '+'_'+timestr+'.html'\n",
    "    _file= open(filename1,\"w\")\n",
    "    _file.write(htm)\n",
    "    _file.close()\n",
    "    return (comp1Counterg1, comp1Counterg2, comp1Counterp1, comp1Counterp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "175452fa-4f30-4015-ba8f-5d40fd5c1f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AER\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_04_01_11H/AER/plots/stats/tab3' created successfully.\n",
      "AFB\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_04_01_11H/AFB/plots/stats/tab3' created successfully.\n",
      "CREDIT_RISK_DATASET\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_04_01_11H/CREDIT_RISK_DATASET/plots/stats/tab3' created successfully.\n",
      "GERMAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_04_01_11H/GERMAN/plots/stats/tab3' created successfully.\n",
      "JAPAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_04_01_11H/JAPAN/plots/stats/tab3' created successfully.\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_04_01_11H/stats/tab3' created successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': [{'s': 21, 'e': 18, 'i': 107},\n",
       "   {'s': 28, 'e': 21, 'i': 59},\n",
       "   {'s': 124, 'e': 164, 'i': 78}],\n",
       "  'precision': [{'s': 22, 'e': 6, 'i': 104},\n",
       "   {'s': 31, 'e': 8, 'i': 49},\n",
       "   {'s': 174, 'e': 155, 'i': 71}],\n",
       "  'recall': [{'s': 32, 'e': 6, 'i': 113},\n",
       "   {'s': 35, 'e': 10, 'i': 73},\n",
       "   {'s': 119, 'e': 150, 'i': 82}],\n",
       "  'f1-score': [{'s': 37, 'e': 7, 'i': 114},\n",
       "   {'s': 36, 'e': 9, 'i': 75},\n",
       "   {'s': 114, 'e': 150, 'i': 78}]},\n",
       " {'accuracy': [{'s': 20, 'e': 12, 'i': 95},\n",
       "   {'s': 73, 'e': 28, 'i': 85},\n",
       "   {'s': 173, 'e': 59, 'i': 75}],\n",
       "  'precision': [{'s': 25, 'e': 5, 'i': 94},\n",
       "   {'s': 79, 'e': 6, 'i': 74},\n",
       "   {'s': 210, 'e': 57, 'i': 70}],\n",
       "  'recall': [{'s': 30, 'e': 5, 'i': 121},\n",
       "   {'s': 89, 'e': 13, 'i': 95},\n",
       "   {'s': 165, 'e': 48, 'i': 54}],\n",
       "  'f1-score': [{'s': 29, 'e': 5, 'i': 122},\n",
       "   {'s': 87, 'e': 13, 'i': 100},\n",
       "   {'s': 163, 'e': 48, 'i': 53}]},\n",
       " {'accuracy': [{'s': 15, 'e': 14, 'i': 119},\n",
       "   {'s': 31, 'e': 31, 'i': 77},\n",
       "   {'s': 61, 'e': 222, 'i': 50}],\n",
       "  'precision': [{'s': 16, 'e': 5, 'i': 112},\n",
       "   {'s': 44, 'e': 24, 'i': 67},\n",
       "   {'s': 103, 'e': 207, 'i': 42}],\n",
       "  'recall': [{'s': 27, 'e': 7, 'i': 137},\n",
       "   {'s': 38, 'e': 21, 'i': 79},\n",
       "   {'s': 61, 'e': 204, 'i': 46}],\n",
       "  'f1-score': [{'s': 28, 'e': 7, 'i': 139},\n",
       "   {'s': 37, 'e': 21, 'i': 77},\n",
       "   {'s': 61, 'e': 204, 'i': 46}]},\n",
       " {'accuracy': [{'s': 35, 'e': 16, 'i': 106},\n",
       "   {'s': 81, 'e': 18, 'i': 76},\n",
       "   {'s': 160, 'e': 59, 'i': 69}],\n",
       "  'precision': [{'s': 39, 'e': 5, 'i': 99},\n",
       "   {'s': 107, 'e': 8, 'i': 76},\n",
       "   {'s': 165, 'e': 49, 'i': 72}],\n",
       "  'recall': [{'s': 29, 'e': 4, 'i': 126},\n",
       "   {'s': 90, 'e': 6, 'i': 83},\n",
       "   {'s': 161, 'e': 50, 'i': 71}],\n",
       "  'f1-score': [{'s': 31, 'e': 4, 'i': 127},\n",
       "   {'s': 85, 'e': 6, 'i': 86},\n",
       "   {'s': 161, 'e': 50, 'i': 70}]})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer_launcher_comp(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_6, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8d14c-7461-428d-ba1b-85c90643c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_launcher_best(outputs_name=None, analytical_func=None, layers=None, approach=None, aggregation_f=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"3\">(Good MLN 1, Good MLN 1)</td><td colspan=\"3\">(Good MLN 1, Bad MLN 1)</td><td colspan=\"3\">(Bad MLN 1, Bad MLN 1)</td></tr><tr>{\"<td>Classic ></td><td>Classic =</td><td>Classic <</td>\"*3}</tr>'\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    tab3_head_g = {\n",
    "        'accuracy': head_lambda('accuracy'),\n",
    "        'precision': head_lambda('precision'),\n",
    "        'recall': head_lambda('recall'),\n",
    "        'f1-score': head_lambda('f1-score')\n",
    "    }\n",
    "    tab3_body_g1 = {\n",
    "        'accuracy': '',\n",
    "        'precision': '',\n",
    "        'recall': '',\n",
    "        'f1-score': ''\n",
    "    }\n",
    "    comp1 = {\n",
    "        'accuracy': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'precision': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'recall': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }],\n",
    "        'f1-score': [{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        },{\n",
    "            's': 0,\n",
    "            'e':0,\n",
    "            'i':0\n",
    "        }]\n",
    "    }\n",
    "    style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "    \n",
    "    comp1Counterg1 = deepcopy(comp1)\n",
    "    comp1Counterg2 = deepcopy(comp1)\n",
    "    comp1Counterp1 = deepcopy(comp1)\n",
    "    comp1Counterp2 = deepcopy(comp1)\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        (tg1\n",
    "        ,tg2\n",
    "        ,tp1\n",
    "        ,tp2) = analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2])), \n",
    "            approach= approach\n",
    "            )\n",
    "        for metric in comp1Counterg1.keys():\n",
    "            for i,vector in enumerate(tg1[metric]):\n",
    "                comp1Counterg1[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterg1[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterg1[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tg2[metric]):\n",
    "                comp1Counterg2[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterg2[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterg2[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tp1[metric]):\n",
    "                comp1Counterp1[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterp1[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterp1[metric][i][\"i\"] += vector[\"i\"]\n",
    "            for i,vector in enumerate(tp2[metric]):\n",
    "                comp1Counterp2[metric][i][\"s\"] += vector[\"s\"]\n",
    "                comp1Counterp2[metric][i][\"e\"] += vector[\"e\"]\n",
    "                comp1Counterp2[metric][i][\"i\"] += vector[\"i\"]\n",
    "    caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "    **models_name,\n",
    "    'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "    'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "    'MLN': 'Descriptors extracted from MLN',\n",
    "    'Classic': f'Learning from classic dataset',\n",
    "    'Classic - Att': f'Learning from classic dataset where Att had been removed',\n",
    "    'Classic + MLN': f'Learning from classic dataset where MLN had been added',\n",
    "    'Classic + MLN - Att': f'Learning from classic dataset where MLN had been added and Att removed'\n",
    "    }.items()])\n",
    "    for metric in comp1Counterg1.keys():\n",
    "            total = ('<tr><td rowspan=\"2\"><strong>Global</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg1[metric]\n",
    "                ])+'</tr>')\n",
    "            \n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterg2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterg2[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td rowspan=\"2\"><strong>Personalized</strong></td><td>Classic + MLN</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp1[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp1[metric]\n",
    "                ])+'</tr>')\n",
    "\n",
    "            total += ('<tr><td>Classic + MLN - Att</td>'+ ''.join([\n",
    "                f'<td>{\"<strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"s\"]}{\"</strong>\" * int(vector[\"s\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"e\"]}{\"</strong>\" * int(vector[\"e\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'+\n",
    "                f'<td>{\"<strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}{vector[\"i\"]}{\"</strong>\" * int(vector[\"i\"] >= max(max([(ap[\"s\"],ap[\"e\"],ap[\"i\"]) for ap in comp1Counterp2[metric]])))}</td>'  \n",
    "                for vector in comp1Counterp2[metric]\n",
    "                ])+'</tr>')\n",
    "            tab3_body_g1[metric] = total\n",
    "    # comparaison\n",
    "    #1\n",
    "    tabs = ''\n",
    "    for metric in comp1Counterg1.keys():\n",
    "        tabs += f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "    \n",
    "    caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "    #table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{tab3_head_g[metric]}{tab3_body_g1[metric]}</table>'\n",
    "    htm = f'<html><head>{style}<title> Tuple qualitity comparaison on all datasets based on Classic + MLN and Classic + MLN + Att Approachs and Global Logic </title></head><body style=\"background-color: white;\">{caption}{tabs}</body></html>'\n",
    "    \n",
    "    create_domain(f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/tab3')\n",
    "    timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    filename1 = f'{os.getcwd()}/analyze_{outputs_name}_made_on_{day}H/stats/tab3/Statistical comparaison of Tuple of MLN1 quality in all datasets on global logic using Classic + MLN and Classic + MLN + Att apporachs '+'_'+timestr+'.html'\n",
    "    _file= open(filename1,\"w\")\n",
    "    _file.write(htm)\n",
    "    _file.close()\n",
    "    return (comp1Counterg1, comp1Counterg2, comp1Counterp1, comp1Counterp2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

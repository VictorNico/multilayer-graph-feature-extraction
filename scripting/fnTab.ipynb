{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdcc12f-4384-45a2-98bd-5232a6a26ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4dae4e-486b-4e8a-8fa2-f2000fa0d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.report successfull loaded: 100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from modules.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d704b7-48fb-4391-a1f2-432a0ad6cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3260abe5-bbb2-4aac-9f68-0eda36cb2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886a2309-131f-4f25-90a4-a721d7d347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3091a1cf-f7be-4be4-b44d-87c31ad7a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(root_dir, func, verbose=False):\n",
    "    data_filenames = []\n",
    "    # Walk through the directories and files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # dirpath: current directory path\n",
    "        # dirnames: list of directories in the current directory\n",
    "        # filenames: list of files in the current directory\n",
    "\n",
    "        # Print the current directory\n",
    "        print('Directory:', dirpath)  if verbose else None\n",
    "        # Print all the subdirectories\n",
    "        if verbose:\n",
    "            for dirname in dirnames:\n",
    "                print('Subdirectory:', os.path.join(dirpath, dirname))\n",
    "\n",
    "        # Print all the files\n",
    "        for filename in filenames:\n",
    "            if func(filename) and not ('x_' in filename or 'y_' in filename or 'metric' in filename):\n",
    "                print('File:', os.path.join(dirpath, filename)) if verbose else None\n",
    "                data_filenames.append(os.path.join(dirpath, filename))\n",
    "\n",
    "        # Print an empty line to separate directories\n",
    "        print()  if verbose else None\n",
    "    return data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cda763e-846d-42d2-ae9d-0dc162e134c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLN_F = lambda x: (('classic_mln_' in x) and not('classic_mln_-' in x)) # find metric of model where mln were added\n",
    "MLN__F = lambda x: (('classic_mln_-' in x)) # where mln attribut were removed first\n",
    "MLN_C_F = lambda x: (('classic_-' in x)) # where mln attribut were removed first\n",
    "MLN_C= lambda x: (('classic_' in x)) # where mln attribut were removed first\n",
    "\n",
    "INTER_F = lambda x: (not('_max_' in x) and ('inter' in x))\n",
    "INTRA_F = lambda x: (not('_max_' in x) and ('intra' in x))\n",
    "COMBINE_F = lambda x: (not('_max_' in x) and ('combine' in x))\n",
    "ULTRA_F = lambda x: (not('_max_' in x) and ('ultra' in x))\n",
    "INTER_MAX_F = lambda x: (('_max_' in x) and ('inter' in x))\n",
    "INTRA_MAX_F = lambda x: (('_max_' in x) and ('intra' in x))\n",
    "COMBINE_MAX_F = lambda x: (('_max_' in x) and ('combine' in x))\n",
    "ULTRA_MAX_F = lambda x: (('_max_' in x) and ('ultra' in x))\n",
    "DEGREE_F = lambda x: (('degree' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9208f6cc-f0fc-40da-9cbd-4e494d23b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_1(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"2\">Accuracy</td><td colspan=\"2\">Precision</td><td colspan=\"2\">Recall</td><td colspan=\"2\">F1-score</td></tr><tr>{\"<td>G</td><td>P</td>\"*4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'precision': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'recall': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key]['G'].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key]['P'].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            #totalImpact[metric][\"P\"].append(tab1_body_model[model][metric][key]['P'] >= tab1_body_model[model][metric][key]['G'])\n",
    "                            #totalImpact[metric][\"G\"].append(tab1_body_model[model][metric][key]['P'] <= tab1_body_model[model][metric][key]['P'])\n",
    "        \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "            tab1_body+= f'<tr> <td rowspan=\"2\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # add metric in the vector\n",
    "                    totalImpact[metric][\"P\"].append(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "                    totalImpact[metric][\"G\"].append(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "        \n",
    "                    tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'\n",
    "                                ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td></tr>')\n",
    "        tab1_body+= f'<tr> <td colspan=\"2\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td>'\n",
    "                            ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td></tr>')\n",
    "            \n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab1')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab1/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e624bca0-8b98-49df-b047-0e47596eb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_from_cols = lambda x:(list(set([\n",
    "    var.split(\"__\")[1] for var in [\n",
    "        coll \n",
    "        for coll in [\n",
    "            col \n",
    "            for col in x \n",
    "                if not (\n",
    "                    ('precision' in col ) \n",
    "                    or ('accuracy' in col ) \n",
    "                    or ('recall' in col) \n",
    "                    or ('f1-score' in col)\n",
    "                )\n",
    "            ] \n",
    "            if (\"__\" in coll)\n",
    "        ]\n",
    "    ]\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5aecf1-35ec-49cf-ae19-297913705389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_launcher(outputs_name=None, analytical_func=None, layers=None, approach=None):\n",
    "    \n",
    "    result_folders = [dirnames for _, dirnames, _ in os.walk(f'{os.getcwd()}/{outputs_name}')][0]\n",
    "    for dataset_name in result_folders:\n",
    "        print(dataset_name)\n",
    "        classic_f = [\n",
    "                        load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        for file in get_filenames(\n",
    "                            root_dir=f'{os.getcwd()}/{outputs_name}/{dataset_name}/data_selection_storage', \n",
    "                            func=MLN_C, \n",
    "                            verbose=False\n",
    "                            )\n",
    "                        ][-1]\n",
    "        quali_col = get_qualitative_from_cols(classic_f.columns.to_list())\n",
    "        models_list = classic_f.index.values.tolist()\n",
    "        models = model_desc()\n",
    "        models_name = { key : models[key] for key in models.keys() if key in models_list}\n",
    "        layers = list(set([1, 2, len(quali_col)]))\n",
    "        analytical_func(\n",
    "            cols=quali_col, \n",
    "            outputs_path=f'{os.getcwd()}/{outputs_name}/{dataset_name}', \n",
    "            cwd=os.getcwd(), \n",
    "            data_folder=dataset_name, \n",
    "            classic_metrics=classic_f, \n",
    "            models_name=models_name,\n",
    "            layers= layers if layers != None else list(set([1, 2, len(quali_col)])), \n",
    "            approach= approach\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a85acf7f-4569-409d-a8a6-36ea94b241e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = None\n",
    "approach = ['classic_mln','classic_mln_-_mlna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ea6117-dc08-4397-a515-5c559e5179a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AER\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/AER/plots/fnTab/tab1' created successfully.\n",
      "AFB\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/AFB/plots/fnTab/tab1' created successfully.\n",
      "CREDIT_RISK_DATASET\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/CREDIT_RISK_DATASET/plots/fnTab/tab1' created successfully.\n",
      "GERMAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/GERMAN/plots/fnTab/tab1' created successfully.\n",
      "JAPAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/JAPAN/plots/fnTab/tab1' created successfully.\n"
     ]
    }
   ],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_1, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea955056-7e98-4092-af2d-28439430809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_2(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for key in layers}\n",
    "        totalImpact = {\n",
    "            'accuracy': {f'MLN {key}': [] for key in layers},\n",
    "            'precision': {f'MLN {key}': [] for key in layers},\n",
    "            'recall': {f'MLN {key}': [] for key in layers},\n",
    "            'f1-score': {f'MLN {key}': [] for key in layers}\n",
    "        }\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"3\" rowspan=\"2\">{x}</td><td colspan=\"{len(mlnL)}\">Accuracy</td><td colspan=\"{len(mlnL)}\">Precision</td><td colspan=\"{len(mlnL)}\">Recall</td><td colspan=\"{len(mlnL)}\">F1-score</td></tr><tr>{\"\".join([\"<td>\"+key+\"</td>\" for key in mlnL.keys()]) *4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "            \n",
    "        dictio = {\n",
    "            'classic_-_mlna': 'Classic - Att',\n",
    "            'classic_mln': 'Classic + MLN',\n",
    "            'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "            'classic': 'Classic'\n",
    "        }\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k}'][\"G\"].append(round(files['global'][key].loc[model,metric],4))\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k}'][\"P\"].append(round(files['personalized'][key].loc[model,metric],4))\n",
    "                            \n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}    \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                tab1_body+= f'<tr> <td rowspan=\"4\">{model}</td>'\n",
    "                # fetch approach\n",
    "                for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                    # fetch evaluation metric\n",
    "                    tab1_body+= (f'<tr> <td rowspan=\"2\">{dictio[key]}</td>') if i != 0 else (f'<td rowspan=\"2\">{dictio[key]}</td>')\n",
    "                    for l,logic in enumerate(logics.keys()):\n",
    "                        tab1_body+= (f'<tr><td>{logics[logic]}</td>') if l != 0 else (f'<td>{logics[logic]}</td>')\n",
    "                        for y, metric in enumerate(metrics):\n",
    "                            #print(f\"{y}--\")\n",
    "                            # fetch layers\n",
    "                            for z, layer in enumerate(mlnL.keys()):\n",
    "                                #print(f\"{z};\")\n",
    "                                # add metric in the vector\n",
    "                                maxi = [max(tab1_body_model[model][metric][key][lay][logic]) for lay in mlnL ]\n",
    "                                totalImpact[metric][layer].append(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))\n",
    "                    \n",
    "                                tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td></tr>') if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                            f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td>')\n",
    "                            \n",
    "        tab1_body+= f'<tr> <td colspan=\"3\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            for z, layer in enumerate(mlnL.keys()):\n",
    "                maxi = [sum(totalImpact[metric][lay]) for lay in mlnL]\n",
    "                tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td></tr>'\n",
    "                                ) if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td>')\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle et modélisation </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab2')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab2/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1728349-50fb-459e-9eaa-b685a9267fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AER\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/AER/plots/fnTab/tab2' created successfully.\n",
      "AFB\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/AFB/plots/fnTab/tab2' created successfully.\n",
      "CREDIT_RISK_DATASET\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/CREDIT_RISK_DATASET/plots/fnTab/tab2' created successfully.\n",
      "GERMAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/GERMAN/plots/fnTab/tab2' created successfully.\n",
      "JAPAN\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "['xgb', 'dtc', 'lrc', 'rfc', 'sv']\n",
      "Directory '/Users/djiemboutientcheuvictornico/Documents/M2_Thesis/M2_thesis/scripting/analyze_outputs_16032024_made_on_2024_03_28_09H/JAPAN/plots/fnTab/tab2' created successfully.\n"
     ]
    }
   ],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_2, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0338183-5233-455a-96de-c6135915f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_3(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"2\" rowspan=\"2\">{x}</td><td colspan=\"2\">Accuracy</td><td colspan=\"2\">Precision</td><td colspan=\"2\">Recall</td><td colspan=\"2\">F1-score</td></tr><tr>{\"<td>G</td><td>P</td>\"*4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "                'classic_mln_-_mlna':{\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        totalImpact = {\n",
    "            'accuracy': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'precision': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'recall': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                },\n",
    "            'f1-score': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                }\n",
    "        }\n",
    "        \n",
    "        dictio = {\n",
    "                    'classic_-_mlna': 'Classic - Att',\n",
    "                    'classic_mln': 'Classic + MLN',\n",
    "                    'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "                    'classic': 'Classic'\n",
    "                }\n",
    "        \n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key]['G'].append(round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) if round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) >= 0 else 0)\n",
    "                            tab1_body_model[model][metric][key]['P'].append(round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) if round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) >= 0 else 0)\n",
    "                            #totalImpact[metric][\"P\"].append(tab1_body_model[model][metric][key]['P'] >= tab1_body_model[model][metric][key]['G'])\n",
    "                            #totalImpact[metric][\"G\"].append(tab1_body_model[model][metric][key]['P'] <= tab1_body_model[model][metric][key]['P'])\n",
    "        \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "            tab1_body+= f'<tr> <td rowspan=\"2\">{model}</td>'\n",
    "            # fetch approach\n",
    "            for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                # fetch evaluation metric\n",
    "                tab1_body+= f'<tr> <td>{dictio[key]}</td>' if i != 0 else f'<td>{dictio[key]}</td>'\n",
    "                for y, metric in enumerate(metrics):\n",
    "                    # add metric in the vector\n",
    "                    totalImpact[metric][\"P\"].append(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "                    totalImpact[metric][\"G\"].append(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))\n",
    "        \n",
    "                    tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'\n",
    "                                ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"G\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) >= max(tab1_body_model[model][metric][key][\"P\"]))}</td>'+\n",
    "                                f'<td> {\"<strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}{max(tab1_body_model[model][metric][key][\"P\"])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][\"G\"]) <= max(tab1_body_model[model][metric][key][\"P\"]))}</td></tr>')\n",
    "        tab1_body+= f'<tr> <td colspan=\"2\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td>'\n",
    "                            ) if y != len(metrics)-1 else (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"G\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) >= sum(totalImpact[metric][\"P\"]))}</td>'+\n",
    "                            f'<td>{\"<strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}{sum(totalImpact[metric][\"P\"])}{\"</strong>\"*int(sum(totalImpact[metric][\"G\"]) <= sum(totalImpact[metric][\"P\"]))}</td></tr>')\n",
    "            \n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best outperforming metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab3')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab3/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f49b3-011c-45b7-b3e0-30d28491dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_3, layers=layers, approach=approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63cb1c58-5784-4c85-8d58-aaa68434ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analyzer_statistics_tab_f_4(cols=None, outputs_path=None, cwd=None, data_folder=None, classic_metrics=None, models_name=None, layers=[1], approach=None):\n",
    "    \"\"\" build relevance results about the datasset\n",
    "    \n",
    "    Args:\n",
    "        - cols: list of qualitative variable in the dataset\n",
    "        - outputs_path: the path where the experimental results are located\n",
    "        - \n",
    "    \n",
    "    Returns:\n",
    "        A dedicated folder with those relevante reports and charts\n",
    "    \n",
    "    \"\"\"\n",
    "    day = time.strftime(\"%Y_%m_%d_%H\")\n",
    "    if cols != None or classic_metrics != None: # check if cols and classics metrics are filled\n",
    "        ## analyse of k layer\n",
    "\n",
    "        # find out all best metric details\n",
    "        mlnL = {f'MLN {key}': {\n",
    "                    'P':[],\n",
    "                    'G':[]\n",
    "                } for key in layers}\n",
    "        totalImpact = {\n",
    "            'accuracy': {f'MLN {key}': [] for key in layers},\n",
    "            'precision': {f'MLN {key}': [] for key in layers},\n",
    "            'recall': {f'MLN {key}': [] for key in layers},\n",
    "            'f1-score': {f'MLN {key}': [] for key in layers}\n",
    "        }\n",
    "        head_lambda = lambda x: f'<tr><td colspan=\"3\" rowspan=\"2\">{x}</td><td colspan=\"{len(mlnL)}\">Accuracy</td><td colspan=\"{len(mlnL)}\">Precision</td><td colspan=\"{len(mlnL)}\">Recall</td><td colspan=\"{len(mlnL)}\">F1-score</td></tr><tr>{\"\".join([\"<td>\"+key+\"</td>\" for key in mlnL.keys()]) *4}</tr>'\n",
    "        tab1_head = head_lambda(data_folder)\n",
    "        tab1_body = \"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'precision': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'recall': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            },\n",
    "            'f1-score': {\n",
    "                'classic_mln':deepcopy(mlnL),\n",
    "                'classic_mln_-_mlna':deepcopy(mlnL)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "            \n",
    "        dictio = {\n",
    "            'classic_-_mlna': 'Classic - Att',\n",
    "            'classic_mln': 'Classic + MLN',\n",
    "            'classic_mln_-_mlna': 'Classic + MLN - Att',\n",
    "            'classic': 'Classic'\n",
    "        }\n",
    "        \n",
    "        style = '<style> table, th, td {border: 1px solid black;border-collapse: collapse;} .wrap-text {word-wrap: break-word;} .wrap-text {overflow-wrap: break-word;} .limited-column {width: 100px;} .dashed-border {border: 1px dashed black;}.dotted-border {border: 1px dotted black;} td {text-align: center;} caption {margin:0; margin-bottom: 2px; text-align: start; border: 1px dashed black;} caption > h2 {text-align: center;}</style>'\n",
    "        \n",
    "        caption_content_lambda = lambda x: ''.join([f'<span><strong>{key}</strong>: {value}</span><br>' for key, value in {\n",
    "            **models_name,\n",
    "            'MLN k Layer(s)': 'MultiLayer Network with k layer(s)',\n",
    "            'Att': 'Attributs or modalities of variable(s) used to build MLN',\n",
    "            'MLN': 'Descriptors extracted from MLN',\n",
    "            'Classic': f'Learning from classic dataset of {data_folder}',\n",
    "            'Classic - Att': f'Learning from classic dataset of {data_folder} where Att had been removed',\n",
    "            'Classic + MLN': f'Learning from classic dataset of {data_folder} where MLN had been added',\n",
    "            'Classic + MLN - Att': f'Learning from classic dataset of {data_folder} where MLN had been added and Att removed'\n",
    "            }.items()])\n",
    "        \n",
    "        tab1_body_model = {key: deepcopy(metrics) for key in models_name.keys()}\n",
    "\n",
    "        # fetch layers\n",
    "        for k in layers:\n",
    "            # fetch each combinantion of atributs in layers\n",
    "            for layer_config in get_combinations(range(len(cols)),k): # create subsets of k index of OHE and fetch it\n",
    "                col_targeted= [f'{cols[i]}' for i in layer_config]\n",
    "                case_k= '±'.join(col_targeted) if len(layer_config)>1 else col_targeted[0]\n",
    "                \n",
    "                ### get files for distincts logic\n",
    "                match= lambda x: (\n",
    "                    sum(\n",
    "                        [\n",
    "                            re.sub(r'[^\\w\\s]', '', unidecode(partern)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                            for partern in case_k.split(\"±\")\n",
    "                            ]\n",
    "                        ) == k if k > 1 else re.sub(r'[^\\w\\s]', '', unidecode(case_k)) in re.sub(r'[^\\w\\s]', '', unidecode(x))\n",
    "                    )\n",
    "                files = {\n",
    "                    'global':{\n",
    "                        'classic': classic_metrics,\n",
    "                        #'classic_-_mlna':[\n",
    "                        #    load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                        #    for file in get_filenames(\n",
    "                        #        root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                        #        func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                        #        verbose=False\n",
    "                         #       )\n",
    "                         #   ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/global/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    },\n",
    "                    \"personalized\":{\n",
    "                        'classic': classic_metrics,\n",
    "                       # 'classic_-_mlna':[\n",
    "                       #     load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                       #     for file in get_filenames(\n",
    "                       #         root_dir=f'{outputs_path}/qualitative/mlna_{k}/data_selection_storage', \n",
    "                       #         func=lambda x: ((MLN_C_F(x)) and (match(x))), \n",
    "                       #         verbose=False\n",
    "                       #         )\n",
    "                       #     ][-1],\n",
    "                        'classic_mln':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN_F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1],\n",
    "                        'classic_mln_-_mlna':[\n",
    "                            load_data_set_from_url(path=file,sep='\\t', encoding='utf-8',index_col=0, na_values=None) \n",
    "                            for file in get_filenames(\n",
    "                                root_dir=f'{outputs_path}/qualitative/mlna_{k}/personalized/data_selection_storage', \n",
    "                                func=lambda x: ((MLN__F(x)) and (match(x))), \n",
    "                                verbose=False\n",
    "                                )\n",
    "                            ][-1]\n",
    "                    }\n",
    "                }\n",
    "                # print(files)\n",
    "                #outputs[logic] = files\n",
    "                ### transform and normalize\n",
    "                models_list = files['personalized']['classic'].index.values.tolist()\n",
    "                print(models_list)\n",
    "                metrics = [\"accuracy\",\"precision\",\"recall\",\"f1-score\"]\n",
    "                \n",
    "                # fetch models\n",
    "                for model in models_list:\n",
    "                    # fetch evaluation metric\n",
    "                    for metric in metrics:\n",
    "                        # fetch approach\n",
    "                        for i, key in enumerate(approach): \n",
    "                            # add metric in the vector\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k}'][\"G\"].append(round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) if round(((round(files['global'][key].loc[model,metric],4) - round(files['global']['classic'].loc[model,metric],4))/round(files['global']['classic'].loc[model,metric],4))*100,4) >= 0 else 0)\n",
    "                            tab1_body_model[model][metric][key][f'MLN {k}'][\"P\"].append(round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) if round(((round(files['personalized'][key].loc[model,metric],4) - round(files['personalized']['classic'].loc[model,metric],4))/round(files['personalized']['classic'].loc[model,metric],4))*100,4) >= 0 else 0)\n",
    "                            \n",
    "        logics = {\"G\":\"Global\",\"P\":\"Personalized\"}    \n",
    "        # fetch each model\n",
    "        for model in models_list:\n",
    "                tab1_body+= f'<tr> <td rowspan=\"4\">{model}</td>'\n",
    "                # fetch approach\n",
    "                for i, key in enumerate(files['global'].keys() if approach == None else approach):\n",
    "                    # fetch evaluation metric\n",
    "                    tab1_body+= (f'<tr> <td rowspan=\"2\">{dictio[key]}</td>') if i != 0 else (f'<td rowspan=\"2\">{dictio[key]}</td>')\n",
    "                    for l,logic in enumerate(logics.keys()):\n",
    "                        tab1_body+= (f'<tr><td>{logics[logic]}</td>') if l != 0 else (f'<td>{logics[logic]}</td>')\n",
    "                        for y, metric in enumerate(metrics):\n",
    "                            #print(f\"{y}--\")\n",
    "                            # fetch layers\n",
    "                            for z, layer in enumerate(mlnL.keys()):\n",
    "                                #print(f\"{z};\")\n",
    "                                # add metric in the vector\n",
    "                                maxi = [max(tab1_body_model[model][metric][key][lay][logic]) for lay in mlnL ]\n",
    "                                totalImpact[metric][layer].append(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))\n",
    "                    \n",
    "                                tab1_body+= (f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td></tr>') if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                            f'<td>{\"<strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}{max(tab1_body_model[model][metric][key][layer][logic])}{\"</strong>\"*int(max(tab1_body_model[model][metric][key][layer][logic]) == max(maxi))}</td>')\n",
    "                            \n",
    "        tab1_body+= f'<tr> <td colspan=\"3\">Total</td>'\n",
    "        for y, metric in enumerate(metrics): \n",
    "            for z, layer in enumerate(mlnL.keys()):\n",
    "                maxi = [sum(totalImpact[metric][lay]) for lay in mlnL]\n",
    "                tab1_body+= (f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td></tr>'\n",
    "                                ) if ((y == len(metrics)-1) and (z == len(mlnL)-1 )) else (\n",
    "                                f'<td>{\"<strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}{sum(totalImpact[metric][layer])}{\"</strong>\"*int(sum(totalImpact[metric][layer]) == max(maxi))}</td>')\n",
    "        \n",
    "        caption = f'<caption><h2>Legend</h2>{caption_content_lambda(metric)}</caption>'\n",
    "        table_html = f'<table style=\"border: 2px solid black; width: 100% !important; background-color: #FFFFFF; color:#000000;\">{caption}{tab1_head}{tab1_body}</table>'\n",
    "        htm = f'<html><head>{style}<title> Best outperforming metrics of personalized and global logic for Classic + MLN et Classic + MLN - Att pour chaque modèle et modélisation </title></head><body style=\"background-color: white;\">{table_html}</body></html>'\n",
    "        \n",
    "        create_domain(f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab4')\n",
    "        timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        filename1 = f'{cwd}/analyze_{outputs_path.split(\"/\")[-2]}_made_on_{day}H/{data_folder}/plots/fnTab/tab4/Statistical comparaison of approachs in {data_folder} on global logic'+'_'+timestr+'.html'\n",
    "        _file= open(filename1,\"w\")\n",
    "        _file.write(htm)\n",
    "        _file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f541b-204f-4bd0-ad17-837b2567754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_launcher(outputs_name=\"outputs_16032024\", analytical_func=metrics_analyzer_statistics_tab_f_4, layers=layers, approach=approach)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
